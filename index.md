# causal
 - [[pdfs/causal/a_meta_transfer_objective_for_learning_to_disentangle_causal_mechanisms.pdf|A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms.]]: (cite: conf/iclr/BengioDRKLBGP20) . [[papers/causal/a_meta_transfer_objective_for_learning_to_disentangle_causal_mechanisms.md|Notes]]
 - [[pdfs/causal/causal_discovery_in_physical_systems_from_videos.pdf|Causal Discovery in Physical Systems from Videos.]]: (cite: conf/nips/Li0AFG20) [[papers/causal/causal_discovery_in_physical_systems_from_videos.md|Notes]]
 - [[pdfs/causal/indepedendent_causal_mechanisms.pdf|Learning Independent Causal Mechanisms.]]: (cite: conf/icml/ParascandoloKRS18) . [[papers/causal/indepedendent_causal_mechanisms.md|Notes]]
 - [[pdfs/causal/nonlinear_causal_discovery_with_additive_noise_models.pdf|Nonlinear causal discovery with additive noise models.]]: (cite: conf/nips/HoyerJMPS08) [[papers/causal/nonlinear_causal_discovery_with_additive_noise_models.md|Notes]]
 - [[pdfs/causal/towards_causal_representation_learning.pdf|Towards Causal Representation Learning.]]: (cite: journals/corr/abs-2102-11107/Scholkopf/2021) . [[papers/causal/towards_causal_representation_learning.md|Notes]]
# cogsci
 - [[pdfs/cogsci/building_machines_that_learn_and_think_like_people.pdf|Building Machines that Learn and Think Like People.]]: (cite: conf/atal/Tenenbaum18) . [[papers/cogsci/building_machines_that_learn_and_think_like_people.md|Notes]]
 - [[pdfs/cogsci/cognitive_effects_of_language_on_human_navigation.pdf|Cognitive effects of language on human navigation]]: . [[papers/cogsci/cognitive_effects_of_language_on_human_navigation.md|Notes]]
 - [[pdfs/cogsci/human_few_shot_learning_of_compositional_instructions.pdf|Human few-shot learning of compositional instructions.]]: (cite: conf/cogsci/LakeLB19) Once a person learns a new verb "dax", he or she can effortly understand how to "dax twice", or "walk and dax" or "dax vigourously". In general people can learn and use novel functional concepts from very few examples (few-shot learning). People can also compose concepts in complex ways that go beyond the provided demonstrations. There are three inductive biases that people make: mutual exclusivity, one-to-one mapping and iconic concatenation. (See in general, Chomsky. N, 1957, Syntatctic Structures and Montague, R. (1970) Universal Grammar, Theoria 36, 373-398). Apparently the ability is also central to how people learn from few-shots (Fordor J. 1975, The Language of Thought; The compositionality papers). [[papers/cogsci/human_few_shot_learning_of_compositional_instructions.md|Notes]]
 - [[pdfs/cogsci/investigating_human_priors_for_playing_video_games.pdf|Investigating Human Priors for Playing Video Games.]]: (cite: conf/iclr/DubeyAPEG18) . [[papers/cogsci/investigating_human_priors_for_playing_video_games.md|Notes]]
 - [[pdfs/cogsci/what_underlies_rapid_learning_and_systematic_generalization_in_humans.pdf|What underlies rapid learning and systematic generalization in humans.]]: (cite: journals/corr/abs-2107-06994/Nam/2021) . [[papers/cogsci/what_underlies_rapid_learning_and_systematic_generalization_in_humans.md|Notes]]
# cv
 - [[pdfs/cv/a_novel_global_spatial_attention_mechanism_in_convolutional_neural_network_for_medical_image_classification.pdf|A Novel Global Spatial Attention Mechanism in Convolutional Neural Network for Medical Image Classification.]]: (cite: journals/corr/abs-2007-15897/Xu/2020) . [[papers/cv/a_novel_global_spatial_attention_mechanism_in_convolutional_neural_network_for_medical_image_classification.md|Notes]]
 - [[pdfs/cv/are_cnn_or_transformers_more_like_human_vision.pdf|Are Convolutional Neural Networks or Transformers more like human vision?]]: (cite: journals/corr/abs-2105-07197/Tuli/2021) . [[papers/cv/are_cnn_or_transformers_more_like_human_vision.md|Notes]]
 - [[pdfs/cv/deep_automodulators.pdf|Deep Automodulators.]]: (cite: conf/nips/HeljakkaHKS20) . [[papers/cv/deep_automodulators.md|Notes]]
 - [[pdfs/cv/designing_network_design_spaces.pdf|Designing Network Design Spaces.]]: (cite: conf/cvpr/RadosavovicKGHD20) [[papers/cv/designing_network_design_spaces.md|Notes]]
 - [[pdfs/cv/film_feature_wise_linear_modulation.pdf|FiLM - Visual Reasoning with a General Conditioning Layer.]]: (cite: conf/aaai/PerezSVDC18) . [[papers/cv/film_feature_wise_linear_modulation.md|Notes]]
 - [[pdfs/cv/generative_pretraining_from_pixels.pdf|Generative Pretraining From Pixels.]]: (cite: conf/icml/ChenRC0JLS20) Sort of like PixelCNN for Transformers . [[papers/cv/generative_pretraining_from_pixels.md|Notes]]
 - [[pdfs/cv/pretraining_from_pixels.pdf|Generative Pretraining From Pixels.]]: (cite: conf/icml/ChenRC0JLS20) [[papers/cv/pretraining_from_pixels.md|Notes]]
 - [[pdfs/cv/mlp_mixer.pdf|MLP-Mixer - An all-MLP Architecture for Vision.]]: (cite: journals/corr/abs-2105-01601/Tolstikhin/2021) Takes the "image-patch transformers" architectures and removes the transformers to test the hypothesis that the patches are what matters. Based exclusively on MLPs. Apply the MLPs to image patches (mixing the per-location features) and then apply the MLPS across patches (mixing spatial information). [[papers/cv/mlp_mixer.md|Notes]]
 - [[pdfs/cv/patches_are_all_you_need_.pdf|Patches Are All You Need?]]: (cite: journals/corr/abs-2201-09792/Trockman/2022) Is the performance of ViTs due to the transformer or due to the patches? Paper proposes ConvMixer. ConvMixer only uses convolutions to achieve the mixing steps. [[papers/cv/patches_are_all_you_need_.md|Notes]]
 - [[pdfs/cv/residual_attention_network.pdf|Residual Attention Network for Image Classification.]]: (cite: conf/cvpr/WangJQYLZWT17) . [[papers/cv/residual_attention_network.md|Notes]]
 - [[pdfs/cv/revisiting_resnets_improved_training_and_scaling_strategies.pdf|Revisiting ResNets: Improved Training and Scaling Strategies.]]: (cite: conf/nips/BelloFDCSLSZ21) . [[papers/cv/revisiting_resnets_improved_training_and_scaling.md|Notes]]. [[papers/cv/revisiting_resnets_improved_training_and_scaling_strategies.md|Notes]]
 - [[pdfs/cv/towards_biologically_plausible_convolutional_networks.pdf|Towards Biologically Plausible Convolutional Networks.]]: (cite: journals/corr/abs-2106-13031/Pogodin/2021) . Proposes a locally-connected relaxation of convolution which can fit into a hebbian learning rule and be regularized so that it behaves like a convolution via a weight-sharing update phase. . [[papers/cv/towards_biologically_plausible_convolutional_networks.md|Notes]]
 - [[pdfs/cv/unsupervised_learning_of_object_keypoints_for_perception_and_control.pdf|Unsupervised Learning of Object Keypoints for Perception and Control.]]: (cite: conf/nips/KulkarniGIBRZM19) [[papers/cv/unsupervised_learning_of_object_keypoints_for_perception_and_control.md|Notes]]
 - [[pdfs/cv/unsupervised_learning_of_object_landmarks_conditional_image_generation.pdf|Unsupervised Learning of Object Landmarks through Conditional Image Generation.]]: (cite: conf/nips/JakabGBV18) . [[papers/cv/unsupervised_learning_of_object_landmarks_conditional_image_generation.md|Notes]]
 - [[pdfs/cv/unsupervised_semantic_segmentation_with_self_supervised_object_centric_representations.pdf|Unsupervised Semantic Segmentation with Self-supervised Object-centric Representations.]]: (cite: journals/corr/abs-2207-05027/Zadaianchuk/2022) . [[papers/cv/unsupervised_semantic_segmentation_with_self_supervised_object_centric_representations.md|Notes]]
 - [[pdfs/cv/visual_reasoning_with_multi_hop_feature_modulation.pdf|Visual Reasoning with Multi-hop Feature Modulation.]]: (cite: conf/eccv/StrubSPVMPCP18) Extension of FiLM for long-running language tasks. The basic idea is to refine the conditioning vector for each convolutional layer by using attention over the encoded language inputs . [[papers/cv/visual_reasoning_with_multi_hop_feature_modulation.md|Notes]]
 - [[pdfs/cv/spatial_transformer_networks.pdf|spatial_transformer_networks]]: . [[papers/cv/spatial_transformer_networks.md|Notes]]
## segmentation
 - [[pdfs/cv/segmentation/label_efficient_semantic_segmentation_with_diffusion_models.pdf|Label-Efficient Semantic Segmentation with Diffusion Models.]]: (cite: conf/iclr/BaranchukVRKB22) . [[papers/cv/segmentation/label_efficient_semantic_segmentation_with_diffusion_models.md|Notes]]
## transformer
 - [[pdfs/cv/transformer/icml_flow_guided_sparse_transformer_video_deblurring_slides.pdf|Flow-Guided Sparse Transformer for Video Deblurring (slides)]]: . [[papers/cv/transformer/icml_flow_guided_sparse_transformer_video_deblurring_slides.md|Notes]]
 - [[pdfs/cv/transformer/flow_guided_sparse_transformer_for_video_deblurring.pdf|Flow-Guided Sparse Transformer for Video Deblurring.]]: (cite: conf/icml/LinCHWYZDZTG22) Use optical flow to condition attention. [[papers/cv/transformer/flow_guided_sparse_transformer_for_video_deblurring.md|Notes]]
# dbml
 - [[pdfs/dbml/certifiable_unlearning_pipelines_for_logistic_regression_an_experimental_study.pdf|Certifiable Unlearning Pipelines for Logistic Regression: An Experimental Study]]: . [[papers/dbml/certifiable_unlearning_pipelines_for_logistic_regression_an_experimental_study.md|Notes]]
 - [[pdfs/dbml/dbml_survey.pdf|Database Meets Deep Learning: Challenges and Opportunities.]]: (cite: journals/corr/abs-1906-08986/Wang/2019) . [[papers/dbml/dbml_survey.md|Notes]]
# dl
 - [[pdfs/dl/deep_reasoning_networks.pdf|Deep Reasoning Networks for Unsupervised Pattern De-mixing with Constraint Reasoning.]]: (cite: conf/icml/ChenBZAGG20) . [[papers/dl/deep_reasoning_networks.md|Notes]]
 - [[pdfs/dl/distilling_the_knowledge_in_a_neural_network.pdf|Distilling the Knowledge in a Neural Network.]]: (cite: journals/corr/HintonVD15/Hinton/2015) . [[papers/dl/distilling_the_knowledge_in_a_neural_network.md|Notes]]
 - [[pdfs/dl/deconvolution.pdf|Graph deconvolutional networks.]]: (cite: journals/isci/ZhangHYCY20) . [[papers/dl/deconvolution.md|Notes]]
 - [[pdfs/dl/deep_sets.pdf|Information Systems on Hesitant Fuzzy Sets.]]: (cite: journals/ijrsda/DJ16) . [[papers/dl/deep_sets.md|Notes]]
 - [[pdfs/dl/mentornet_corrupted_labels.pdf|MentorNet: Regularizing Very Deep Neural Networks on Corrupted Labels.]]: (cite: journals/corr/abs-1712-05055/Jiang/2017) . [[papers/dl/mentornet_corrupted_labels.md|Notes]]
 - [[pdfs/dl/neural_tangent_kernel_eigenvalues_accurately_predict_generalization.pdf|Neural Tangent Kernel Eigenvalues Accurately Predict Generalization.]]: (cite: journals/corr/abs-2110-03922/Simon/2021) . [[papers/dl/neural_tangent_kernel_eigenvalues_accurately_predict_generalization.md|Notes]]
 - [[pdfs/dl/slide_lsh.pdf|SLIDE: In Defence of Smart Algorithms over Hardware Acceleration for Large-Scale Deep Learning Systems.]]: . [[papers/dl/slide_lsh.md|Notes]]
 - [[pdfs/dl/soft_sort_continuous_argsort.pdf|SoftSort: A Continuous Relaxation for the argsort Operator.]]: (cite: conf/icml/PrilloE20) . [[papers/dl/soft_sort_continuous_argsort.md|Notes]]
## active
 - [[pdfs/dl/active/active_learning_helps_pretrained_models_learn_the_intended_task.pdf|Active Learning Helps Pretrained Models Learn the Intended Task.]]: (cite: journals/corr/abs-2204-08491/Tamkin/2022) . [[papers/dl/active/active_learning_helps_pretrained_models_learn_the_intended_task.md|Notes]]
 - [[pdfs/dl/active/prioritized_training_on_points_that_are_learnable_worth_learning_and_net_yet_learnt.pdf|prioritized_training_on_points_that_are_learnable_worth_learning_and_net_yet_learnt]]: . [[papers/dl/active/prioritized_training_on_points_that_are_learnable_worth_learning_and_net_yet_learnt.md|Notes]]
## augmentation
 - [[pdfs/dl/augmentation/felmi_few_shot_learning_with_hard_mixup.pdf|felmi_few_shot_learning_with_hard_mixup]]: . [[papers/dl/augmentation/felmi_few_shot_learning_with_hard_mixup.md|Notes]]
## big_picture
 - [[pdfs/dl/big_picture/hinton_part_whole_hierarchies.pdf|How to represent part-whole hierarchies in a neural network.]]: (cite: journals/corr/abs-2102-12627/Hinton/2021) . [[papers/dl/big_picture/hinton_part_whole_hierarchies.md|Notes]]
 - [[pdfs/dl/big_picture/bengio_higher_level_cognition.pdf|Inductive Biases for Deep Learning of Higher-Level Cognition.]]: (cite: journals/corr/abs-2011-15091/Goyal/2020) . [[papers/dl/big_picture/bengio_higher_level_cognition.md|Notes]]
## books
 - [[pdfs/dl/books/dl_book_a_ilin.pdf|Deep Learning Lecture Notes(Alexander Ilin, 2021)]]: . [[papers/dl/books/dl_book_a_ilin.md|Notes]]
 - [[pdfs/dl/books/dl_book_bengio.pdf|Deep Learning.]]: (cite: books/daglib/0040158) . [[papers/dl/books/dl_book_bengio.md|Notes]]
## causal
 - [[pdfs/dl/causal/improving_multi_task_generalization_via_regularizing_spurious_correlation.pdf|Improving Multi-Task Generalization via Regularizing Spurious Correlation.]]: (cite: journals/corr/abs-2205-09797/Hu/2022) . [[papers/dl/causal/improving_multi_task_generalization_via_regularizing_spurious_correlation.md|Notes]]
 - [[pdfs/dl/causal/interventional_contrastive_learning_with_a_meta_semantic_regularizer.pdf|Interventional Contrastive Learning with a Meta Semantic Regularizer]]: . [[papers/dl/causal/interventional_contrastive_learning_with_a_meta_semantic_regularizer.md|Notes]]
 - [[pdfs/dl/causal/learning_to_induce_causal_structure.pdf|Learning to Induce Causal Structure.]]: (cite: journals/corr/abs-2204-04875/Ke/2022) . [[papers/dl/causal/learning_to_induce_causal_structure.md|Notes]]
 - [[pdfs/dl/causal/towards_understanding_how_machines_can_learn_causal_overhypotheses.pdf|Towards Understanding How Machines Can Learn Causal Overhypotheses.]]: (cite: journals/corr/abs-2206-08353/Kosoy/2022) . [[papers/dl/causal/towards_understanding_how_machines_can_learn_causal_overhypotheses.md|Notes]]
## compositional
 - [[pdfs/dl/compositional/relnet_a_simple_neural_network_module_for_relational_reasonign.pdf|A simple neural network module for relational reasoning.]]: (cite: conf/nips/SantoroRBMPBL17) Presents the RelNet architecture. Its not really an architecture as much as it is a framework for architectures, essentially you have a relation function between object pairs in a fully connected graph and then a "summary" function which answers some question. The main challenge is how you get the objects. For example you might get them from pooled image features or from words. [[papers/dl/compositional/relnet_a_simple_neural_network_module_for_relational_reasonign.md|Notes]]
 - [[pdfs/dl/compositional/analogical_reasoning_for_visually_grounded_compositional_generalization.pdf|Analogical Reasoning for Visually Grounded Compositional Generation]]: . [[papers/dl/compositional/analogical_reasoning_for_visually_grounded_compositional_generalization.md|Notes]]
 - [[pdfs/dl/compositional/characterizing_intrinsic_compositionality_in_transformers_with_tree_projections.pdf|Characterizing Intrinsic Compositionality In Transformers With Tree Projections.]]: (cite: journals/corr/abs-2211-01288/Murty/2022) Induce a tree-representation by taking all subspans of a sentence, define some metrics to see how "tree-like" a representation is, then measure how tree-like transformers become. [[papers/dl/compositional/characterizing_intrinsic_compositionality_in_transformers_with_tree_projections.md|Notes]]
 - [[pdfs/dl/compositional/compositional_attention_disentangling_search_and_retrieval.pdf|Compositional Attention - Disentangling Search and Retrieval.]]: (cite: journals/corr/abs-2110-09419/Mittal/2021) In standard multi-head attention, the query, key and value sub-heads are tightly coupled. This paper explores an architecture where they are not, eg, where you have several "search" (query/key) heads and several "retrieval" (eg, value) heads, and MHA is expressed as compositions of each of them . [[papers/dl/compositional/compositional_attention_disentangling_search_and_retrieval.md|Notes]]
 - [[pdfs/dl/compositional/compositional_attention_networks.pdf|Compositional Attention Networks for Machine Reasoning.]]: (cite: conf/iclr/HudsonM18) Proposes a memory-like architecture (MAC, Memory, Attention, Control) for doing cross-model attention, designed for question answering. The idea is that the image starts out as a "knowledge base", then you do reasoning over several steps, updating some memory state each time using . [[papers/dl/compositional/compositional_attention_networks.md|Notes]]
 - [[pdfs/dl/compositional/compositional_genearlization_for_primitive_substitutions.pdf|Compositional Generaliation for Primitive Substitution]]: . [[papers/dl/compositional/compositional_genearlization_for_primitive_substitutions.md|Notes]]
 - [[pdfs/dl/compositional/compositional_generalization_by_learning_analytical_expressions.pdf|Compositional Generalization by Learning Analytical Expressions.]]: (cite: conf/nips/LiuALCL0Z0Z20) . [[papers/dl/compositional/compositional_generalization_by_learning_analytical_expressions.md|Notes]]
 - [[pdfs/dl/compositional/compositional_generalization_in_semantic_parsing_pre_training_vs_specialized_architectures.pdf|Compositional Generalization in Semantic Parsing: Pre-training vs. Specialized Architectures.]]: (cite: journals/corr/abs-2007-08970/Furrer/2020) . [[papers/dl/compositional/compositional_generalization_in_semantic_parsing_pre_training_vs_specialized_architectures.md|Notes]]
 - [[pdfs/dl/compositional/compositional_generalization_via_neural_stack_machines.pdf|Compositional Generalization via Neural-Symbolic Stack Machines.]]: (cite: conf/nips/ChenLYSZ20) . [[papers/dl/compositional/compositional_generalization_via_neural_stack_machines.md|Notes]]
 - [[pdfs/dl/compositional/compose_ae_compositional_learning_of_image_text_query_for_image_retrieval.pdf|Compositional Learning of Image-Text Query for Image Retrieval.]]: (cite: conf/wacv/AnwaarLK21) . ComposeAE model. For image-text retrieval. Given an image query and a text modifier term, find some other image in the database. Both image and text are encoded to vectors, then you decode something to find the relevant image the database. The main contribution is to treat the text term as a kind of rotational operator and enforce symmetry, such that you can rotate backwards from the target to the source. [[papers/dl/compositional/compose_ae_compositional_learning_of_image_text_query_for_image_retrieval.md|Notes]]
 - [[pdfs/dl/compositional/ganformer_2_compositional_transformers_for_scene_generation.pdf|Compositional Transformers for Scene Generation.]]: (cite: conf/nips/HudsonZ21) . GANFormer2 paper. Predict a segmentation map, then infill the segmentation map based on the predicted class. [[papers/dl/compositional/ganformer_2_compositional_transformers_for_scene_generation.md|Notes]]
 - [[pdfs/dl/compositional/compositional_generalization_through_meta_seq2seq.pdf|Compositional generalization through meta sequence-to-sequence learning.]]: (cite: conf/nips/Lake19) . Permute indices in supports and query in meta-seq2seq. This can help with meta-learning to compositionally generalize.  [[papers/dl/compositional/compositional_generalization_through_meta_seq2seq.md|Notes]]
 - [[pdfs/dl/compositional/compositionality_decomposed_neural_networks_generalize.pdf|Compositionality Decomposed - How do Neural Networks Generalise?]]: (cite: journals/jair/HupkesDMB20) .  Introduces PCFG-SET. Examines Transformer, LSTM, ConvSeq2seq on five tasks, systematicity, productivity, synonym substitution, localism and overgeneralization. Most models can't get all those tasks completely correct. Explores in exactly what circumstances tht happens. On everything except overgeneralization, Transformer does better. [[papers/dl/compositional/compositionality_decomposed_neural_networks_generalize.md|Notes]]
 - [[pdfs/dl/compositional/compositionality_as_lexical_symmetry.pdf|Compositionality as Lexical Symmetry.]]: (cite: journals/corr/abs-2201-12926/Akyurek/2022) . [[papers/dl/compositional/compositionality_as_lexical_symmetry.md|Notes]]
 - [[pdfs/dl/compositional/coordination_among_neural_modules_through_a_shared_global_workspace.pdf|Coordination Among Neural Models Through a Shared Global Workspace]]: Deep Learning has moved away from monolithic modules to modular networks such as Transformers and RIMs, each specialize is a neural module that specializes in a different aspect of the task. How do these distinct specialists share information with each other? Global Workspace theory says that these specialists can interact with each other through a workspace. Information is written into the workspace in a competitive way. In this study they implement this concept of a "shared workspace" into RIM, Transformer, TIM and Universal Transformer. Compared to self-attention, the shared workspace is O(N) and not pairwise but rather global-to-local. This can improve specialization. [[papers/dl/compositional/coordination_among_neural_modules_through_a_shared_global_workspace.md|Notes]]
 - [[pdfs/dl/compositional/deep_compositional_question_answering_with_neural_module_networks.pdf|Deep Compositional Question Answering with Neural Module Networks.]]: (cite: journals/corr/AndreasRDK15/Andreas/2015) . [[papers/dl/compositional/deep_compositional_question_answering_with_neural_module_networks.md|Notes]]
 - [[pdfs/dl/compositional/diversity_vs_recognizability_human_like_generalization_in_one_shot_generative_models.pdf|Diversity vs. Recognizability: Human-like generalization in one-shot generative models.]]: (cite: journals/corr/abs-2205-10370/Boutin/2022) . [[papers/dl/compositional/diversity_vs_recognizability_human_like_generalization_in_one_shot_generative_models.md|Notes]]
 - [[pdfs/dl/compositional/explainable_neural_computation_via_stack_neural_module_networks.pdf|Explainable Neural Computation via Stack Neural Module Networks.]]: (cite: conf/eccv/HuADS18) . [[papers/dl/compositional/explainable_neural_computation_via_stack_neural_module_networks.md|Notes]]
 - [[pdfs/dl/compositional/how_do_neural_sequence_models_generalize_local_and_global_context_cues_for_out_of_distribution_prediction.pdf|How Do Neural Sequence Models Generalize? Local and Global Context Cues for Out-of-Distribution Prediction.]]: (cite: journals/corr/abs-2111-03108/Bau/2021) If a language model is presented with a "surprising" next token, how will it generalize? Will it predict based on the local context (eg, just the previously seen token) or will it predict based on the global context and ignore the surprising token? The answer depends on the language being used, but we can influence the choice by noising the local or global context. [[papers/dl/compositional/how_do_neural_sequence_models_generalize_local_and_global_context_cues_for_out_of_distribution_prediction.md|Notes]]
 - [[pdfs/dl/compositional/how_modular_should_neural_networks_be_for_systematic_generalization.pdf|How Modular should Neural Module Networks Be for Systematic Generalization?]]: (cite: conf/nips/DAmarioSB21) . NMNs can have different structures. Either they can be completely decomposed or specialized, they can have "group" structure (eg, color module, relation module, etc) or they can have one module that does everything. In this paper they find that the group structure works the best in the generalization case . [[papers/dl/compositional/how_modular_should_neural_networks_be_for_systematic_generalization.md|Notes]]
 - [[pdfs/dl/compositional/improving_compositional_generalization_with_latent_structure_and_data_augmentation.pdf|Improving Compositional Generalization with Latent Structure and Data Augmentation.]]: (cite: conf/naacl/QiuSPNLST22) . [[papers/dl/compositional/improving_compositional_generalization_with_latent_structure_and_data_augmentation.md|Notes]]
 - [[pdfs/dl/compositional/latent_compositional_representations_improve_systematic_generalization_in_grounded_question_answering.pdf|Latent Compositional Representations Improve Systematic Generalization in Grounded Question Answering.]]: (cite: journals/tacl/BoginSGB21) Creates a "latent parse tree" by encoding every contiguous subsequence of a language statement , composing splits up along the way with a soft-splitting mechanism. Then there is a neural module network used to combine information in certain ways . [[papers/dl/compositional/latent_compositional_representations_improve_systematic_generalization_in_grounded_question_answering.md|Notes]]
 - [[pdfs/dl/compositional/learning_compositional_rules_via_neural_program_synthesis.pdf|Learning Compositional Rules via Neural Program Synthesis.]]: (cite: conf/nips/NyeS0L20) . [[papers/dl/compositional/learning_compositional_rules_via_neural_program_synthesis.md|Notes]]
 - [[pdfs/dl/compositional/learning_to_compose_neural_networks_for_question_answering.pdf|Learning to Compose Neural Networks for Question Answering.]]: (cite: conf/naacl/AndreasRDK16) . [[papers/dl/compositional/learning_to_compose_neural_networks_for_question_answering.md|Notes]]
 - [[pdfs/dl/compositional/learning_to_reason_end_to_end_module_networks_for_visual_question_answering.pdf|Learning to Reason: End-to-End Module Networks for Visual Question Answering.]]: (cite: conf/iccv/HuARDS17) . [[papers/dl/compositional/learning_to_reason_end_to_end_module_networks_for_visual_question_answering.md|Notes]]
 - [[pdfs/dl/compositional/learning_to_recombine_and_resample_data_for_compositional_generalization.pdf|Learning to Recombine and Resample Data for Compositional Generalization.]]: (cite: journals/corr/abs-2010-03706/Akyurek/2020) .  Proposes the R&R method, which learns a model of recombining samples into other samples by selecting "informative neighbours" as supports. [[papers/dl/compositional/learning_to_recombine_and_resample_data_for_compositional_generalization.md|Notes]]
 - [[pdfs/dl/compositional/locality_and_compositionality_in_zero_shot_learning.pdf|Locality and Compositionality in Zero-Shot Learning.]]: (cite: conf/iclr/SylvainPH20) Â Locality (learning small parts of the input) and compositionally (learning representations expressable as a function of a smaller vocabulary) are both deeply related to generalization. Encoders with a good understanding of the local information (parts F1 score) perform better in zero-shot learning  . [[papers/dl/compositional/locality_and_compositionality_in_zero_shot_learning.md|Notes]]
 - [[pdfs/dl/compositional/measuring_compositionality_in_representational_learning.pdf|Measuring Compositionality in Representation Learning.]]: (cite: conf/iclr/Andreas19) . Derive a new metric called TRE (Tree-reconstruction error). This measures the distance between approximation error of compositions of functions learned on primitives vs compositions of oracle functions. The paper shows that there's a relationship between TRE and mutual information between the model and the dataset, but then low TRE doesn't always mean good generalization (and good generalization does not always mean low TRE). [[papers/dl/compositional/measuring_compositionality_in_representational_learning.md|Notes]]
 - [[pdfs/dl/compositional/meta_learning_to_compositionally_generalize.pdf|Meta-Learning to Compositionally Generalize.]]: (cite: conf/acl/ConklinWST20) . They use MAML on SCAN and COGS. The meta-train and meta-test examples come by defining some distance metrics and then sampling similar examples. They say that learning model initializations that optimize in this way constrains you to solutions that generalize well. [[papers/dl/compositional/meta_learning_to_compositionally_generalize.md|Notes]]
 - [[pdfs/dl/compositional/meta_referential_games_to_learn_compositional_learning_behaviours.pdf|Meta-Referential Games to Learn Compositional Learning Behaviours.]]: (cite: journals/corr/abs-2207-08012/Denamganai/2022) . [[papers/dl/compositional/meta_referential_games_to_learn_compositional_learning_behaviours.md|Notes]]
 - [[pdfs/dl/compositional/obtaining_faithful_interpretations_from_compositional_neural_networks.pdf|Obtaining Faithful Interpretations from Compositional Neural Networks.]]: (cite: conf/acl/SubramanianBGWS20) . [[papers/dl/compositional/obtaining_faithful_interpretations_from_compositional_neural_networks.md|Notes]]
 - [[pdfs/dl/compositional/on_sample_efficiency_and_systematic_generalization_of_grounded_language_understanding_with_deep_learning.pdf|On Sample Efficiency and Systematic Generalization of Grounded Language Understanding with Deep Learning (PhD Thesis, Bahdanau)]]: . [[papers/dl/compositional/on_sample_efficiency_and_systematic_generalization_of_grounded_language_understanding_with_deep_learning.md|Notes]]
 - [[pdfs/dl/compositional/on_a_built_in_conflict_between_deep_learning_and_systematic_generalization.pdf|On a Built-in Conflict between Deep Learning and Systematic Generalization.]]: (cite: journals/corr/abs-2208-11633/Li/2022) The main hypothesis here is that function sharing is the issue. Deep learning prefers to learn a simpler function rather than one which requires more partitions of the input space. [[papers/dl/compositional/on_a_built_in_conflict_between_deep_learning_and_systematic_generalization.md|Notes]]
 - [[pdfs/dl/compositional/on_transfer_learning_using_a_mac_model_variant.pdf|On transfer learning using a MAC model variant.]]: (cite: journals/corr/abs-1811-06529/Marois/2018) . [[papers/dl/compositional/on_transfer_learning_using_a_mac_model_variant.md|Notes]]
 - [[pdfs/dl/compositional/reference_limited_compositional_zero_shot_learning.pdf|Reference-Limited Compositional Zero-Shot Learning.]]: (cite: journals/corr/abs-2208-10046/Huang/2022) . [[papers/dl/compositional/reference_limited_compositional_zero_shot_learning.md|Notes]]
 - [[pdfs/dl/compositional/structural_generalization_is_hard_for_sequence_to_sequence_models.pdf|Structural generalization is hard for sequence-to-sequence models.]]: (cite: journals/corr/abs-2210-13050/Yao/2022) . [[papers/dl/compositional/structural_generalization_is_hard_for_sequence_to_sequence_models.md|Notes]]
 - [[pdfs/dl/compositional/systematic_generalization_and_emergent_structures_in_transformers_trained_on_structured_tasks.pdf|Systematic Generalization and Emergent Structures in Transformers Trained on Structured Tasks.]]: (cite: journals/corr/abs-2210-00400/Li/2022) . They train a 2-layer transformer on a task where you have to copy/reverse/group-by/sort inputs. Interesting results are that in the latent space, you group the objects together according to what is required in the task description. Also there is a data augmentation method for length generalization, basically assign random monotonic time indices to sequence elements. [[papers/dl/compositional/systematic_generalization_and_emergent_structures_in_transformers_trained_on_structured_tasks.md|Notes]]
 - [[pdfs/dl/compositional/systematicity_emerges_in_transformers_when_abstract_grammatical_roles_guide_attention.pdf|Systematicity Emerges in Transformers when Abstract Grammatical Roles Guide Attention.]]: (cite: conf/naacl/ChakravarthyRO22) If you append the grammatical roles to tokens in SCAN, a transformer will learn to leverage them and generalize OOD. . [[papers/dl/compositional/systematicity_emerges_in_transformers_when_abstract_grammatical_roles_guide_attention.md|Notes]]
 - [[pdfs/dl/compositional/systematicity_in_a_recurrent_neural_network_by_factorizing_syntax_and_semantics.pdf|Systematicity in a Recurrent Neural Network by Factorizing Syntax and Semantics.]]: (cite: conf/cogsci/RussinJOB20) . [[papers/dl/compositional/systematicity_in_a_recurrent_neural_network_by_factorizing_syntax_and_semantics.md|Notes]]
 - [[pdfs/dl/compositional/transformers_generalize_differently_from_information_stored_in_context_vs_weights.pdf|Transformers generalize differently from information stored in context vs in weights.]]: (cite: journals/corr/abs-2210-05675/Chan/2022) . [[papers/dl/compositional/transformers_generalize_differently_from_information_stored_in_context_vs_weights.md|Notes]]
 - [[pdfs/dl/compositional/unlocking_compositional_generalization_in_pre_trained_models_using_intermediate_representations.pdf|Unlocking Compositional Generalization in Pre-trained Models Using Intermediate Representations.]]: (cite: journals/corr/abs-2104-07478/Herzig/2021) . [[papers/dl/compositional/unlocking_compositional_generalization_in_pre_trained_models_using_intermediate_representations.md|Notes]]
 - [[pdfs/dl/compositional/variable_compositionality_reliably_emerges_in_neural_networks.pdf|Variable Compositionality Reliably Emerges in Neural Networks]]: Relevant for when neural networks invent a language to communicate - how compositional are these languages? . [[papers/dl/compositional/variable_compositionality_reliably_emerges_in_neural_networks.md|Notes]]
 - [[pdfs/dl/compositional/composer_visually_grounded_concept_composition.pdf|Visually Grounded Concept Composition.]]: (cite: conf/emnlp/0002HQSS21) Introduces the Composer Architecture and "Concept and Relation Graph". The basic idea is to parse the query sentence into a parse tree and assign roles to each of the words in a dependency parse. Then you to a sort of "coarse-to-fine" process up the tree, combining the argument embeddings in each relation with each word matched with object detection features in the image. So for example "a bald man is standing by the beer pumps at the bar" would match "beer" and "pumps", then combine with "the (NN) (NN)" and match "the beer pumps" and so on until you get a final matching score. There are also some loss functions like "multi-scale visual alignment loss" (which computes the loss for each concept up the hierarchy with positive and negative examples) as well as an order-preserving loss, eg, coarser grained concepts should match the image less than finer-grained ones. The model does quite well on realistic out-of-distribution data, at least better than ViLBERT does, but there is still some room for improvement. [[papers/dl/compositional/composer_visually_grounded_concept_composition.md|Notes]]
 - [[pdfs/dl/compositional/zeroc_a_neuro_symbolic_model_for_zero_shot_concept_recognition_and_acquisition_at_inference_time.pdf|ZeroC: A Neuro-Symbolic Model for Zero-shot Concept Recognition and Acquisition at Inference Time.]]: (cite: journals/corr/abs-2206-15049/Wu/2022) . [[papers/dl/compositional/zeroc_a_neuro_symbolic_model_for_zero_shot_concept_recognition_and_acquisition_at_inference_time.md|Notes]]
 - [[pdfs/dl/compositional/compositional_generalization_through_abstract_representations_in_human_and_artificial_neural_networks.pdf|compositional_generalization_through_abstract_representations_in_human_and_artificial_neural_networks]]: . [[papers/dl/compositional/compositional_generalization_through_abstract_representations_in_human_and_artificial_neural_networks.md|Notes]]
 - [[pdfs/dl/compositional/compositionality_decomposed_neural_networks_generalize (1).pdf|compositionality_decomposed_neural_networks_generalize (1)]]: . [[papers/dl/compositional/compositionality_decomposed_neural_networks_generalize (1).md|Notes]]
### fewshot
 - [[pdfs/dl/compositional/fewshot/compositional_models_for_few_shot_sequence_learning.pdf|Compositional Models for Few-Shot Sequence Learning]]: . [[papers/dl/compositional/fewshot/compositional_models_for_few_shot_sequence_learning.md|Notes]]
 - [[pdfs/dl/compositional/fewshot/learning_compositional_representations_for_few_shot_recognition.pdf|Learning Compositional Representations for Few-Shot Recognition.]]: (cite: conf/iccv/TokmakovWH19) . [[papers/dl/compositional/fewshot/learning_compositional_representations_for_few_shot_recognition.md|Notes]]
## compression
### decomposition
 - [[pdfs/dl/compression/decomposition/powersgd_practical_low_rank_gradient_compression_for_distributed_optimization.pdf|PowerSGD: Practical Low-Rank Gradient Compression for Distributed Optimization.]]: (cite: conf/nips/VogelsKJ19) . [[papers/dl/compression/decomposition/powersgd_practical_low_rank_gradient_compression_for_distributed_optimization.md|Notes]]
 - [[pdfs/dl/compression/decomposition/on_low_rank_training_of_deep_neural_networks.pdf|on_low_rank_training_of_deep_neural_networks]]: . [[papers/dl/compression/decomposition/on_low_rank_training_of_deep_neural_networks.md|Notes]]
### pruning
 - [[pdfs/dl/compression/pruning/robustness_to_pruning_predicts_generalization_in_deep_neural_networks.pdf|Robustness to Pruning Predicts Generalization in Deep Neural Networks.]]: (cite: journals/corr/abs-2103-06002/Kuhn/2021) . [[papers/dl/compression/pruning/robustness_to_pruning_predicts_generalization_in_deep_neural_networks.md|Notes]]
 - [[pdfs/dl/compression/pruning/the_combinatorial_brain_surgeon_pruning_weights_that_cancel_one_another_in_neural_networks.pdf|The Combinatorial Brain Surgeon: Pruning Weights That Cancel One Another in Neural Networks.]]: (cite: conf/icml/0003SRZ22) . [[papers/dl/compression/pruning/the_combinatorial_brain_surgeon_pruning_weights_that_cancel_one_another_in_neural_networks.md|Notes]]
### quantization
 - [[pdfs/dl/compression/quantization/an_empirical_study_of_low_precision_quantization_for_tinyml.pdf|An Empirical Study of Low Precision Quantization for TinyML.]]: (cite: journals/corr/abs-2203-05492/Zhuo/2022) . [[papers/dl/compression/quantization/an_empirical_study_of_low_precision_quantization_for_tinyml.md|Notes]]
 - [[pdfs/dl/compression/quantization/is_integer_arithmetic_enough_for_deep_learning_training.pdf|Is Integer Arithmetic Enough for Deep Learning Training?]]: (cite: journals/corr/abs-2207-08822/Ghaffari/2022) . [[papers/dl/compression/quantization/is_integer_arithmetic_enough_for_deep_learning_training.md|Notes]]
 - [[pdfs/dl/compression/quantization/llm.int8_8_bit_matrix_multiplication_for_transformers_at_scale.pdf|LLM.int8(): 8-bit Matrix Multiplication for Transformers at Scale.]]: (cite: journals/corr/abs-2208-07339/Dettmers/2022) . [[papers/dl/compression/quantization/llm.int8_8_bit_matrix_multiplication_for_transformers_at_scale.md|Notes]]
 - [[pdfs/dl/compression/quantization/precision_machine_learning.pdf|Precision Machine Learning.]]: (cite: journals/corr/abs-2210-13447/Michaud/2022) . [[papers/dl/compression/quantization/precision_machine_learning.md|Notes]]
## contrastive
 - [[pdfs/dl/contrastive/simclr_contrastive_visual_rep.pdf|A Simple Framework for Contrastive Learning of Visual Representations.]]: (cite: conf/icml/ChenK0H20) SimCLR paper . [[papers/dl/contrastive/simclr_contrastive_visual_rep.md|Notes]]
 - [[pdfs/dl/contrastive/a_survey_on_contrastive_self_supervised_learning.pdf|A Survey on Contrastive Self-supervised Learning.]]: (cite: journals/corr/abs-2011-00362/Jaiswal/2020) . [[papers/dl/contrastive/a_survey_on_contrastive_self_supervised_learning.md|Notes]]
 - [[pdfs/dl/contrastive/barlow_twins_self_supervised_learning_via_redundancy_reduction.pdf|Barlow Twins: Self-Supervised Learning via Redundancy Reduction.]]: (cite: conf/icml/ZbontarJMLD21) . [[papers/dl/contrastive/barlow_twins_self_supervised_learning_via_redundancy_reduction.md|Notes]]
 - [[pdfs/dl/contrastive/big_self_supervised_strong_semi_supervised.pdf|Big Self-Supervised Models are Strong Semi-Supervised Learners.]]: (cite: conf/nips/ChenKSNH20) . [[papers/dl/contrastive/big_self_supervised_strong_semi_supervised.md|Notes]]
 - [[pdfs/dl/contrastive/data_determines_distributional_robustness_in_constrastive_language_image_pre_training.pdf|Data Determines Distributional Robustness in Contrastive Language Image Pre-training (CLIP).]]: (cite: conf/icml/FangIWWSDS22) The more diverse the training distribution, the more robust the model. [[papers/dl/contrastive/data_determines_distributional_robustness_in_constrastive_language_image_pre_training.md|Notes]]
 - [[pdfs/dl/contrastive/do_more_negative_samples_necessarily_hurt_in_contrastive_learning.pdf|Do More Negative Samples Necessarily Hurt in Contrastive Learning?]]: (cite: journals/corr/abs-2205-01789/Awasthi/2022) . [[papers/dl/contrastive/do_more_negative_samples_necessarily_hurt_in_contrastive_learning.md|Notes]]
 - [[pdfs/dl/contrastive/energy_based_contrastive_learning_of_visual_representations.pdf|Energy-Based Contrastive Learning of Visual Representations.]]: (cite: journals/corr/abs-2202-04933/Kim/2022) . [[papers/dl/contrastive/energy_based_contrastive_learning_of_visual_representations.md|Notes]]
 - [[pdfs/dl/contrastive/exploring_simple_siamese_representation_learning.pdf|Exploring Simple Siamese Representation Learning.]]: (cite: conf/cvpr/ChenH21) . [[papers/dl/contrastive/exploring_simple_siamese_representation_learning.md|Notes]]
 - [[pdfs/dl/contrastive/exploring_the_gap_between_collapsed_and_whitened_in_self_supervised_learning.pdf|Exploring the Gap between Collapsed &amp; Whitened Features in Self-Supervised Learning.]]: (cite: conf/icml/HeO22) . [[papers/dl/contrastive/exploring_the_gap_between_collapsed_and_whitened_in_self_supervised_learning.md|Notes]]
 - [[pdfs/dl/contrastive/how_much_can_clip_benefit_vision_and_language_tasks.pdf|How Much Can CLIP Benefit Vision-and-Language Tasks?]]: (cite: journals/corr/abs-2107-06383/Shen/2021) This paper studies the vision encoder in vision-and-language tasks (eg, image captioning, VLN, question answering). The encoder matters a lot. But one problem with clip is that you have shallow fusion (eg, the fusion happens at the end) and not deep fusion like other VQA models. So in this paper they use CLIP as the visual encoder. CLIP can be easily integrated into existing models and supports fast inference. CLIP can serve as a drop-in replacement on previous in-domain dependent encoders. [[papers/dl/contrastive/how_much_can_clip_benefit_vision_and_language_tasks.md|Notes]]
 - [[pdfs/dl/contrastive/investigating_why_constrative_learning_benefits_robustness_against_label_noise.pdf|Investigating Why Contrastive Learning Benefits Robustness Against Label Noise.]]: (cite: journals/corr/abs-2201-12498/Xue/2022) . [[papers/dl/contrastive/investigating_why_constrative_learning_benefits_robustness_against_label_noise.md|Notes]]
 - [[pdfs/dl/contrastive/clip_learning_transferable_visual_models_nl_supervision.pdf|Learning Transferable Visual Models From Natural Language Supervision.]]: (cite: conf/icml/RadfordKHRGASAM21) CLIP approach. Text/image encoder to vectors, take the outer product of the embeddings and do contrastive loss by bidirectional cross-entropy between elements on the diagonal and everything else. Then this can lead to zero-shot transfer for things like image classification, by measuring affinity with "image of a (cls)". [[papers/dl/contrastive/clip_learning_transferable_visual_models_nl_supervision.md|Notes]]
 - [[pdfs/dl/contrastive/learning_visual_features_from_large_weakly_supervised_data.pdf|Learning Visual Features from Large Weakly Supervised Data.]]: (cite: conf/eccv/JoulinMJV16) . [[papers/dl/contrastive/learning_visual_features_from_large_weakly_supervised_data.md|Notes]]
 - [[pdfs/dl/contrastive/learning_weakly_supervised_contrastive_representations.pdf|Learning Weakly-Supervised Contrastive Representations.]]: (cite: journals/corr/abs-2202-06670/Tsai/2022) Take for example images that have hashtags. These are additional but also noisy signals. Can they come above just regular old contrastive learning? In this paper, use it for clustering (Clsuter InfoCNE. Rank attributes by entropy and cluster data such that data within the same cluster as the same value of selected attributes). Then minimize cluster overlap using InfoNCE. Similar representations should come from data from similar clusters.  . [[papers/dl/contrastive/learning_weakly_supervised_contrastive_representations.md|Notes]]
 - [[pdfs/dl/contrastive/local_plasticity_rules_can_learn_deep_representations_using_self_supervised_contrastive_predictions.pdf|Local plasticity rules can learn deep representations using self-supervised contrastive predictions.]]: (cite: conf/nips/IllingVBG21) . [[papers/dl/contrastive/local_plasticity_rules_can_learn_deep_representations_using_self_supervised_contrastive_predictions.md|Notes]]
 - [[pdfs/dl/contrastive/masked_siamese_networks_for_label_efficient_learning.pdf|Masked Siamese Networks for Label-Efficient Learning.]]: (cite: journals/corr/abs-2204-07141/Assran/2022) . [[papers/dl/contrastive/masked_siamese_networks_for_label_efficient_learning.md|Notes]]
 - [[pdfs/dl/contrastive/metaug_contrastive_learning_via_meta_feature_agumentation.pdf|MetAug: Contrastive Learning via Meta Feature Augmentation.]]: (cite: conf/icml/LiQZ0X22) Meta-learning to augment the latent space during contrastive learning, as opposed to applying transform based augmentations . [[papers/dl/contrastive/metaug_contrastive_learning_via_meta_feature_agumentation.md|Notes]]
 - [[pdfs/dl/contrastive/momentum_contrast_for_unsupervised_visual_representation_learning.pdf|Momentum Contrast for Unsupervised Visual Representation Learning.]]: (cite: conf/cvpr/He0WXG20) . [[papers/dl/contrastive/momentum_contrast_for_unsupervised_visual_representation_learning.md|Notes]]
 - [[pdfs/dl/contrastive/multimodal_contrastive_learning_with_limoe_the_language_image_mixture_of_experts.pdf|Multimodal Contrastive Learning with LIMoE: the Language-Image Mixture of Experts.]]: (cite: journals/corr/abs-2206-02770/Mustafa/2022) . [[papers/dl/contrastive/multimodal_contrastive_learning_with_limoe_the_language_image_mixture_of_experts.md|Notes]]
 - [[pdfs/dl/contrastive/on_the_surrogate_gap_between_contrastive_and_supervised_losses.pdf|On the Surrogate Gap between Contrastive and Supervised Losses.]]: (cite: conf/icml/0002NN22) . [[papers/dl/contrastive/on_the_surrogate_gap_between_contrastive_and_supervised_losses.md|Notes]]
 - [[pdfs/dl/contrastive/contrastive_predictive_coding_infonce.pdf|Representation Learning with Contrastive Predictive Coding.]]: (cite: journals/corr/abs-1807-03748/Oord/2018) . [[papers/dl/contrastive/contrastive_predictive_coding_infonce.md|Notes]]
 - [[pdfs/dl/contrastive/robustness_verification_for_constrastive_learning.pdf|Robustness Verification for Contrastive Learning.]]: (cite: conf/icml/Wang022) . [[papers/dl/contrastive/robustness_verification_for_constrastive_learning.md|Notes]]
 - [[pdfs/dl/contrastive/scaling_up_visual_and_vision_language_representation_learning_noisy_text.pdf|Scaling Up Visual and Vision-Language Representation Learning With Noisy Text Supervision.]]: (cite: conf/icml/JiaYXCPPLSLD21) Like CLIP, but use a noisy dataset of images and alt texts, with some minimal filtering. [[papers/dl/contrastive/scaling_up_visual_and_vision_language_representation_learning_noisy_text.md|Notes]]
 - [[pdfs/dl/contrastive/the_close_relationship_between_contrastive_learning_and_meta_learning.pdf|The Close Relationship Between Contrastive Learning and Meta-Learning.]]: (cite: conf/iclr/NiSSGG22) In contrastive learning we have a 1-shot-b-way problem, eg, the labels are not fixed but are actually new targets every time. This is like meta-learning, where the task distribution shifts on every training instance. Or more precisely, one of the augmented views is the support and the other one is the query. You can in-fact apply meta-learning algorithms like ProtoNet here, where the augmented views make the support set, and then you have to get the query set correct, which is equivalent to contrastive learning. You can also boost SSL with meta-specific augmentations, eg, by having meta-augmentations. [[papers/dl/contrastive/the_close_relationship_between_contrastive_learning_and_meta_learning.md|Notes]]
 - [[pdfs/dl/contrastive/contrastive_representaiton_hypersphere.pdf|Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere.]]: (cite: conf/icml/0001I20) . [[papers/dl/contrastive/contrastive_representaiton_hypersphere.md|Notes]]
 - [[pdfs/dl/contrastive/byol_self_supervised_no_contrastive.pdf|Understanding self-supervised Learning Dynamics without Contrastive Pairs.]]: (cite: journals/corr/abs-2102-06810/Tian/2021) Explains why BYOL works the way it does . [[papers/dl/contrastive/byol_self_supervised_no_contrastive.md|Notes]]
 - [[pdfs/dl/contrastive/swav_unsupervised_learning_of_visual_features_by_contrasting_cluster_assignments.pdf|Unsupervised Learning of Visual Features by Contrasting Cluster Assignments.]]: (cite: conf/nips/CaronMMGBJ20) . [[papers/dl/contrastive/swav_unsupervised_learning_of_visual_features_by_contrasting_cluster_assignments.md|Notes]]
 - [[pdfs/dl/contrastive/vicreg_variance_invariance_covariance_regularization_for_self_supervised_learning.pdf|VICReg: Variance-Invariance-Covariance Regularization for Self-Supervised Learning.]]: (cite: journals/corr/abs-2105-04906/Bardes/2021) . [[papers/dl/contrastive/vicreg_variance_invariance_covariance_regularization_for_self_supervised_learning.md|Notes]]
 - [[pdfs/dl/contrastive/ermolov_whitening_ssl.pdf|Whitening for Self-Supervised Representation Learning.]]: (cite: conf/icml/ErmolovSSS21) . [[papers/dl/contrastive/ermolov_whitening_ssl.md|Notes]]
 - [[pdfs/dl/contrastive/a_little_help_from_my_friends_nearest_neighbour_contrastive_learning.pdf|With a Little Help from My Friends: Nearest-Neighbor Contrastive Learning of Visual Representations.]]: (cite: conf/iccv/DwibediATSZ21) . [[papers/dl/contrastive/a_little_help_from_my_friends_nearest_neighbour_contrastive_learning.md|Notes]]
 - [[pdfs/dl/contrastive/data2vec_a_general_framework_for_self_supervised_learning_in_speech_vision_and_language.pdf|data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language.]]: (cite: conf/icml/BaevskiHXBGA22) Self-supervised learning by predicting intermediate masked tokens on different layers of a transformer. [[papers/dl/contrastive/data2vec_a_general_framework_for_self_supervised_learning_in_speech_vision_and_language.md|Notes]]
 - [[pdfs/dl/contrastive/uniclip_unified_framework_for_contrastive_language_image_pretraining.pdf|uniclip_unified_framework_for_contrastive_language_image_pretraining]]: . [[papers/dl/contrastive/uniclip_unified_framework_for_contrastive_language_image_pretraining.md|Notes]]
## conv
 - [[pdfs/dl/conv/coord_conv.pdf|An intriguing failing of convolutional neural networks and the CoordConv solution.]]: (cite: conf/nips/LiuLMSFSY18) . [[papers/dl/conv/coord_conv.md|Notes]]
## disentanglement
 - [[pdfs/dl/disentanglement/beta_intact_vae_identifying_and_estimating_causal_effects_under_limited_overlap.pdf|$\beta$-Intact-VAE: Identifying and Estimating Causal Effects under Limited Overlap.]]: (cite: conf/iclr/WuF22) . [[papers/dl/disentanglement/beta_intact_vae_identifying_and_estimating_causal_effects_under_limited_overlap.md|Notes]]
 - [[pdfs/dl/disentanglement/a_framework_for_the_quantitative_evaluation_of_disentangled_representations.pdf|A Framework for the Quantitative Evaluation of Disentangled Representations.]]: (cite: conf/iclr/EastwoodW18) . [[papers/dl/disentanglement/a_framework_for_the_quantitative_evaluation_of_disentangled_representations.md|Notes]]
 - [[pdfs/dl/disentanglement/an_empirical_study_on_disentanglement_of_negative_free_contrastive_learning.pdf|An Empirical Study on Disentanglement of Negative-free Contrastive Learning.]]: (cite: journals/corr/abs-2206-04756/Cao/2022) . [[papers/dl/disentanglement/an_empirical_study_on_disentanglement_of_negative_free_contrastive_learning.md|Notes]]
 - [[pdfs/dl/disentanglement/challenging_assumptions_unsupervised_disentanglement.pdf|Challenging Common Assumptions in the Unsupervised Learning of Disentangled Representations.]]: (cite: conf/iclr/LocatelloBLRGSB19) Shows that learning disentangled representations is fundamentally impossible without inductive biases on both the models and the data . [[papers/dl/disentanglement/challenging_assumptions_unsupervised_disentanglement.md|Notes]]
 - [[pdfs/dl/disentanglement/compositional_generalization_in_unsupervised_compositional_representation_learning_a_study_on_disentanglement_and_emergent_language.pdf|Compositional Generalization in Unsupervised Compositional Representation Learning: A Study on Disentanglement and Emergent Language.]]: (cite: journals/corr/abs-2210-00482/Xu/2022) . [[papers/dl/disentanglement/compositional_generalization_in_unsupervised_compositional_representation_learning_a_study_on_disentanglement_and_emergent_language.md|Notes]]
 - [[pdfs/dl/disentanglement/deft_distilling_entangled_factors_by_preventing_information_diffusion.pdf|DEFT: distilling entangled factors by preventing information diffusion.]]: (cite: journals/ml/WuWYLLZ22) . [[papers/dl/disentanglement/deft_distilling_entangled_factors_by_preventing_information_diffusion.md|Notes]]
 - [[pdfs/dl/disentanglement/dissect_disentangled_simultaneous_explanations_via_concept_traversals.pdf|DISSECT - Disentangled Simultaneous Explanations via Concept Traversals.]]: (cite: journals/corr/abs-2105-15164/Ghandeharioun/2021) A single explanation is not enough, make a single framework that gives you multiple explanations for how you could move from one classification to another. For example with melanoma, not just making it bigger, but making it darker etc. Follows a GAN-based design, which a concept traversal disentangler element. Make sure that different explanation dimensions capture different things . [[papers/dl/disentanglement/dissect_disentangled_simultaneous_explanations_via_concept_traversals.md|Notes]]
 - [[pdfs/dl/disentanglement/disentangled_recurrent_wasserstein_autoencoder.pdf|Disentangled Recurrent Wasserstein Autoencoder.]]: (cite: conf/iclr/HanMHLZ21) . [[papers/dl/disentanglement/disentangled_recurrent_wasserstein_autoencoder.md|Notes]]
 - [[pdfs/dl/disentanglement/disentangled_variational_auto_encoder_for_semi_supervised_learning.pdf|Disentangled Variational Auto-Encoder for semi-supervised learning.]]: (cite: journals/isci/LiPWPYC19) . [[papers/dl/disentanglement/disentangled_variational_auto_encoder_for_semi_supervised_learning.md|Notes]]
 - [[pdfs/dl/disentanglement/disentanglement_and_generalization_under_correlation_shifts.pdf|Disentanglement and Generalization Under Correlation Shifts.]]: (cite: journals/corr/abs-2112-14754/Funke/2021) Studies the problem of disentanglement when you have correlated features. Starts with a simple case study, $x = As + n, s \sim (0, C_s), s \sim N(0, C_n)$, where $s$ are the generative facturesm $n$ is noise and $A$ is a mixing matrix. The optimal linear solution is not $A^{-1}$ as we'd expect, eg, you don't get disentanglement that way. If you try to fix this by penalizing unconditional mutual information, things get worse because the correlation between the generative factors and the noise is actually a predictive feature. The solution is to penalize *conditional* mutual information, eg $I(z_0, ..., z_k|s_j)$. because we can assume that the latent factors are independent once we know something about one of the generative factors (eg, knowing $s_j$ means that $z_{k}$ does not tell us any more about $z_i$). Then the authors provide a mechanism to try and extend this idea to a training process, by taking two samples with a shared generative factor, then shuffling the latents for all the other latent variables and discriminating between the true and shuffled cases. [[papers/dl/disentanglement/disentanglement_and_generalization_under_correlation_shifts.md|Notes]]
 - [[pdfs/dl/disentanglement/disentangling_autoencoders.pdf|Disentangling Autoencoders (DAE).]]: (cite: journals/corr/abs-2202-09926/Cha/2022) . [[papers/dl/disentanglement/disentangling_autoencoders.md|Notes]]
 - [[pdfs/dl/disentanglement/factor_vae.pdf|Disentangling by Factorising.]]: (cite: conf/icml/KimM18) Proposes FactorVAE, a method to disentangle by permuting sampled latents from the encoder across the batch dimension and fooling a discriminator into thinking that they're the same. This promotes independence between the latent factors. [[papers/dl/disentanglement/factor_vae.md|Notes]]
 - [[pdfs/dl/disentanglement/disentangling_by_subspace_diffusion.pdf|Disentangling by Subspace Diffusion.]]: (cite: conf/nips/PfauHBR20) . [[papers/dl/disentanglement/disentangling_by_subspace_diffusion.md|Notes]]
 - [[pdfs/dl/disentanglement/beta_tcvae.pdf|Isolating Sources of Disentanglement in VAEs]]: Introduces the Beta-TCVAE architecture . [[papers/dl/disentanglement/beta_tcvae.md|Notes]]
 - [[pdfs/dl/disentanglement/monet_unsupervised_scene_decomposition_representation.pdf|MONet: Unsupervised Scene Decomposition and Representation.]]: (cite: journals/corr/abs-1901-11390/Burgess/2019) . [[papers/dl/disentanglement/monet_unsupervised_scene_decomposition_representation.md|Notes]]
 - [[pdfs/dl/disentanglement/multi_objective_deep_data_generation_with_correlated_property_control.pdf|Multi-objective Deep Data Generation with Correlated Property Control.]]: (cite: journals/corr/abs-2210-01796/Wang/2022) . [[papers/dl/disentanglement/multi_objective_deep_data_generation_with_correlated_property_control.md|Notes]]
 - [[pdfs/dl/disentanglement/trauble_on_disentangled_representations_learned_from_correlated_data.pdf|On Disentangled Representations Learned from Correlated Data.]]: (cite: conf/icml/TraubleCKLDGSB21) Experimental training setups for disentanglement are far too idealistic, since typically you observe all combinations of factors of variation. Realistic datasets have correlations between factors of variation. This work performs a large scale empirical investigation as to whether current disentanglement methods can still learn good representations when the dataset is correlated. Weaker correlations are easier to disentangle. It may be possible to resolve latent entanglement post-hoc by predicting ground truth labels from entangled dimensions using a few examples. [[papers/dl/disentanglement/trauble_on_disentangled_representations_learned_from_correlated_data.md|Notes]]
 - [[pdfs/dl/disentanglement/on_disentangled_representations_learned_from_correlated_data.pdf|On Disentangled Representations Learned from Correlated Data.]]: (cite: conf/icml/TraubleCKLDGSB21) . [[papers/dl/disentanglement/on_disentangled_representations_learned_from_correlated_data.md|Notes]]
 - [[pdfs/dl/disentanglement/disentangled_representations_correlated_data.pdf|On Disentangled Representations Learned from Correlated Data.]]: (cite: conf/icml/TraubleCKLDGSB21) . [[papers/dl/disentanglement/disentangled_representations_correlated_data.md|Notes]]
 - [[pdfs/dl/disentanglement/on_the_transfer_of_disentangled_representations_in_realistic_settings.pdf|On the Transfer of Disentangled Representations in Realistic Settings.]]: (cite: conf/iclr/DittadiTLWAWBS21) . [[papers/dl/disentanglement/on_the_transfer_of_disentangled_representations_in_realistic_settings.md|Notes]]
 - [[pdfs/dl/disentanglement/progressive_hierarchical_disentanglement.pdf|Progressive Learning and Disentanglement of Hierarchical Representations.]]: (cite: conf/iclr/0007MGW20) . [[papers/dl/disentanglement/progressive_hierarchical_disentanglement.md|Notes]]
 - [[pdfs/dl/disentanglement/bengio_representation_learning_review_new_perspectives.pdf|Representation Learning: A Review and New Perspectives.]]: (cite: journals/pami/BengioCV13) . [[papers/dl/disentanglement/bengio_representation_learning_review_new_perspectives.md|Notes]]
 - [[pdfs/dl/disentanglement/sbd_spatial_broadcast_decoder_vae_disentanglement.pdf|Spatial Broadcast Decoder: A Simple Architecture for Learning Disentangled Representations in VAEs.]]: (cite: journals/corr/abs-1901-07017/Watters/2019) . [[papers/dl/disentanglement/sbd_spatial_broadcast_decoder_vae_disentanglement.md|Notes]]
 - [[pdfs/dl/disentanglement/sbd_symmetry_based_disentangled_representation_interaction.pdf|Symmetry-Based Disentangled Representation Learning requires Interaction with Environments.]]: (cite: conf/nips/Caselles-DupreO19) . [[papers/dl/disentanglement/sbd_symmetry_based_disentangled_representation_interaction.md|Notes]]
 - [[pdfs/dl/disentanglement/the_role_of_disentanglement_in_generalisation.pdf|The role of Disentanglement in Generalisation.]]: (cite: conf/iclr/MonteroLCMB21) . [[papers/dl/disentanglement/the_role_of_disentanglement_in_generalisation.md|Notes]]
 - [[pdfs/dl/disentanglement/nonlinear_disentanglement_temporal_sparse_coding.pdf|Towards Nonlinear Disentanglement in Natural Data with Temporal Sparse Coding.]]: (cite: conf/iclr/KlindtSSUBBP21) . [[papers/dl/disentanglement/nonlinear_disentanglement_temporal_sparse_coding.md|Notes]]
 - [[pdfs/dl/disentanglement/definition_disentanglement.pdf|Towards a Definition of Disentangled Representations.]]: (cite: journals/corr/abs-1812-02230/Higgins/2018) . [[papers/dl/disentanglement/definition_disentanglement.md|Notes]]
 - [[pdfs/dl/disentanglement/understanding_disentanglement_beta_vae.pdf|Understanding disentangling in $beta$-VAE]]: . [[papers/dl/disentanglement/understanding_disentanglement_beta_vae.md|Notes]]
 - [[pdfs/dl/disentanglement/udr_unsupervised_model_selection_for_variational_disentangled_representation_learning.pdf|Unsupervised Model Selection for Variational Disentangled Representation Learning.]]: (cite: conf/iclr/DuanMSWBLH20) . [[papers/dl/disentanglement/udr_unsupervised_model_selection_for_variational_disentangled_representation_learning.md|Notes]]
 - [[pdfs/dl/disentanglement/model_selection_vae_disentanglement.pdf|Unsupervised Model Selection for Variational Disentangled Representation Learning.]]: (cite: conf/iclr/DuanMSWBLH20) Introduces "Unsupervised Disentanglement Ranking" (UDR) to quantify the quality of disentanglement by performing pairwise comparisons between model representations . [[papers/dl/disentanglement/model_selection_vae_disentanglement.md|Notes]]
 - [[pdfs/dl/disentanglement/unsupervised_model_selection_for_variational_disentangled_representation_learning.pdf|Unsupervised Model Selection for Variational Disentangled Representation Learning.]]: (cite: conf/iclr/DuanMSWBLH20) . [[papers/dl/disentanglement/unsupervised_model_selection_for_variational_disentangled_representation_learning.md|Notes]]
 - [[pdfs/dl/disentanglement/vae_does_pca_by_accident.pdf|Variational Autoencoders Pursue PCA Directions (by Accident).]]: (cite: conf/cvpr/RolinekZM19) . [[papers/dl/disentanglement/vae_does_pca_by_accident.md|Notes]]
 - [[pdfs/dl/disentanglement/visual_concepts_tokenization.pdf|Visual Concepts Tokenization.]]: (cite: journals/corr/abs-2205-10093/Yang/2022) . [[papers/dl/disentanglement/visual_concepts_tokenization.md|Notes]]
 - [[pdfs/dl/disentanglement/weak_supervised_disentanglement_guarantees.pdf|Weakly Supervised Disentanglement with Guarantees.]]: (cite: conf/iclr/ShuCKEP20) . [[papers/dl/disentanglement/weak_supervised_disentanglement_guarantees.md|Notes]]
 - [[pdfs/dl/disentanglement/weakly_supervised_disentanglement.pdf|Weakly-Supervised Disentanglement Without Compromises.]]: (cite: conf/icml/LocatelloPRSBT20) Locatello's 'AdaGVAE' paper. [[papers/dl/disentanglement/weakly_supervised_disentanglement.md|Notes]]
 - [[pdfs/dl/disentanglement/beta_vae_learning_basic_visual_concepts_with_a_constrained_variational_framework.pdf|beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework.]]: (cite: conf/iclr/HigginsMPBGBML17) . [[papers/dl/disentanglement/beta_vae_learning_basic_visual_concepts_with_a_constrained_variational_framework.md|Notes]]
 - [[pdfs/dl/disentanglement/lost_in_latent_space_examining_failures_of_disentangled_models_at_combinatorial_generalisation.pdf|lost_in_latent_space_examining_failures_of_disentangled_models_at_combinatorial_generalisation]]: . [[papers/dl/disentanglement/lost_in_latent_space_examining_failures_of_disentangled_models_at_combinatorial_generalisation.md|Notes]]
### vqvae
 - [[pdfs/dl/disentanglement/vqvae/discrete_valued_neural_communication_in_structured_architectures_enhances_generalization.pdf|Discrete-Valued Neural Communication in Structured Architectures Enhances Generalization]]: The nature of structured models is that you have communiation among components with a bottleneck. In this work, tighten the bottleneck using discreteness and a VQ-VAE. They do multi-headed discreteness with shared codebooks. Discrete Valued Neural Communication substantially improves systematic generalization in variety of architectures, eg, transformers, modular architectures, GNNs, etc. The basic idea is that you introduce a discrete latent space vector (eg, an L-way categorical variable), so you quantise and concatenate the results for each âheadâ of some continuous vector in a feedforward network (eg, $h \to s_0, â¦, s_G, s_i \in \mathbb{R}^{m/G}$). Each segment is discretized by picking the closest neighbour in the codebook. Its basically VQ-VAE for anything. They get good OOD performance on sort-of-CLEVR, movement prediction in Atari, grid-world object movement prediction (OOD is that there are five objects in training, three objects in OOD-1 and two objects in OOD-2), 3-body physics object movement prediction (OOD ball sizes). [[papers/dl/disentanglement/vqvae/discrete_valued_neural_communication_in_structured_architectures_enhances_generalization.md|Notes]]
 - [[pdfs/dl/disentanglement/vqvae/vq_vae.pdf|Neural Discrete Representation Learning.]]: (cite: conf/nips/OordVK17) . [[papers/dl/disentanglement/vqvae/vq_vae.md|Notes]]
 - [[pdfs/dl/disentanglement/vqvae/vqvae_training.pdf|Robust Training of Vector Quantized Bottleneck Models.]]: (cite: conf/ijcnn/LancuckiCSMCDKA20) . [[papers/dl/disentanglement/vqvae/vqvae_training.md|Notes]]
## energy
 - [[pdfs/dl/energy/energy_based_out_of_distribution_detection.pdf|Energy-based Out-of-distribution Detection.]]: (cite: conf/nips/LiuWOL20) . [[papers/dl/energy/energy_based_out_of_distribution_detection.md|Notes]]
 - [[pdfs/dl/energy/learning_iterative_reasoning_through_energy_minimization.pdf|Learning Iterative Reasoning through Energy Minimization.]]: (cite: conf/icml/DuLTM22) . [[papers/dl/energy/learning_iterative_reasoning_through_energy_minimization.md|Notes]]
## ensembling
 - [[pdfs/dl/ensembling/composing_ensembles_of_pretrained_models_via_iterative_consensus.pdf|composing_ensembles_of_pretrained_models_via_iterative_consensus]]: . [[papers/dl/ensembling/composing_ensembles_of_pretrained_models_via_iterative_consensus.md|Notes]]
## generalization
 - [[pdfs/dl/generalization/a_study_of_compositional_generalization_in_neural_networks.pdf|A Study of Compositional Generalization in Neural Models.]]: (cite: journals/corr/abs-2006-09437/Klinger/2020) . [[papers/dl/generalization/a_study_of_compositional_generalization_in_neural_networks.md|Notes]]
 - [[pdfs/dl/generalization/adversarial_multiple_source_domain_adaptation.pdf|Adversarial Multiple Source Domain Adaptation.]]: (cite: conf/nips/ZhaoZWMCG18) . [[papers/dl/generalization/adversarial_multiple_source_domain_adaptation.md|Notes]]
 - [[pdfs/dl/generalization/assaying_out_of_distribution_generalization_in_transfer_learning.pdf|Assaying Out-Of-Distribution Generalization in Transfer Learning.]]: (cite: journals/corr/abs-2207-09239/Wenzel/2022) . [[papers/dl/generalization/assaying_out_of_distribution_generalization_in_transfer_learning.md|Notes]]
 - [[pdfs/dl/generalization/bag_of_tricks_for_out_of_distribution_generalization.pdf|Bag of Tricks for Out-of-Distribution Generalization.]]: (cite: journals/corr/abs-2208-10722/Chen/2022) . Uses multi-objective learning, cutup, mixup, label smoothing and some data augmentation to do well on OOD CV tasks. [[papers/dl/generalization/bag_of_tricks_for_out_of_distribution_generalization.md|Notes]]
 - [[pdfs/dl/generalization/certifying_out_of_domain_generalization_for_blackblox_functions.pdf|Certifying Out-of-Domain Generalization for Blackbox Functions.]]: (cite: conf/icml/WeberLWZ0022) . [[papers/dl/generalization/certifying_out_of_domain_generalization_for_blackblox_functions.md|Notes]]
 - [[pdfs/dl/generalization/characterizing_structural_regularities_of_labeled_data_in_overparameterized_models.pdf|Characterizing Structural Regularities of Labeled Data in Overparameterized Models.]]: (cite: conf/icml/JiangZTM21) . [[papers/dl/generalization/characterizing_structural_regularities_of_labeled_data_in_overparameterized_models.md|Notes]]
 - [[pdfs/dl/generalization/diverse_weight_averaging_for_out_of_distribution_generalization.pdf|Diverse Weight Averaging for Out-of-Distribution Generalization.]]: (cite: journals/corr/abs-2205-09739/Rame/2022) . [[papers/dl/generalization/diverse_weight_averaging_for_out_of_distribution_generalization.md|Notes]]
 - [[pdfs/dl/generalization/domain_adversarial_training_of_neural_networks.pdf|Domain-Adversarial Training of Neural Networks.]]: (cite: series/acvpr/GaninUAGLLML17) . [[papers/dl/generalization/domain_adversarial_training_of_neural_networks.md|Notes]]
 - [[pdfs/dl/generalization/evaluation_models_local_decision_boundaries_via_contrast_sets.pdf|Evaluating Models&apos; Local Decision Boundaries via Contrast Sets.]]: (cite: conf/emnlp/0001ABBBCDDEGGH20) Recommendation that dataset authors perturb test instances in small ways to check if the model is doing well on a test example by chance. [[papers/dl/generalization/evaluation_models_local_decision_boundaries_via_contrast_sets.md|Notes]]
 - [[pdfs/dl/generalization/generalization_without_systematicity_on_the_compositional_skills_of_sequence_to_sequence_rnns.pdf|Generalization without Systematicity - On the Compositional Skills of Sequence-to-Sequence Recurrent Networks.]]: (cite: conf/icml/LakeB18) . The paper that presents SCAN . [[papers/dl/generalization/generalization_without_systematicity_on_the_compositional_skills_of_sequence_to_sequence_rnns.md|Notes]]
 - [[pdfs/dl/generalization/improving_out_of_distribution_robustness_via_selective_augmentation.pdf|Improving Out-of-Distribution Robustness via Selective Augmentation.]]: (cite: conf/icml/Yao0LZL0F22) Mixup-based technique called LISA. Sample with either the same labels but different domain, or same domain but different labels. [[papers/dl/generalization/improving_out_of_distribution_robustness_via_selective_augmentation.md|Notes]]
 - [[pdfs/dl/generalization/in_search_of_lost_domain_generalization.pdf|In Search of Lost Domain Generalization.]]: (cite: conf/iclr/GulrajaniL21) . [[papers/dl/generalization/in_search_of_lost_domain_generalization.md|Notes]]
 - [[pdfs/dl/generalization/is_out_of_distribution_detection_learnable.pdf|Is Out-of-Distribution Detection Learnable?]]: (cite: journals/corr/abs-2210-14707/Fang/2022) . [[papers/dl/generalization/is_out_of_distribution_detection_learnable.md|Notes]]
 - [[pdfs/dl/generalization/linear_connectivity_reveals_genearlization_strategies.pdf|Linear Connectivity Reveals Generalization Strategies.]]: (cite: journals/corr/abs-2205-12411/Juneja/2022) . [[papers/dl/generalization/linear_connectivity_reveals_genearlization_strategies.md|Notes]]
 - [[pdfs/dl/generalization/modeling_the_data_generating_process_is_necessary_for_out_of_distribution_generalization.pdf|Modeling the Data-Generating Process is Necessary for Out-of-Distribution Generalization.]]: (cite: journals/corr/abs-2206-07837/Kaur/2022) . [[papers/dl/generalization/modeling_the_data_generating_process_is_necessary_for_out_of_distribution_generalization.md|Notes]]
 - [[pdfs/dl/generalization/predicting_out_of_domain_generalization_with_local_manifold_smoothness.pdf|Predicting Out-of-Domain Generalization with Local Manifold Smoothness.]]: (cite: journals/corr/abs-2207-02093/Ng/2022) . The idea here is to see how the classifier does at distance $r$ around some test datapoint, if there is smoothness (eg, you stay in the same class at distance $r$) then your generalization will probably be better. They also demonstrate that there's such a correlation.  [[papers/dl/generalization/predicting_out_of_domain_generalization_with_local_manifold_smoothness.md|Notes]]
 - [[pdfs/dl/generalization/systematic_generalisation_with_group_invariant_predictions.pdf|Systematic generalisation with group invariant predictions.]]: (cite: conf/iclr/AhmedBSC21) . [[papers/dl/generalization/systematic_generalisation_with_group_invariant_predictions.md|Notes]]
 - [[pdfs/dl/generalization/test_test_time_self_training_under_distribution_shift.pdf|Test-Time Training with Self-Supervision for Generalization under Distribution Shifts.]]: (cite: conf/icml/SunWLMEH20) . [[papers/dl/generalization/test_test_time_self_training_under_distribution_shift.md|Notes]]
 - [[pdfs/dl/generalization/pitfalls_of_simplicity_bias_in_neural_networks.pdf|The Pitfalls of Simplicity Bias in Neural Networks.]]: (cite: conf/nips/ShahTR0N20) . [[papers/dl/generalization/pitfalls_of_simplicity_bias_in_neural_networks.md|Notes]]
 - [[pdfs/dl/generalization/the_value_of_out_of_distribution_data.pdf|The Value of Out-of-Distribution Data.]]: (cite: journals/corr/abs-2208-10967/Silva/2022) . Adding OOD data to training does not always improve performance on OOD. You need to have the correct sampling procedure . [[papers/dl/generalization/the_value_of_out_of_distribution_data.md|Notes]]
 - [[pdfs/dl/generalization/towards_understanding_how_momentum_improves_generalization_in_deep_learning.pdf|Towards understanding how momentum improves generalization in deep learning.]]: (cite: conf/icml/JelassiL22) . [[papers/dl/generalization/towards_understanding_how_momentum_improves_generalization_in_deep_learning.md|Notes]]
 - [[pdfs/dl/generalization/underspecification_presents_challenges_for_credibility_in_modern_machine_learning.pdf|Underspecification Presents Challenges for Credibility in Modern Machine Learning.]]: (cite: journals/corr/abs-2011-03395/D&apos;Amour/2020) . [[papers/dl/generalization/underspecification_presents_challenges_for_credibility_in_modern_machine_learning.md|Notes]]
 - [[pdfs/dl/generalization/understanding_the_failure_modes_of_out_of_distribution_generalization.pdf|Understanding the Failure Modes of Out-of-Distribution Generalization.]]: (cite: journals/corr/abs-2010-15775/Nagarajan/2020) There are two explanations for why classifiers rely on spuriously correlated feautres and fail out of distribution. The first view is the statistical one, which says that if the invariant feature is not fully predictive, then the bayes-optimal classifier will necessarily rely on spuriously correlated features to get a better result. But even if the invariant feature *is* fully predictive, classifiers tend to rely on these sorts of spurious correlations anyway. This reliance goes away over time in the limit of gradient descent, but there is another failure mode, geometric, that doesn't, becuase of non-trivial geometry. [[papers/dl/generalization/understanding_the_failure_modes_of_out_of_distribution_generalization.md|Notes]]
## generative
 - [[pdfs/dl/generative/argmax_flows_and_multinomial_diffusion_learning_categorical_distributions.pdf|Argmax Flows and Multinomial Diffusion: Learning Categorical Distributions.]]: (cite: conf/nips/HoogeboomNJFW21) . [[papers/dl/generative/argmax_flows_and_multinomial_diffusion_learning_categorical_distributions.md|Notes]]
 - [[pdfs/dl/generative/nash_generating_images_sparse_representations.pdf|Generating images with sparse representations.]]: (cite: conf/icml/NashMDB21) . [[papers/dl/generative/nash_generating_images_sparse_representations.md|Notes]]
 - [[pdfs/dl/generative/generative_imagination_object_world_models.pdf|Improving Generative Imagination in Object-Centric World Models.]]: (cite: conf/icml/LinWPFJA20) . [[papers/dl/generative/generative_imagination_object_world_models.md|Notes]]
 - [[pdfs/dl/generative/adversarial_feature_learning.pdf|Learning Discriminative Features for Adversarial Robustness.]]: (cite: conf/msn/HoslerPYSZL21) . [[papers/dl/generative/adversarial_feature_learning.md|Notes]]
 - [[pdfs/dl/generative/mixup_resynthesis.pdf|On Adversarial Mixup Resynthesis.]]: (cite: conf/nips/BeckhamHVLGHBP19) . [[papers/dl/generative/mixup_resynthesis.md|Notes]]
 - [[pdfs/dl/generative/vqgan_clip_open_domain_image_generation_and_editing_with_natural_language_guidance.pdf|VQGAN-CLIP: Open Domain Image Generation and Editing with Natural Language Guidance.]]: (cite: journals/corr/abs-2204-08583/Crowson/2022) . [[papers/dl/generative/vqgan_clip_open_domain_image_generation_and_editing_with_natural_language_guidance.md|Notes]]
### autoregressive
 - [[pdfs/dl/generative/autoregressive/pixelcnn.pdf|Conditional Image Generation with PixelCNN Decoders.]]: (cite: conf/nips/OordKEKVG16) . [[papers/dl/generative/autoregressive/pixelcnn.md|Notes]]
 - [[pdfs/dl/generative/autoregressive/taming_transformers_for_high_resolution_image_synthesis.pdf|Taming Transformers for High-Resolution Image Synthesis.]]: (cite: conf/cvpr/EsserRO21) . [[papers/dl/generative/autoregressive/taming_transformers_for_high_resolution_image_synthesis.md|Notes]]
### dae
 - [[pdfs/dl/generative/dae/what_regularized_auto_encoders_learn_from_the_data_generating_distribution.pdf|What regularized auto-encoders learn from the data-generating distribution.]]: (cite: journals/jmlr/AlainB14) . [[papers/dl/generative/dae/what_regularized_auto_encoders_learn_from_the_data_generating_distribution.md|Notes]]
### diffusion
 - [[pdfs/dl/generative/diffusion/a_continuous_time_framework_for_discrete_denoising_models.pdf|A Continuous Time Framework for Discrete Denoising Models.]]: (cite: journals/corr/abs-2205-14987/Campbell/2022) . [[papers/dl/generative/diffusion/a_continuous_time_framework_for_discrete_denoising_models.md|Notes]]
 - [[pdfs/dl/generative/diffusion/analog_bits_generating_discrete_data_using_diffusion_models_with_self_conditioning.pdf|Analog Bits: Generating Discrete Data using Diffusion Models with Self-Conditioning.]]: (cite: journals/corr/abs-2208-04202/Chen/2022) . [[papers/dl/generative/diffusion/analog_bits_generating_discrete_data_using_diffusion_models_with_self_conditioning.md|Notes]]
 - [[pdfs/dl/generative/diffusion/autoregressive_diffusion_model.pdf|Autoregressive Diffusion Models.]]: (cite: journals/corr/abs-2110-02037/Hoogeboom/2021) Leverages [[d3pm_structured_denoising_diffusion_models_in_discrete_state_spaces]] and [[argmax_flows_and_multinomial_diffusion_learning_categorical_distributions]] to provide a model class of order-agnostic autoregressive models. Does not require causla masking of model representations and supports parallel generation. It seems as though it can be trained as a "collection of D BERTs" with appropriate loss-reweighting terms. They are equivalent to absorbing diffusion in the infinite limit. [[papers/dl/generative/diffusion/autoregressive_diffusion_model.md|Notes]]
 - [[pdfs/dl/generative/diffusion/concrete_score_matching_generalized_score_matching_for_discrete_data.pdf|Concrete Score Matching: Generalized Score Matching for Discrete Data.]]: (cite: journals/corr/abs-2211-00802/Meng/2022) . [[papers/dl/generative/diffusion/concrete_score_matching_generalized_score_matching_for_discrete_data.md|Notes]]
 - [[pdfs/dl/generative/diffusion/d2c_diffusion_decoding_models_for_few_shot_conditional_generation.pdf|D2C: Diffusion-Decoding Models for Few-Shot Conditional Generation.]]: (cite: conf/nips/SinhaSME21) . [[papers/dl/generative/diffusion/d2c_diffusion_decoding_models_for_few_shot_conditional_generation.md|Notes]]
 - [[pdfs/dl/generative/diffusion/deep_unsupervised_learning_using_nonequilibrium_thermodynamics.pdf|Deep Unsupervised Learning using Nonequilibrium Thermodynamics.]]: (cite: conf/icml/Sohl-DicksteinW15) Original diffusion paper  . [[papers/dl/generative/diffusion/deep_unsupervised_learning_using_nonequilibrium_thermodynamics.md|Notes]]
 - [[pdfs/dl/generative/diffusion/denoising_diffusion_implicit_models.pdf|Denoising Diffusion Implicit Models.]]: (cite: conf/iclr/SongME21) . [[papers/dl/generative/diffusion/denoising_diffusion_implicit_models.md|Notes]]
 - [[pdfs/dl/generative/diffusion/denoising_diffusion_probabilistic_models.pdf|Denoising Diffusion Probabilistic Models.]]: (cite: conf/nips/HoJA20) . [[papers/dl/generative/diffusion/denoising_diffusion_probabilistic_models.md|Notes]]
 - [[pdfs/dl/generative/diffusion/denoising_diffusion_restoration_models.pdf|Denoising Diffusion Restoration Models.]]: (cite: journals/corr/abs-2201-11793/Kawar/2022) . [[papers/dl/generative/diffusion/denoising_diffusion_restoration_models.md|Notes]]
 - [[pdfs/dl/generative/diffusion/diffwave_a_versatile_diffusion_model_for_audio_synthesis.pdf|DiffWave - A Versatile Diffusion Model for Audio Synthesis.]]: (cite: conf/iclr/KongPHZC21) . Presents a diffusion-based model for synthesizing audio both conditional and unconditional. Unlike other models like WaveNet, it does not synthesize autoregressively. Rather it uses a diffusion approach - you have a diffusion process which converts an audio sample to noise and then learn the reversing process; going from noise back to that audio. The approach uses some recent advances in diffusion research to optimize the training of the lower bound plus an architecture with bidirectional dilated convolutions to presumably do refinement at different frequency bands . [[papers/dl/generative/diffusion/diffwave_a_versatile_diffusion_model_for_audio_synthesis.md|Notes]]
 - [[pdfs/dl/generative/diffusion/diffusion_models_beat_gan_on_image_synthesis.pdf|Diffusion Models Beat GANs on Image Synthesis.]]: (cite: journals/corr/abs-2105-05233/Dhariwal/2021) Some small changes to diffusion models can beat GAN models on image synthesis tasks (eg, U-Net, adaptive group normalization, conditioning on the gradients of a classifier, conditional reverse noising). [[papers/dl/generative/diffusion/diffusion_models_beat_gan_on_image_synthesis.md|Notes]]
 - [[pdfs/dl/generative/diffusion/diffusion_models_a_comprehensive_survey_of_methods_and_applications.pdf|Diffusion Models: A Comprehensive Survey of Methods and Applications.]]: (cite: journals/corr/abs-2209-00796/Yang/2022) . [[papers/dl/generative/diffusion/diffusion_models_a_comprehensive_survey_of_methods_and_applications.md|Notes]]
 - [[pdfs/dl/generative/diffusion/diffusion_posterior_sampling_for_general_noisy_inverse_problems.pdf|Diffusion Posterior Sampling for General Noisy Inverse Problems.]]: (cite: journals/corr/abs-2209-14687/Chung/2022) . [[papers/dl/generative/diffusion/diffusion_posterior_sampling_for_general_noisy_inverse_problems.md|Notes]]
 - [[pdfs/dl/generative/diffusion/diffusion_models_as_plug_and_play_priors.pdf|Diffusion models as plug-and-play priors.]]: (cite: journals/corr/abs-2206-09012/Graikos/2022) . [[papers/dl/generative/diffusion/diffusion_models_as_plug_and_play_priors.md|Notes]]
 - [[pdfs/dl/generative/diffusion/diffusionclip_text_guided_diffusion_models_for_robust_image_manipulation.pdf|DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation.]]: (cite: conf/cvpr/KimKY22a) . [[papers/dl/generative/diffusion/diffusionclip_text_guided_diffusion_models_for_robust_image_manipulation.md|Notes]]
 - [[pdfs/dl/generative/diffusion/elucidating_the_design_space_of_diffusion_based_generative_models.pdf|Elucidating the Design Space of Diffusion-Based Generative Models.]]: (cite: journals/corr/abs-2206-00364/Karras/2022) . [[papers/dl/generative/diffusion/elucidating_the_design_space_of_diffusion_based_generative_models.md|Notes]]
 - [[pdfs/dl/generative/diffusion/few_shot_diffusion_models.pdf|Few-Shot Diffusion Models.]]: (cite: journals/corr/abs-2205-15463/Giannone/2022) . [[papers/dl/generative/diffusion/few_shot_diffusion_models.md|Notes]]
 - [[pdfs/dl/generative/diffusion/flexible_diffusion_modeling_of_long_videos.pdf|Flexible Diffusion Modeling of Long Videos.]]: (cite: journals/corr/abs-2205-11495/Harvey/2022) . [[papers/dl/generative/diffusion/flexible_diffusion_modeling_of_long_videos.md|Notes]]
 - [[pdfs/dl/generative/diffusion/glide_towards_photorealistic_image_generation_and_editing_with_text_guided_diffusion_models.pdf|GLIDE - Towards Photorealistic Image Generation and Editing with Text-Guided Diffusion Models.]]: (cite: journals/corr/abs-2112-10741/Nichol/2021) . [[papers/dl/generative/diffusion/glide_towards_photorealistic_image_generation_and_editing_with_text_guided_diffusion_models.md|Notes]]
 - [[pdfs/dl/generative/diffusion/geodiff_a_geometric_diffusion_model_for_molecular_conformation_generation.pdf|GeoDiff: a Geometric Diffusion Model for Molecular Conformation Generation.]]: (cite: journals/corr/abs-2203-02923/Xu/2022) . [[papers/dl/generative/diffusion/geodiff_a_geometric_diffusion_model_for_molecular_conformation_generation.md|Notes]]
 - [[pdfs/dl/generative/diffusion/dall_e_2_hierarhical_text_conditioned_image_generation_with_clip_latents.pdf|Hierarchical Text-Conditional Image Generation with CLIP Latents.]]: (cite: journals/corr/abs-2204-06125/Ramesh/2022) DALL-E 2 paper. Uses Diffusion conditioned in CLIP latents from CLIP pretrianing . [[papers/dl/generative/diffusion/dall_e_2_hierarhical_text_conditioned_image_generation_with_clip_latents.md|Notes]]
 - [[pdfs/dl/generative/diffusion/high_resolution_image_synthesis_with_latent_diffusion_models.pdf|High-Resolution Image Synthesis with Latent Diffusion Models.]]: (cite: journals/corr/abs-2112-10752/Rombach/2021) . [[papers/dl/generative/diffusion/high_resolution_image_synthesis_with_latent_diffusion_models.md|Notes]]
 - [[pdfs/dl/generative/diffusion/improved_denoising_diffusion_probabilistic_models.pdf|Improved Denoising Diffusion Probabilistic Models.]]: (cite: conf/icml/NicholD21) . [[papers/dl/generative/diffusion/improved_denoising_diffusion_probabilistic_models.md|Notes]]
 - [[pdfs/dl/generative/diffusion/improving_diffusion_models_for_inverse_problems_using_manifold_constraints.pdf|Improving Diffusion Models for Inverse Problems using Manifold Constraints.]]: (cite: journals/corr/abs-2206-00941/Chung/2022) . [[papers/dl/generative/diffusion/improving_diffusion_models_for_inverse_problems_using_manifold_constraints.md|Notes]]
 - [[pdfs/dl/generative/diffusion/on_distillation_of_guided_diffusion_models.pdf|On Distillation of Guided Diffusion Models.]]: (cite: journals/corr/abs-2210-03142/Meng/2022) . [[papers/dl/generative/diffusion/on_distillation_of_guided_diffusion_models.md|Notes]]
 - [[pdfs/dl/generative/diffusion/photorealistic_text_to_image_diffusion_models_with_deep_language_understanding.pdf|Photorealistic Text-to-Image Diffusion Models with Deep Language Understanding.]]: (cite: journals/corr/abs-2205-11487/Saharia/2022) . [[papers/dl/generative/diffusion/photorealistic_text_to_image_diffusion_models_with_deep_language_understanding.md|Notes]]
 - [[pdfs/dl/generative/diffusion/progressive_distillation_for_for_fast_sampling_of_diffusion_models.pdf|Progressive Distillation for Fast Sampling of Diffusion Models.]]: (cite: journals/corr/abs-2202-00512/Salimans/2022) The diffusion forward pass is slow because it needs to be applied multiple times. This method presents a simple alternative, which is to train a distillation model, then approximate two forward passes using one, repeatedly doing this until you have a "distilled" forward pass. [[papers/dl/generative/diffusion/progressive_distillation_for_for_fast_sampling_of_diffusion_models.md|Notes]]
 - [[pdfs/dl/generative/diffusion/repaint_inpainting_using_denoising_diffusion_probabilistic_models.pdf|RePaint: Inpainting using Denoising Diffusion Probabilistic Models.]]: (cite: journals/corr/abs-2201-09865/Lugmayr/2022) . [[papers/dl/generative/diffusion/repaint_inpainting_using_denoising_diffusion_probabilistic_models.md|Notes]]
 - [[pdfs/dl/generative/diffusion/retrieval_augmented_diffusion_models.pdf|Retrieval-Augmented Diffusion Models.]]: (cite: journals/corr/abs-2204-11824/Blattmann/2022) . [[papers/dl/generative/diffusion/retrieval_augmented_diffusion_models.md|Notes]]
 - [[pdfs/dl/generative/diffusion/riemannian_diffusion_models.pdf|Riemannian Diffusion Models.]]: (cite: journals/corr/abs-2208-07949/Huang/2022) . [[papers/dl/generative/diffusion/riemannian_diffusion_models.md|Notes]]
 - [[pdfs/dl/generative/diffusion/score_based_generative_modeling.pdf|Score-Based Generative Modeling through Stochastic Differential Equations.]]: (cite: conf/iclr/0011SKKEP21) Generative modelling problem - we want to turn noise into something from the data distribution. The basic idea is that if you know the gradient of the noise, then you can make a reverse stochastic differential equation. Proposes a predictor-corrector which combines numerical SDE solvers with an MCMC approach and provides a way to do class-conditional generation, image inpainting, etc. [[papers/dl/generative/diffusion/score_based_generative_modeling.md|Notes]]
 - [[pdfs/dl/generative/diffusion/d3pm_structured_denoising_diffusion_models_in_discrete_state_spaces.pdf|Structured Denoising Diffusion Models in Discrete State-Spaces.]]: (cite: conf/nips/AustinJHTB21) Introduces D3PM, which shows how to do diffusion over discrete state spaces, by using transition matrices wiht absorbing states. They have some experiments showing how to apply this to a quantized swiss roll, reconstructing the original discrete 2D image from a noisy one. They also have tests on text as well, where you can reconstructed masked tokens using a diffusion process . [[papers/dl/generative/diffusion/d3pm_structured_denoising_diffusion_models_in_discrete_state_spaces.md|Notes]]
 - [[pdfs/dl/generative/diffusion/video_diffusion_models.pdf|Video Diffusion Models.]]: (cite: journals/corr/abs-2204-03458/Ho/2022) . [[papers/dl/generative/diffusion/video_diffusion_models.md|Notes]]
 - [[pdfs/dl/generative/diffusion/photorealistic_text_to_image_with_deep_language_understanding.pdf|photorealistic_text_to_image_with_deep_language_understanding]]: . [[papers/dl/generative/diffusion/photorealistic_text_to_image_with_deep_language_understanding.md|Notes]]
 - [[pdfs/dl/generative/diffusion/semantic_diffusion_network_for_semantic_segmentation.pdf|semantic_diffusion_network_for_semantic_segmentation]]: . [[papers/dl/generative/diffusion/semantic_diffusion_network_for_semantic_segmentation.md|Notes]]
 - [[pdfs/dl/generative/diffusion/unsupervised_representation_learning_from_pretrained_diffusion_probabilistic_models.pdf|unsupervised_representation_learning_from_pretrained_diffusion_probabilistic_models]]: . [[papers/dl/generative/diffusion/unsupervised_representation_learning_from_pretrained_diffusion_probabilistic_models.md|Notes]]
#### compositional
 - [[pdfs/dl/generative/diffusion/compositional/compositional_image_generation_and_manipulation_with_diffusion_probabilistic_models.pdf|Compositional Image Generation and Manipulation with Diffusion Probabilistic Models]]: . [[papers/dl/generative/diffusion/compositional/compositional_image_generation_and_manipulation_with_diffusion_probabilistic_models.md|Notes]]
 - [[pdfs/dl/generative/diffusion/compositional/compositional_visual_generation_with_compositional_diffusion_models.pdf|Compositional Visual Generation with Composable Diffusion Models.]]: (cite: journals/corr/abs-2206-01714/Liu/2022) . [[papers/dl/generative/diffusion/compositional/compositional_visual_generation_with_compositional_diffusion_models.md|Notes]]
#### graph
 - [[pdfs/dl/generative/diffusion/graph/equivariant_diffusion_for_molecule_generation_in_3d.pdf|Equivariant Diffusion for Molecule Generation in 3D.]]: (cite: conf/icml/HoogeboomSVW22) . [[papers/dl/generative/diffusion/graph/equivariant_diffusion_for_molecule_generation_in_3d.md|Notes]]
### energy
 - [[pdfs/dl/generative/energy/implicit_generation_with_energy_based_models.pdf|Implicit Generation and Modeling with Energy Based Models.]]: (cite: conf/nips/DuM19) . [[papers/dl/generative/energy/implicit_generation_with_energy_based_models.md|Notes]]
 - [[pdfs/dl/generative/energy/improved_contrastive_divergence_training_of_energy_based_model.pdf|Improved Contrastive Divergence Training of Energy Based Models.]]: (cite: journals/corr/abs-2012-01316/Du/2020) . [[papers/dl/generative/energy/improved_contrastive_divergence_training_of_energy_based_model.md|Notes]]
 - [[pdfs/dl/generative/energy/comet_unsupervised_learning_of_compositional_energy_concepts.pdf|Unsupervised Learning of Compositional Energy Concepts.]]: (cite: conf/nips/DuLSTM21) . [[papers/dl/generative/energy/comet_unsupervised_learning_of_compositional_energy_concepts.md|Notes]]
### gan
 - [[pdfs/dl/generative/gan/stylegan3.pdf|Alias-Free Generative Adversarial Networks.]]: (cite: journals/corr/abs-2106-12423/Karras/2021) AKA StyleGAN3. Bad signal processing creates a "texture sticking" problem when interpolating between generated images in the latent space. With some fixes in the encoder/decoder architecture to respect signal processing rules, it fixes the aliasing problem leading to a smoother latent space interpolation without texture sticking. [[papers/dl/generative/gan/stylegan3.md|Notes]]
 - [[pdfs/dl/generative/gan/ganformer_generative_adversarial_transformers.pdf|Generative Adversarial Transformers.]]: (cite: conf/icml/HudsonZ21) . [[papers/dl/generative/gan/ganformer_generative_adversarial_transformers.md|Notes]]
 - [[pdfs/dl/generative/gan/infogan.pdf|InfoGAN: Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets.]]: (cite: conf/nips/ChenCDHSSA16) . [[papers/dl/generative/gan/infogan.md|Notes]]
 - [[pdfs/dl/generative/gan/big_bigan.pdf|Large Scale Adversarial Representation Learning.]]: (cite: conf/nips/DonahueS19) . [[papers/dl/generative/gan/big_bigan.md|Notes]]
 - [[pdfs/dl/generative/gan/stylet2f_generating_human_faces_from_textual_description_using_stylegan2.pdf|StyleT2F: Generating Human Faces from Textual Description Using StyleGAN2.]]: (cite: journals/corr/abs-2204-07924/Sabae/2022) . [[papers/dl/generative/gan/stylet2f_generating_human_faces_from_textual_description_using_stylegan2.md|Notes]]
### normalizing_flows
 - [[pdfs/dl/generative/normalizing_flows/density_estimation_using_real_nvp.pdf|Density estimation using Real NVP.]]: (cite: conf/iclr/DinhSB17) . [[papers/dl/generative/normalizing_flows/density_estimation_using_real_nvp.md|Notes]]
### vae
 - [[pdfs/dl/generative/vae/inductive_bias_vae.pdf|InteL-VAEs - Adding Inductive Biases to Variational Auto-Encoders via Intermediary Latents.]]: (cite: journals/corr/abs-2106-13746/Miao/2021) Incorporate a mapping function into the encoder of a VAE which maps from a unit sphere distribution to separate clusters. Then it is easier to decode from those clusters. The mapping function can depend on the problem, its a kind of structural prior on the data space. [[papers/dl/generative/vae/inductive_bias_vae.md|Notes]]
 - [[pdfs/dl/generative/vae/nvae_hierarchical_vae.pdf|NVAE: A Deep Hierarchical Variational Autoencoder.]]: (cite: conf/nips/VahdatK20) . [[papers/dl/generative/vae/nvae_hierarchical_vae.md|Notes]]
 - [[pdfs/dl/generative/vae/rethinking_controllable_variational_autoencoders.pdf|Rethinking Controllable Variational Autoencoders.]]: (cite: conf/cvpr/ShaoYLLCYZ22) Extends on ControlVAE with a model called DyanmicVAE. The general idea behind these class of models is to extend [[beta_vae_learning_basic_visual_concepts_with_a_constrained_variational_framework]] by attaching a PI controller to the $\beta$ term. The KL Divergence is part of the loop used to tune the $\beta$ parameter, such that it smoothly adjusts during training (so you start our with disentanglement, then move towards higher reconsrtruction quality) . [[papers/dl/generative/vae/rethinking_controllable_variational_autoencoders.md|Notes]]
## gflownet
 - [[pdfs/dl/gflownet/gflownet_foundations.pdf|GFlowNet Foundations.]]: (cite: journals/corr/abs-2111-09266/Bengio/2021) . [[papers/dl/gflownet/gflownet_foundations.md|Notes]]
 - [[pdfs/dl/gflownet/trajectory_balance_improved_credit_assignment_in_gflownets.pdf|Trajectory Balance: Improved Credit Assignment in GFlowNets.]]: (cite: journals/corr/abs-2201-13259/Malkin/2022) . [[papers/dl/gflownet/trajectory_balance_improved_credit_assignment_in_gflownets.md|Notes]]
 - [[pdfs/dl/gflownet/robust_scheduling_with_gflownets.pdf|robust_scheduling_with_gflownets]]: . [[papers/dl/gflownet/robust_scheduling_with_gflownets.md|Notes]]
## graph
 - [[pdfs/dl/graph/constraint_based_graph_network_simulator.pdf|Constraint-based graph network simulator.]]: (cite: conf/icml/RubanovaSPB22) . [[papers/dl/graph/constraint_based_graph_network_simulator.md|Notes]]
 - [[pdfs/dl/graph/yu_deep_latent_graph_matching.pdf|Deep Latent Graph Matching.]]: (cite: conf/icml/YuWYL21) . [[papers/dl/graph/yu_deep_latent_graph_matching.md|Notes]]
 - [[pdfs/dl/graph/graph_neural_networks_with_lea.pdf|Graph Neural Networks with Learnable Structural and Positional Representations.]]: (cite: conf/iclr/DwivediL0BB22) . [[papers/dl/graph/graph_neural_networks_with_lea.md|Notes]]
 - [[pdfs/dl/graph/find_your_friendly_neighbourhood_graph_attention.pdf|How to Find Your Friendly Neighborhood: Graph Attention Design with Self-Supervision.]]: (cite: conf/iclr/KimO21) . [[papers/dl/graph/find_your_friendly_neighbourhood_graph_attention.md|Notes]]
 - [[pdfs/dl/graph/pure_transformers_are_powerful_graph_learners.pdf|Pure Transformers are Powerful Graph Learners.]]: (cite: journals/corr/abs-2207-02505/Kim/2022) . [[papers/dl/graph/pure_transformers_are_powerful_graph_learners.md|Notes]]
 - [[pdfs/dl/graph/superglue_learning_feature_matching_gnns.pdf|SuperGlue: Learning Feature Matching with Graph Neural Networks.]]: (cite: journals/corr/abs-1911-11763/Sarlin/2019) . [[papers/dl/graph/superglue_learning_feature_matching_gnns.md|Notes]]
## imle
 - [[pdfs/dl/imle/implicit_mle_backprop_discrete_exponential_family.pdf|Implicit MLE: Backpropagating Through Discrete Exponential Family Distributions.]]: (cite: conf/nips/NiepertMF21) . [[papers/dl/imle/implicit_mle_backprop_discrete_exponential_family.md|Notes]]
 - [[pdfs/dl/imle/chimle_conditional_hierarchical_mle_for_multimodal_conditional_image_synthesis.pdf|chimle_conditional_hierarchical_mle_for_multimodal_conditional_image_synthesis]]: . [[papers/dl/imle/chimle_conditional_hierarchical_mle_for_multimodal_conditional_image_synthesis.md|Notes]]
## independent
 - [[pdfs/dl/independent/neural_attentive_circuits.pdf|Neural Attentive Circuits.]]: (cite: journals/corr/abs-2210-08031/Rahaman/2022) . You have separate processing modules that interact sparsely with attention. The key difference is that the signature and code vectors for conditioning are different, and the signature vectors modulate the probability that two modules are going to interact (as opposed to just doing attention between modules). [[papers/dl/independent/neural_attentive_circuits.md|Notes]]
 - [[pdfs/dl/independent/rim.pdf|Recurrent Independent Mechanisms.]]: (cite: conf/iclr/GoyalLHSLBS21) . [[papers/dl/independent/rim.md|Notes]]
## interpretability
 - [[pdfs/dl/interpretability/a_benchmark_for_interpretability_methods_in_deep_learning.pdf|a_benchmark_for_interpretability_methods_in_deep_learning]]: . [[papers/dl/interpretability/a_benchmark_for_interpretability_methods_in_deep_learning.md|Notes]]
## logic
 - [[pdfs/dl/logic/neural_arithmetic_units.pdf|Neural Arithmetic Units.]]: (cite: conf/iclr/MadsenJ20) . [[papers/dl/logic/neural_arithmetic_units.md|Notes]]
## meta
 - [[pdfs/dl/meta/a_closer_look_at_prototype_classifier_for_few_shot_image_classification.pdf|A Closer Look at Prototype Classifier for Few-shot Image Classification.]]: (cite: journals/corr/abs-2110-05076/Hou/2021) . [[papers/dl/meta/a_closer_look_at_prototype_classifier_for_few_shot_image_classification.md|Notes]]
 - [[pdfs/dl/meta/efficient_variance_reduction_for_meta_learning.pdf|Efficient Variance Reduction for Meta-learning.]]: (cite: conf/icml/YangK22) . [[papers/dl/meta/efficient_variance_reduction_for_meta_learning.md|Notes]]
 - [[pdfs/dl/meta/meta_attention_networks.pdf|Meta-Attention Networks: Meta Learning Attention To Modulate Information Between Sparsely Interacting Recurrent Modules.]]: . [[papers/dl/meta/meta_attention_networks.md|Notes]]
 - [[pdfs/dl/meta/meta_learning_in_neural_networks_a_survey.pdf|Meta-Learning in Neural Networks: A Survey.]]: (cite: journals/corr/abs-2004-05439/Hospedales/2020) . [[papers/dl/meta/meta_learning_in_neural_networks_a_survey.md|Notes]]
 - [[pdfs/dl/meta/meta_learning_via_classifier_free_guidance.pdf|Meta-Learning via Classifier(-free) Guidance.]]: (cite: journals/corr/abs-2210-08942/Nava/2022) . [[papers/dl/meta/meta_learning_via_classifier_free_guidance.md|Notes]]
 - [[pdfs/dl/meta/meta_learning_few_shot_nlp_survey.pdf|Meta-learning for Few-shot Natural Language Processing: A Survey.]]: (cite: journals/corr/abs-2007-09604/Yin/2020) . [[papers/dl/meta/meta_learning_few_shot_nlp_survey.md|Notes]]
 - [[pdfs/dl/meta/modular_meta_learning.pdf|Modular meta-learning.]]: (cite: conf/corl/AletLK18) . [[papers/dl/meta/modular_meta_learning.md|Notes]]
 - [[pdfs/dl/meta/rethinking_generalization_in_few_shot_classification.pdf|Rethinking Generalization in Few-Shot Classification.]]: (cite: journals/corr/abs-2206-07267/Hiller/2022) . [[papers/dl/meta/rethinking_generalization_in_few_shot_classification.md|Notes]]
 - [[pdfs/dl/meta/meta_learning_makes_a_better_multimodal_few_shot_leaner.pdf|meta_learning_makes_a_better_multimodal_few_shot_leaner]]: . [[papers/dl/meta/meta_learning_makes_a_better_multimodal_few_shot_leaner.md|Notes]]
 - [[pdfs/dl/meta/multi_objective_tree_structured_parzen_estimator_meets_meta_learning.pdf|multi_objective_tree_structured_parzen_estimator_meets_meta_learning]]: . [[papers/dl/meta/multi_objective_tree_structured_parzen_estimator_meets_meta_learning.md|Notes]]
 - [[pdfs/dl/meta/unsupervised_meta_learning_via_few_shot_pseudo_supervised_contrastive_learning.pdf|unsupervised_meta_learning_via_few_shot_pseudo_supervised_contrastive_learning]]: . [[papers/dl/meta/unsupervised_meta_learning_via_few_shot_pseudo_supervised_contrastive_learning.md|Notes]]
## model_parallel
 - [[pdfs/dl/model_parallel/on_optimizing_the_communication_of_model_parallelism.pdf|On Optimizing the Communication of Model Parallelism.]]: (cite: journals/corr/abs-2211-05322/Zhuang/2022) . [[papers/dl/model_parallel/on_optimizing_the_communication_of_model_parallelism.md|Notes]]
## neural_ode
 - [[pdfs/dl/neural_ode/neural_abstractions.pdf|neural_abstractions]]: . [[papers/dl/neural_ode/neural_abstractions.md|Notes]]
## noncontrastive
 - [[pdfs/dl/noncontrastive/understanding_self_supervised_learning_dynamics_without_contrastive_pairs.pdf|Understanding self-supervised learning dynamics without contrastive pairs.]]: (cite: conf/icml/TianCG21) . [[papers/dl/noncontrastive/understanding_self_supervised_learning_dynamics_without_contrastive_pairs.md|Notes]]
## object_centric
 - [[pdfs/dl/object_centric/object_representations_as_fixed_points_training_iterative_inference_algorithms_with_implicit_differentiation.pdf|Object Representations as Fixed Points: Training Iterative Inference Algorithms with Implicit Differentiation]]: . [[papers/dl/object_centric/object_representations_as_fixed_points_training_iterative_inference_algorithms_with_implicit_differentiation.md|Notes]]
 - [[pdfs/dl/object_centric/slot_attention.pdf|Object-Centric Learning with Slot Attention.]]: (cite: conf/nips/LocatelloWUMHUD20) . [[papers/dl/object_centric/slot_attention.md|Notes]]
 - [[pdfs/dl/object_centric/scalor_generative_world_models_with_scaleable_object_representations.pdf|SCALOR: Generative World Models with Scalable Object Representations.]]: (cite: conf/iclr/JiangJMA20) . [[papers/dl/object_centric/scalor_generative_world_models_with_scaleable_object_representations.md|Notes]]
 - [[pdfs/dl/object_centric/unsupervised_learning_of_temporal_abstractions_with_slot_based_transformers.pdf|Unsupervised Learning of Temporal Abstractions with Slot-based Transformers.]]: (cite: journals/corr/abs-2203-13573/Gopalakrishnan/2022) . [[papers/dl/object_centric/unsupervised_learning_of_temporal_abstractions_with_slot_based_transformers.md|Notes]]
### segmentation
#### video
 - [[pdfs/dl/object_centric/segmentation/video/video_object_segmentation_using_space_time_memory_networks.pdf|Video Object Segmentation Using Space-Time Memory Networks.]]: (cite: conf/iccv/OhLXK19) . [[papers/dl/object_centric/segmentation/video/video_object_segmentation_using_space_time_memory_networks.md|Notes]]
 - [[pdfs/dl/object_centric/segmentation/video/xmem_long_term_video_object_segmentation_with_an_atkinson_shiffrin_memory_model.pdf|XMem: Long-Term Video Object Segmentation with an Atkinson-Shiffrin Memory Model.]]: (cite: conf/eccv/ChengS22) . [[papers/dl/object_centric/segmentation/video/xmem_long_term_video_object_segmentation_with_an_atkinson_shiffrin_memory_model.md|Notes]]
 - [[pdfs/dl/object_centric/segmentation/video/rethinking_space_time_networks_with_improved_memory_coverage_for_efficiency_video_object_segmentation.pdf|rethinking_space_time_networks_with_improved_memory_coverage_for_efficiency_video_object_segmentation]]: . [[papers/dl/object_centric/segmentation/video/rethinking_space_time_networks_with_improved_memory_coverage_for_efficiency_video_object_segmentation.md|Notes]]
## optimization
 - [[pdfs/dl/optimization/gradient_descent_the_ultimate_optimizer.pdf|Gradient Descent: The Ultimate Optimizer.]]: (cite: journals/corr/abs-1909-13371/Chandra/2019) . [[papers/dl/optimization/gradient_descent_the_ultimate_optimizer.md|Notes]]
 - [[pdfs/dl/optimization/self_normalizing_neural_networks.pdf|Self-Normalizing Neural Networks.]]: (cite: conf/nips/KlambauerUMH17) . [[papers/dl/optimization/self_normalizing_neural_networks.md|Notes]]
 - [[pdfs/dl/optimization/understanding_and_improving_layer_normalization.pdf|Understanding and Improving Layer Normalization.]]: (cite: conf/nips/Xu0ZZL19) . [[papers/dl/optimization/understanding_and_improving_layer_normalization.md|Notes]]
 - [[pdfs/dl/optimization/understanding_the_generalization_of_adam_in_learning_neural_networks_with_proper_regularization.pdf|Understanding the Generalization of Adam in Learning Neural Networks with Proper Regularization.]]: (cite: journals/corr/abs-2108-11371/Zou/2021) . [[papers/dl/optimization/understanding_the_generalization_of_adam_in_learning_neural_networks_with_proper_regularization.md|Notes]]
 - [[pdfs/dl/optimization/dont_decay_the_learning_rate_increase_the_batch_size.pdf|dont_decay_the_learning_rate_increase_the_batch_size]]: . [[papers/dl/optimization/dont_decay_the_learning_rate_increase_the_batch_size.md|Notes]]
 - [[pdfs/dl/optimization/escaping_saddle_points_for_effective_generalization_on_class_imbalanced_data.pdf|escaping_saddle_points_for_effective_generalization_on_class_imbalanced_data]]: . [[papers/dl/optimization/escaping_saddle_points_for_effective_generalization_on_class_imbalanced_data.md|Notes]]
## regularization
### dropout
 - [[pdfs/dl/regularization/dropout/learning_sparse_networks_using_targeted_dropout.pdf|Learning Sparse Networks Using Targeted Dropout.]]: (cite: journals/corr/abs-1905-13678/Gomez/2019) . [[papers/dl/regularization/dropout/learning_sparse_networks_using_targeted_dropout.md|Notes]]
 - [[pdfs/dl/regularization/dropout/improving_compute_efficiency_frontiers_with_sliceout.pdf|improving_compute_efficiency_frontiers_with_sliceout]]: . [[papers/dl/regularization/dropout/improving_compute_efficiency_frontiers_with_sliceout.md|Notes]]
## relational
 - [[pdfs/dl/relational/memory_augmented_dynamic_neural_relational_inference.pdf|Memory-augmented Dynamic Neural Relational Inference.]]: (cite: conf/iccv/Gong0SH21) . [[papers/dl/relational/memory_augmented_dynamic_neural_relational_inference.md|Notes]]
 - [[pdfs/dl/relational/on_neural_architecture_inductive_biases_for_relational_tasks.pdf|On Neural Architecture Inductive Biases for Relational Tasks.]]: (cite: journals/corr/abs-2206-05056/Kerg/2022) . [[papers/dl/relational/on_neural_architecture_inductive_biases_for_relational_tasks.md|Notes]]
 - [[pdfs/dl/relational/tell_me_why_explanations_support_learning_relational_and_causal_structure.pdf|Tell me why! Explanations support learning relational and causal structure.]]: (cite: conf/icml/LampinenRDCTMYS22) . [[papers/dl/relational/tell_me_why_explanations_support_learning_relational_and_causal_structure.md|Notes]]
 - [[pdfs/dl/relational/transe_translating_embeddings_for_modelling_multi_relational_data.pdf|Translating Embeddings for Modeling Multi-relational Data.]]: (cite: conf/nips/BordesUGWY13) TransE method, models relationships by modeling them as translations . [[papers/dl/relational/transe_translating_embeddings_for_modelling_multi_relational_data.md|Notes]]
## representation_learning
 - [[pdfs/dl/representation_learning/cvae_enhances_salient_features.pdf|Contrastive Variational Autoencoder Enhances Salient Features.]]: (cite: journals/corr/abs-1902-04601/Abid/2019) . [[papers/dl/representation_learning/cvae_enhances_salient_features.md|Notes]]
 - [[pdfs/dl/representation_learning/relative_representations_enable_zero_shot_latent_space_communication.pdf|Relative representations enable zero-shot latent space communication.]]: (cite: journals/corr/abs-2209-15430/Moschella/2022) . [[papers/dl/representation_learning/relative_representations_enable_zero_shot_latent_space_communication.md|Notes]]
 - [[pdfs/dl/representation_learning/sketch_embed_net_learning_novel_concepts_by_imitating_drawings.pdf|SketchEmbedNet - Learning Novel Concepts by Imitating Drawings.]]: (cite: conf/icml/WangRZ21) Learn parameters to an RNN which outputs a program used to produce a sketch matching a particular input. The results show that "learning to sketch" produces representations which classify well compared to contrastive learning and demonstrate "conceptual composition" (snowman - circle + square = square snowman) . [[papers/dl/representation_learning/sketch_embed_net_learning_novel_concepts_by_imitating_drawings.md|Notes]]
 - [[pdfs/dl/representation_learning/visual_representation_learning_does_not_generalize_strongly.pdf|Visual Representation Learning Does Not Generalize Strongly Within the Same Domain.]]: (cite: journals/corr/abs-2107-08221/Schott/2021) Recompose, interpolate or extrapolate only existing factors of variation from the training data. Models that learn the correct mechanism should be able to genearlize to this benchmark, but they fail to do so. Almost all models bad at extrapolation except "transfer learning" models. Unsupervised models not very good at concept composition. [[papers/dl/representation_learning/visual_representation_learning_does_not_generalize_strongly.md|Notes]]
 - [[pdfs/dl/representation_learning/weakly_supervised_representation_learning_with_sparse_perturbations.pdf|Weakly Supervised Representation Learning with Sparse Perturbations.]]: (cite: journals/corr/abs-2206-01101/Ahuja/2022) . [[papers/dl/representation_learning/weakly_supervised_representation_learning_with_sparse_perturbations.md|Notes]]
## satnet
 - [[pdfs/dl/satnet/abductive_knowledge_induction_satnet.pdf|Abductive Knowledge Induction from Raw Data.]]: (cite: conf/ijcai/DaiM21) . [[papers/dl/satnet/abductive_knowledge_induction_satnet.md|Notes]]
 - [[pdfs/dl/satnet/satnet_symbolic_grounding_assessment.pdf|Assessing SATNet&apos;s Ability to Solve the Symbol Grounding Problem.]]: (cite: conf/nips/ChangFLS20) . [[papers/dl/satnet/satnet_symbolic_grounding_assessment.md|Notes]]
 - [[pdfs/dl/satnet/satnet_nlp_application.pdf|Deep Weighted MaxSAT for Aspect-based Opinion Extraction.]]: (cite: conf/emnlp/WuWP20) . [[papers/dl/satnet/satnet_nlp_application.md|Notes]]
 - [[pdfs/dl/satnet/satnet_bridging_dl_logical_reasoning_differentiable_sat_solver_lp.pdf|SATNet: Bridging deep learning and logical reasoning using a differentiable satisfiability solver.]]: (cite: conf/icml/WangDWK19) . [[papers/dl/satnet/satnet_bridging_dl_logical_reasoning_differentiable_sat_solver_lp.md|Notes]]
 - [[pdfs/dl/satnet/techniques_symbolic_grounding_satnet.pdf|Techniques for Symbol Grounding with SATNet.]]: (cite: conf/nips/TopanRS21) . [[papers/dl/satnet/techniques_symbolic_grounding_satnet.md|Notes]]
## semisupervised
 - [[pdfs/dl/semisupervised/mean_teachers_are_better_role_models_weighted_average_consistency_targets_improve_semi_supervised_deep_learning_results.pdf|Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results.]]: (cite: conf/iclr/TarvainenV17) . [[papers/dl/semisupervised/mean_teachers_are_better_role_models_weighted_average_consistency_targets_improve_semi_supervised_deep_learning_results.md|Notes]]
 - [[pdfs/dl/semisupervised/semi_supervised_learning_with_ladder_networks.pdf|Semi-supervised Learning with Ladder Networks.]]: (cite: conf/nips/RasmusBHVR15) . [[papers/dl/semisupervised/semi_supervised_learning_with_ladder_networks.md|Notes]]
 - [[pdfs/dl/semisupervised/temporal_ensembling_for_semi_supervised_learning.pdf|Temporal Ensembling for Semi-Supervised Learning.]]: (cite: conf/iclr/LaineA17) . [[papers/dl/semisupervised/temporal_ensembling_for_semi_supervised_learning.md|Notes]]
## sequence
 - [[pdfs/dl/sequence/a_formal_hierarchy_of_rnn_architectures.pdf|A Formal Hierarchy of RNN Architectures.]]: (cite: conf/acl/MerrillWGSSY20) . [[papers/dl/sequence/a_formal_hierarchy_of_rnn_architectures.md|Notes]]
 - [[pdfs/dl/sequence/conv_lstm.pdf|Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting.]]: (cite: conf/nips/ShiCWYWW15) . [[papers/dl/sequence/conv_lstm.md|Notes]]
 - [[pdfs/dl/sequence/dilated_rnn.pdf|Dilated Recurrent Neural Networks.]]: (cite: conf/nips/ChangZHYGTCWHH17) . [[papers/dl/sequence/dilated_rnn.md|Notes]]
 - [[pdfs/dl/sequence/film_frequency_improved_legendre_memory_model_for_long_term_time_series_forecasting.pdf|FiLM: Frequency improved Legendre Memory Model for Long-term Time Series Forecasting.]]: (cite: journals/corr/abs-2205-08897/Zhou/2022) . [[papers/dl/sequence/film_frequency_improved_legendre_memory_model_for_long_term_time_series_forecasting.md|Notes]]
 - [[pdfs/dl/sequence/urlstm_gating.pdf|Improving the Gating Mechanism of Recurrent Neural Networks.]]: (cite: conf/icml/GuGP0P20) Introduces the URLSTM improvement to LSTM, basically better initialization and gating design to promote long-term memories . [[papers/dl/sequence/urlstm_gating.md|Notes]]
 - [[pdfs/dl/sequence/mc_lstm.pdf|MC-LSTM - Mass-Conserving LSTM.]]: (cite: conf/icml/HoedtKKHHNHK21) Adjust the architecture of an LSTM such that "mass" cannot appear from nowhere, it must either explicitly enter the system via the input gate and mass leaving the system plus current mass must sum up to the total mass (input + current mass at previous timestep). [[papers/dl/sequence/mc_lstm.md|Notes]]
 - [[pdfs/dl/sequence/soft_dtw_a_differentiable_loss_function_for_time_series.pdf|Soft-DTW: a Differentiable Loss Function for Time-Series.]]: (cite: conf/icml/CuturiB17) . [[papers/dl/sequence/soft_dtw_a_differentiable_loss_function_for_time_series.md|Notes]]
 - [[pdfs/dl/sequence/unsupervised_learning_of_equivariant_structure_from_sequences.pdf|Unsupervised Learning of Equivariant Structure from Sequences.]]: (cite: journals/corr/abs-2210-05972/Miyato/2022) . [[papers/dl/sequence/unsupervised_learning_of_equivariant_structure_from_sequences.md|Notes]]
 - [[pdfs/dl/sequence/neural_attention_memory.pdf|neural_attention_memory]]: . [[papers/dl/sequence/neural_attention_memory.md|Notes]]
## sets
 - [[pdfs/dl/sets/xie_proximal_point.pdf|A Fast Proximal Point Method for Computing Exact Wasserstein Distance.]]: (cite: conf/uai/XieWWZ19) . [[papers/dl/sets/xie_proximal_point.md|Notes]]
 - [[pdfs/dl/sets/relational_set_representations.pdf|Better Set Representations For Relational Reasoning.]]: (cite: conf/nips/HuangHSZLB20) . [[papers/dl/sets/relational_set_representations.md|Notes]]
 - [[pdfs/dl/sets/dspn_deep_set_prediction.pdf|Deep Set Prediction Networks.]]: (cite: conf/nips/ZhangHP19) . [[papers/dl/sets/dspn_deep_set_prediction.md|Notes]]
## sparse
 - [[pdfs/dl/sparse/graph_induced_sparsity_gini.pdf|Improving Molecular Graph Neural Network Explainability with Orthonormalization and Induced Sparsity.]]: (cite: conf/icml/HendersonCM21) Introduces Batch Representation Orthonormalization and Gini regularization as a mechanism to regularize and induce sparsity in graphs. Gini regularization effectively puts a penalty on the inverse-gini coefficient, eg, $(\sum^n \sum^m \frac{|w_{ij} - w_{ij'}}{2(n^2 - n)\tilde w_i})^{-1}$ . [[papers/dl/sparse/graph_induced_sparsity_gini.md|Notes]]
### activations
 - [[pdfs/dl/sparse/activations/from_softmax_to_sparsemax_a_sparse_model_of_attention_and_multi_label_classification.pdf|From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification.]]: (cite: conf/icml/MartinsA16) . [[papers/dl/sparse/activations/from_softmax_to_sparsemax_a_sparse_model_of_attention_and_multi_label_classification.md|Notes]]
 - [[pdfs/dl/sparse/activations/learning_sparse_distributions.pdf|Learning Sparse Distributions using Iterative Hard Thresholding.]]: (cite: conf/nips/ZhangKKK19) Use a projected gradient descent algorithm known as Iterative Hard Trehsholding to sparsify distributions.  The proposed greedy algorithm can approximate a sparse distribution nearing the  modelled distribution in density. The GSProj algorithm iteratively solves $j \in \arg \min_{i \in [n] \setminus S} \{\min_{p \in P_{s \cup i}} ||p(\cdot) - q(\cdot)||^2_2\}$ , adding $j$ to $S$ until the desired density level is reached. [[papers/dl/sparse/activations/learning_sparse_distributions.md|Notes]]
 - [[pdfs/dl/sparse/activations/controllable_sparse_alternatives_softmax.pdf|On Controllable Sparse Alternatives to Softmax.]]: (cite: conf/nips/LahaCAKSR18) Develops a unified framework for combining sparsemax and softmax with controllable degrees of sparsity. Proposes sparsegen-lin and sparsehourglass. Sparsemax projects the score vector on to a simplex $\rho(z) = \arg \min_{p \in \delta^{k - 1}}||p - z||^2_2 - \lambda ||p||^2_2$ where $g$ is some "transformation function" and $\lambda$ controls the regularization strength.  The experiments show that when using sparsegen as an altenrative to softmax in the attention operator that you get better test set performance. . [[papers/dl/sparse/activations/controllable_sparse_alternatives_softmax.md|Notes]]
 - [[pdfs/dl/sparse/activations/speeding_up_entmax.pdf|Speeding Up Entmax.]]: (cite: conf/naacl/TezekbayevNGA22) . [[papers/dl/sparse/activations/speeding_up_entmax.md|Notes]]
### attention
 - [[pdfs/dl/sparse/attention/softmax_tempering_for_training_neural_machine_translation_models.pdf|Softmax Tempering for Training Neural Machine Translation Models.]]: (cite: journals/corr/abs-2009-09372/Dabre/2020) Soft sparsity promotion mechanism for output softmax distributions. Divide by temperature when taking the output softmax and multiply by temperature when taking the negative log likelihood. Multiplying the loss by the temperature is necessary to "fix" the gradients so that they aren't skewed by the tempering operation. [[papers/dl/sparse/attention/softmax_tempering_for_training_neural_machine_translation_models.md|Notes]]
### weights
 - [[pdfs/dl/sparse/weights/controlled_sparsity_via_constrained_optimization_or_how_i_learned_to_stop_tuning_penalties_and_love_constraints.pdf|Controlled Sparsity via Constrained Optimization or: How I Learned to Stop Tuning Penalties and Love Constraints.]]: (cite: journals/corr/abs-2208-04425/Gallego-Posada/2022) . [[papers/dl/sparse/weights/controlled_sparsity_via_constrained_optimization_or_how_i_learned_to_stop_tuning_penalties_and_love_constraints.md|Notes]]
 - [[pdfs/dl/sparse/weights/keep_the_gradients_flowing_using_gradient_flow_to_study_sparse_network_optimization.pdf|Keep the Gradients Flowing: Using Gradient Flow to Study Sparse Network Optimization.]]: (cite: journals/corr/abs-2102-01670/Tessera/2021) . [[papers/dl/sparse/weights/keep_the_gradients_flowing_using_gradient_flow_to_study_sparse_network_optimization.md|Notes]]
 - [[pdfs/dl/sparse/weights/sparse_linear_layers_debuggable_deep_networks.pdf|Leveraging Sparse Linear Layers for Debuggable Deep Networks.]]: (cite: conf/icml/WongSM21) Demonstrates how fitting sparse linear models learned over deep feature representations can lead to more debuggable neural networks. View the network as a "deep feature extractor" and linear "decision layer" and only apply the sparsity metric to the decision layer. In the experiments, the features selected by the sparse decision layers "better summarize the model's decision process". [[papers/dl/sparse/weights/sparse_linear_layers_debuggable_deep_networks.md|Notes]]
 - [[pdfs/dl/sparse/weights/lockout_sparse_regularization_neural_networks.pdf|Lockout: Sparse Reguarlization of Neural Networks]]: (cite: journals/corr/abs-2107-07160/Valdes/2021) Proposes Lockout, a mechanism to perform sparsity regularization on nonlinear hypothesis functions. At every iteration, linearlize the loss function and sparsity constraint, solve the corresponding linear programming problem. Effectively, explicit modification of the solution is performed at each step so as to maintain a desired level of sparsity. Only parameters that are not penalized by the constraint are updated first, then update parameters for which decreasing their absolute value decreases the loss, then update the most important parameters such that their absolute value increases but the loss decreases, then update rest of the parameters which are not important by decreasing their absolute value. [[papers/dl/sparse/weights/lockout_sparse_regularization_neural_networks.md|Notes]]
 - [[pdfs/dl/sparse/weights/the_difficulty_of_training_sparse_neural_networks.pdf|The Difficulty of Training Sparse Neural Networks.]]: (cite: journals/corr/abs-1906-10732/Evci/2019) . [[papers/dl/sparse/weights/the_difficulty_of_training_sparse_neural_networks.md|Notes]]
## symbolic
 - [[pdfs/dl/symbolic/drawing_out_of_distribution_with_neuro_symbolic_generative_models.pdf|Drawing out of Distribution with Neuro-Symbolic Generative Models.]]: (cite: journals/corr/abs-2206-01829/Liang/2022) . [[papers/dl/symbolic/drawing_out_of_distribution_with_neuro_symbolic_generative_models.md|Notes]]
 - [[pdfs/dl/symbolic/symbolic_behaviour_in_artificial_intelligence.pdf|Symbolic Behaviour in Artificial Intelligence.]]: (cite: journals/corr/abs-2102-03406/Santoro/2021) Position paper. Talks about what symbolic behaviour actually means. Symbolic behaviour should be receptive, constructive, embedded, malleable, meaningful and graded. The work looks at what this means in the context of an LLM.. [[papers/dl/symbolic/symbolic_behaviour_in_artificial_intelligence.md|Notes]]
## tabular
 - [[pdfs/dl/tabular/deep_neural_networks_and_tabular_data_a_survey.pdf|Deep Neural Networks and Tabular Data: A Survey.]]: (cite: journals/corr/abs-2110-01889/Borisov/2021) . [[papers/dl/tabular/deep_neural_networks_and_tabular_data_a_survey.md|Notes]]
 - [[pdfs/dl/tabular/neural_networks_are_decision_trees.pdf|Neural Networks are Decision Trees.]]: (cite: journals/corr/abs-2210-05189/Aytekin/2022) . [[papers/dl/tabular/neural_networks_are_decision_trees.md|Notes]]
 - [[pdfs/dl/tabular/regularization_is_all_you_need.pdf|Regularization is all you Need: Simple Neural Nets can Excel on Tabular Data.]]: (cite: journals/corr/abs-2106-11189/Kadra/2021) . [[papers/dl/tabular/regularization_is_all_you_need.md|Notes]]
 - [[pdfs/dl/tabular/revisiting_deep_learning_models_for_tabular_data.pdf|Revisiting Deep Learning Models for Tabular Data.]]: (cite: conf/nips/GorishniyRKB21) . [[papers/dl/tabular/revisiting_deep_learning_models_for_tabular_data.md|Notes]]
 - [[pdfs/dl/tabular/saint_improved_neural_networks_for_tabular_data_via_row_attention_and_contrastive_pretraining.pdf|SAINT: Improved Neural Networks for Tabular Data via Row Attention and Contrastive Pre-Training.]]: (cite: journals/corr/abs-2106-01342/Somepalli/2021) . [[papers/dl/tabular/saint_improved_neural_networks_for_tabular_data_via_row_attention_and_contrastive_pretraining.md|Notes]]
 - [[pdfs/dl/tabular/self_attention_between_datapoints_going_beyond_individual_input_output_pairs_in_deep_learning.pdf|Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning.]]: (cite: conf/nips/KossenBLGRG21) . [[papers/dl/tabular/self_attention_between_datapoints_going_beyond_individual_input_output_pairs_in_deep_learning.md|Notes]]
 - [[pdfs/dl/tabular/transfer_learning_with_deep_tabular_models.pdf|Transfer Learning with Deep Tabular Models.]]: (cite: journals/corr/abs-2206-15306/Levin/2022) . [[papers/dl/tabular/transfer_learning_with_deep_tabular_models.md|Notes]]
 - [[pdfs/dl/tabular/treeformer_dense_gradient_trees_for_efficient_attention_computation.pdf|Treeformer: Dense Gradient Trees for Efficient Attention Computation.]]: (cite: journals/corr/abs-2208-09015/Madaan/2022) . [[papers/dl/tabular/treeformer_dense_gradient_trees_for_efficient_attention_computation.md|Notes]]
 - [[pdfs/dl/tabular/why_do_tree_based_models_still_outperform_deep_learning_on_tabular_data.pdf|Why do tree-based models still outperform deep learning on tabular data?]]: (cite: journals/corr/abs-2207-08815/Grinsztajn/2022) A study of 40 different tabular datasets to compare tree-based models and neural networks. Then they make some findings about why the NNs tend to do poorly on these, the most interesting of which is that NNs are biased towards smooth functions and also that NNs are rotationally invariant learners, which means that features are clipped in the rotated space rather than the original space, which leads to unnnecessary mixing . [[papers/dl/tabular/why_do_tree_based_models_still_outperform_deep_learning_on_tabular_data.md|Notes]]
## theory
 - [[pdfs/dl/theory/overparameterization.pdf|A Farewell to the Bias-Variance Tradeoff? An Overview of the Theory of Overparameterized Machine Learning.]]: (cite: journals/corr/abs-2109-02355/Dar/2021) . [[papers/dl/theory/overparameterization.md|Notes]]
 - [[pdfs/dl/theory/good_init.pdf|All you need is a good init.]]: (cite: journals/corr/MishkinM15/Mishkin/2016) . [[papers/dl/theory/good_init.md|Notes]]
 - [[pdfs/dl/theory/batch_normalization_explained.pdf|Batch Normalization Explained.]]: (cite: journals/corr/abs-2209-14778/Balestriero/2022) . [[papers/dl/theory/batch_normalization_explained.md|Notes]]
 - [[pdfs/dl/theory/benign_tempered_or_catastrophic_a_taxonomy_of_overfitting.pdf|Benign, Tempered, or Catastrophic: A Taxonomy of Overfitting.]]: (cite: journals/corr/abs-2207-06569/Mallinar/2022) . [[papers/dl/theory/benign_tempered_or_catastrophic_a_taxonomy_of_overfitting.md|Notes]]
 - [[pdfs/dl/theory/deep_double_descent_where_bigger_models_and_more_data_hurt.pdf|Deep Double Descent: Where Bigger Models and More Data Hurt.]]: (cite: conf/iclr/NakkiranKBYBS20) . [[papers/dl/theory/deep_double_descent_where_bigger_models_and_more_data_hurt.md|Notes]]
 - [[pdfs/dl/theory/robustness_in_deep_learning_the_good_width_the_bad_depth_and_the_ugly_initialization.pdf|Robustness in deep learning: The good (width), the bad (depth), and the ugly (initialization).]]: (cite: journals/corr/abs-2209-07263/Zhu/2022) . [[papers/dl/theory/robustness_in_deep_learning_the_good_width_the_bad_depth_and_the_ugly_initialization.md|Notes]]
 - [[pdfs/dl/theory/computational_limits_deep_learning.pdf|The Computational Limits of Deep Learning.]]: (cite: journals/corr/abs-2007-05558/Thompson/2020) . [[papers/dl/theory/computational_limits_deep_learning.md|Notes]]
 - [[pdfs/dl/theory/the_dual_form_of_neural_networks_revisited_connecting_test_time_predictions_to_training_patterns_via_spotlights_of_attention.pdf|The Dual Form of Neural Networks Revisited: Connecting Test Time Predictions to Training Patterns via Spotlights of Attention.]]: (cite: conf/icml/IrieCS22) Explains what we mean when we say that neural networks "memorize the training set" with an analogy attention between the dataset and the latent variables of the network itself . [[papers/dl/theory/the_dual_form_of_neural_networks_revisited_connecting_test_time_predictions_to_training_patterns_via_spotlights_of_attention.md|Notes]]
 - [[pdfs/dl/theory/modern_math_deep_learning.pdf|The Modern Mathematics of Deep Learning.]]: (cite: journals/corr/abs-2105-04026/Berner/2021) . [[papers/dl/theory/modern_math_deep_learning.md|Notes]]
 - [[pdfs/dl/theory/understanding_dataset_difficulty_with_v_usable_information.pdf|Understanding Dataset Difficulty with V-Usable Information.]]: (cite: conf/icml/EthayarajhCS22) Proposes the idea of $\mathcal{V}$-usable information with respect to a model $\mathcal{V}$ for a more instructive metric of how difficult a dataset is. in practice PVI can help find mislabelled instances, or instances that are likely to be mispredicted. [[papers/dl/theory/understanding_dataset_difficulty_with_v_usable_information.md|Notes]]
 - [[pdfs/dl/theory/uniform_priors_for_data_efficient_learning.pdf|Uniform Priors for Data-Efficient Learning.]]: (cite: conf/cvpr/SinhaRGGALG22) . [[papers/dl/theory/uniform_priors_for_data_efficient_learning.md|Notes]]
 - [[pdfs/dl/theory/what_can_linear_interpolation_of_neural_network_loss_landscapes_tell_us.pdf|What can linear interpolation of neural network loss landscapes tell us?]]: (cite: journals/corr/abs-2106-16004/Vlaar/2021) . [[papers/dl/theory/what_can_linear_interpolation_of_neural_network_loss_landscapes_tell_us.md|Notes]]
 - [[pdfs/dl/theory/why_neural_networks_find_simple_solutions_the_many_regularizers_of_geometric_complexity.pdf|Why neural networks find simple solutions: the many regularizers of geometric complexity.]]: (cite: journals/corr/abs-2209-13083/Dherin/2022) . [[papers/dl/theory/why_neural_networks_find_simple_solutions_the_many_regularizers_of_geometric_complexity.md|Notes]]
 - [[pdfs/dl/theory/on_feature_learning_in_the_prescence_of_spurious_correlations.pdf|on_feature_learning_in_the_prescence_of_spurious_correlations]]: . [[papers/dl/theory/on_feature_learning_in_the_prescence_of_spurious_correlations.md|Notes]]
## transformer
 - [[pdfs/dl/transformer/dong_attention_is_not_all_you_need.pdf|Attention is not all you need: pure attention loses rank doubly exponentially with depth.]]: (cite: conf/icml/DongCL21) . [[papers/dl/transformer/dong_attention_is_not_all_you_need.md|Notes]]
 - [[pdfs/dl/transformer/block_recurrent_transformers.pdf|Block-Recurrent Transformers.]]: (cite: journals/corr/abs-2203-07852/Hutchins/2022) . [[papers/dl/transformer/block_recurrent_transformers.md|Notes]]
 - [[pdfs/dl/transformer/evolving_attention_with_redisual_convolutions.pdf|Evovlving Attention with Residual Connections]]: . [[papers/dl/transformer/evolving_attention_with_redisual_convolutions.md|Notes]]
 - [[pdfs/dl/transformer/extreme_compression_for_pre_trained_transformers_made_simple_and_efficient.pdf|Extreme Compression for Pre-trained Transformers Made Simple and Efficient.]]: (cite: journals/corr/abs-2206-01859/Wu/2022) . [[papers/dl/transformer/extreme_compression_for_pre_trained_transformers_made_simple_and_efficient.md|Notes]]
 - [[pdfs/dl/transformer/hierarhical_transformers_are_more_efficient_language_models.pdf|Hierarchical Transformers Are More Efficient Language Models.]]: (cite: conf/naacl/NawrotTTKWSM22) . [[papers/dl/transformer/hierarhical_transformers_are_more_efficient_language_models.md|Notes]]
 - [[pdfs/dl/transformer/improving_transformers_with_probabilistic_attention_keys.pdf|Improving Transformers with Probabilistic Attention Keys.]]: (cite: conf/icml/NguyenNLNTBHO22) Transformers can learn redundant heads. Replace redundant heads with a mixture of keys following a GMM. [[papers/dl/transformer/improving_transformers_with_probabilistic_attention_keys.md|Notes]]
 - [[pdfs/dl/transformer/insertion_transformer.pdf|Insertion Transformer: Flexible Sequence Generation via Insertion Operations.]]: (cite: conf/icml/SternCKU19) . [[papers/dl/transformer/insertion_transformer.md|Notes]]
 - [[pdfs/dl/transformer/energy_transformer.pdf|IrEne: Interpretable Energy Prediction for Transformers.]]: (cite: conf/acl/CaoLTBB20) . [[papers/dl/transformer/energy_transformer.md|Notes]]
 - [[pdfs/dl/transformer/learning_deep_transformer_models_for_machine_translation.pdf|Learning Deep Transformer Models for Machine Translation.]]: (cite: conf/acl/WangLXZLWC19) . [[papers/dl/transformer/learning_deep_transformer_models_for_machine_translation.md|Notes]]
 - [[pdfs/dl/transformer/on_the_learning_of_non_autoregressive_transformers.pdf|On the Learning of Non-Autoregressive Transformers.]]: (cite: conf/icml/HuangTZLH22) Discussion of the theoretical and empirical challenges of learning non-autoregressive transformers, explaining its hard to learn without the inductive bias that autoregressive gives you. [[papers/dl/transformer/on_the_learning_of_non_autoregressive_transformers.md|Notes]]
 - [[pdfs/dl/transformer/pondernet_learning_to_ponder.pdf|PonderNet: Learning to Ponder.]]: (cite: journals/corr/abs-2107-05407/Banino/2021) . [[papers/dl/transformer/pondernet_learning_to_ponder.md|Notes]]
 - [[pdfs/dl/transformer/recurrent_memory_transformer.pdf|Recurrent Memory Transformer.]]: (cite: journals/corr/abs-2207-06881/Bulatov/2022) . [[papers/dl/transformer/recurrent_memory_transformer.md|Notes]]
 - [[pdfs/dl/transformer/relaxed_attention_for_transformer_models.pdf|Relaxed Attention for Transformer Models.]]: (cite: journals/corr/abs-2209-09735/Lohrenz/2022) . [[papers/dl/transformer/relaxed_attention_for_transformer_models.md|Notes]]
 - [[pdfs/dl/transformer/self_attention_relative_position_representations.pdf|Self-Attention with Relative Position Representations.]]: (cite: conf/naacl/ShawUV18) . [[papers/dl/transformer/self_attention_relative_position_representations.md|Notes]]
 - [[pdfs/dl/transformer/set_transformer.pdf|Set Transformer - A Framework for Attention-based Permutation-Invariant Neural Networks.]]: (cite: conf/icml/LeeLKKCT19) Uses inducing points within the attention blocks to reduce the computational complexity. Does this over toy problems and amortized clustering with mixtured of Gaussians and Anomaly Detection . [[papers/dl/transformer/set_transformer.md|Notes]]
 - [[pdfs/dl/transformer/staircase_attention_for_recurrent_processing_of_sequences.pdf|Staircase Attention for Recurrent Processing of Sequences.]]: (cite: journals/corr/abs-2106-04279/Ju/2021) . [[papers/dl/transformer/staircase_attention_for_recurrent_processing_of_sequences.md|Notes]]
 - [[pdfs/dl/transformer/systematic_generalization_with_edge_transfromers.pdf|Systematic Generalization with Edge Transformers.]]: (cite: conf/nips/BergenOB21) . [[papers/dl/transformer/systematic_generalization_with_edge_transfromers.md|Notes]]
 - [[pdfs/dl/transformer/tab_transformer_tabular_data_modeling.pdf|TabTransformer: Tabular Data Modeling Using Contextual Embeddings.]]: (cite: journals/corr/abs-2012-06678/Huang/2020) . [[papers/dl/transformer/tab_transformer_tabular_data_modeling.md|Notes]]
 - [[pdfs/dl/transformer/temporal_latent_bottleneck_synthesis_of_fast_and_slow_processing_mechanisms_in_sequence_learning.pdf|Temporal Latent Bottleneck: Synthesis of Fast and Slow Processing Mechanisms in Sequence Learning.]]: (cite: journals/corr/abs-2205-14794/Didolkar/2022) . [[papers/dl/transformer/temporal_latent_bottleneck_synthesis_of_fast_and_slow_processing_mechanisms_in_sequence_learning.md|Notes]]
 - [[pdfs/dl/transformer/simple_tricks_to_improve_generalization_of_transformers.pdf|The Devil is in the Detail: Simple Tricks Improve Systematic Generalization of Transformers.]]: (cite: conf/emnlp/CsordasIS21) . [[papers/dl/transformer/simple_tricks_to_improve_generalization_of_transformers.md|Notes]]
 - [[pdfs/dl/transformer/the_devil_is_in_the_detail_simple_tricks_to_improve_systematic_generalization_of_transformers.pdf|The Devil is in the Detail: Simple Tricks to Improve Systematic Generalization of Transformers]]: Studies what is required to make generalization work well in transformers. For length-generalization, the [[universal_transformers]] architecture with relative positional encoding works well, in other cases, what can help is scaling the embeddings properly (eg, downscaling positional encodings) and also proper model selection (eg, early stopping can leave a lot of generalization performance on the table). [[papers/dl/transformer/the_devil_is_in_the_detail_simple_tricks_to_improve_systematic_generalization_of_transformers.md|Notes]]
 - [[pdfs/dl/transformer/theoretical_limitations_of_self_attention_in_nerual_sequence_models.pdf|Theoretical Limitations of Self-Attention in Neural Sequence Models.]]: (cite: journals/tacl/Hahn20) . [[papers/dl/transformer/theoretical_limitations_of_self_attention_in_nerual_sequence_models.md|Notes]]
 - [[pdfs/dl/transformer/transfer_inductive_bias_distillation.pdf|Transferring Inductive Biases through Knowledge Distillation.]]: (cite: journals/corr/abs-2006-00555/Abnar/2020) . [[papers/dl/transformer/transfer_inductive_bias_distillation.md|Notes]]
 - [[pdfs/dl/transformer/transformer_xl_attentive_language_models_beyond_a_fixed_length_context.pdf|Transformer-XL - Attentive Language Models Beyond a Fixed-Length Context.]]: (cite: journals/corr/abs-1901-02860/Dai/2019) . [[papers/dl/transformer/transformer_xl_attentive_language_models_beyond_a_fixed_length_context.md|Notes]]
 - [[pdfs/dl/transformer/tuformer_data_driven_design_of_transformers_for_improved_generalization_or_efficiency.pdf|Tuformer: Data Driven Design of Transformers for Improved Genearlization or Efficiency]]: Standard transformer has a predefined number of heads and is not flexible. In Tuformer, the number of heads is trainable. . [[papers/dl/transformer/tuformer_data_driven_design_of_transformers_for_improved_generalization_or_efficiency.md|Notes]]
 - [[pdfs/dl/transformer/universal_transformers.pdf|Universal Transformers.]]: (cite: conf/iclr/DehghaniGVUK19) Combines the global receptive field of transformers with the weight-sharing inductive bias of RNN. So basically a transformer but the weights are shared across layers, plus, a dynamic halting mechanism.  . [[universal_transformers|Notes]]. [[papers/dl/transformer/universal_transformers.md|Notes]]
 - [[pdfs/dl/transformer/wide_attention_is_the_way_forward_for_transformers.pdf|Wide Attention Is The Way Forward For Transformers.]]: (cite: journals/corr/abs-2210-00640/Brown/2022) . [[papers/dl/transformer/wide_attention_is_the_way_forward_for_transformers.md|Notes]]
 - [[pdfs/dl/transformer/an_adaptive_temporal_attention_mechanism_to_address_distribution_shifts.pdf|an_adaptive_temporal_attention_mechanism_to_address_distribution_shifts]]: . [[papers/dl/transformer/an_adaptive_temporal_attention_mechanism_to_address_distribution_shifts.md|Notes]]
 - [[pdfs/dl/transformer/efficient_queries_transformer_neural_processes.pdf|efficient_queries_transformer_neural_processes]]: . [[papers/dl/transformer/efficient_queries_transformer_neural_processes.md|Notes]]
 - [[pdfs/dl/transformer/first_detrend_then_attend_rethinking_attention_for_timeseries_forecasting.pdf|first_detrend_then_attend_rethinking_attention_for_timeseries_forecasting]]: . [[papers/dl/transformer/first_detrend_then_attend_rethinking_attention_for_timeseries_forecasting.md|Notes]]
 - [[pdfs/dl/transformer/improving_transformer_with_an_admixture_of_attention_heads.pdf|improving_transformer_with_an_admixture_of_attention_heads]]: . [[papers/dl/transformer/improving_transformer_with_an_admixture_of_attention_heads.md|Notes]]
 - [[pdfs/dl/transformer/token_mixup_efficient_attention_guided_token_level_data_augmentation_for_transformers.pdf|token_mixup_efficient_attention_guided_token_level_data_augmentation_for_transformers]]: . [[papers/dl/transformer/token_mixup_efficient_attention_guided_token_level_data_augmentation_for_transformers.md|Notes]]
### analysis
 - [[pdfs/dl/transformer/analysis/analyzing_transformers_in_embedding_space.pdf|Analyzing Transformers in Embedding Space.]]: (cite: journals/corr/abs-2209-02535/Dar/2022) . [[papers/dl/transformer/analysis/analyzing_transformers_in_embedding_space.md|Notes]]
 - [[pdfs/dl/transformer/analysis/attention_is_not_only_a_weight_analyzing_transformers_with_vector_norms.pdf|Attention is Not Only a Weight: Analyzing Transformers with Vector Norms.]]: (cite: conf/emnlp/KobayashiKYI20) . [[papers/dl/transformer/analysis/attention_is_not_only_a_weight_analyzing_transformers_with_vector_norms.md|Notes]]
 - [[pdfs/dl/transformer/analysis/quantifying_attention_flow_transformers.pdf|Quantifying Attention Flow in Transformers.]]: (cite: conf/acl/AbnarZ20) . [[papers/dl/transformer/analysis/quantifying_attention_flow_transformers.md|Notes]]
 - [[pdfs/dl/transformer/analysis/attcat_explaining_transformers_via_attentive_class_tokens.pdf|attcat_explaining_transformers_via_attentive_class_tokens]]: . [[papers/dl/transformer/analysis/attcat_explaining_transformers_via_attentive_class_tokens.md|Notes]]
### circuits
 - [[pdfs/dl/transformer/circuits/routing_transfomer.pdf|Efficient Content-Based Sparse Attention with Routing Transformers.]]: (cite: journals/tacl/RoySVG21) . [[papers/dl/transformer/circuits/routing_transfomer.md|Notes]]
### compositional
 - [[pdfs/dl/transformer/compositional/causal_transformers_improving_robustness_on_spurious_correlations.pdf|Causal Transformers: Improving the Robustness on Spurious Correlations]]: . [[papers/dl/transformer/compositional/causal_transformers_improving_robustness_on_spurious_correlations.md|Notes]]
 - [[pdfs/dl/transformer/compositional/learning_adaptive_control_flow_in_transformers_for_improved_systematic_generalization.pdf|Learning Adaptive Control Flow in Transformers for Improved Systematic Generalization]]: Transformers fail to find intuitive solutions that route relevant information to the right node/operation at the right time in the grid represented by the transformer columns. They come up with a Neural Data Router which acheives 100% length generalization accuracy. Â Their contributions are a copy gate and geometric attention. The copy-gate is essentially just a residual connection with gating on the transformer layer, though it is parameterized by the result of the self-attention as opposed to by a single weight. Geometric attention attends to the closest-mathcing-element. Â Instead of softmax, do sigmoid. Diagonal zero-ed out. Then attention is computed between $i$ and $j$ using source indices which are closer to $i$ than $j$, then you take the product over the converse all of them. The result is that if other things have some probability weight, then they make $A_{ij}$ smaller. [[papers/dl/transformer/compositional/learning_adaptive_control_flow_in_transformers_for_improved_systematic_generalization.md|Notes]]
 - [[pdfs/dl/transformer/compositional/making_transformers_solve_compositional_tasks.pdf|Making Transformers Solve Compositional Tasks.]]: (cite: journals/corr/abs-2108-04378/Ontanon/2021) Challenges the notion that "transformers can't solve compositional tasks". Relative positional encodings help, particularly "relative position embeddings" where distances are encoded with embeddings, a copy decoder helps, weight sharing helps (see the result in [[the_devil_is_in_the_detail_simple_tricks_to_improve_systematic_generalization_of_transformers]]). [[papers/dl/transformer/compositional/making_transformers_solve_compositional_tasks.md|Notes]]
 - [[pdfs/dl/transformer/compositional/transformers_with_competitive_ensembles_of_independent_mechanisms.pdf|Transformers with Competitive Ensembles of Independent Mechanisms.]]: (cite: journals/corr/abs-2103-00336/Lamb/2021) . [[papers/dl/transformer/compositional/transformers_with_competitive_ensembles_of_independent_mechanisms.md|Notes]]
 - [[pdfs/dl/transformer/compositional/attention_for_compositional_modularity.pdf|attention_for_compositional_modularity]]: . [[papers/dl/transformer/compositional/attention_for_compositional_modularity.md|Notes]]
### disentangling
 - [[pdfs/dl/transformer/disentangling/deberta_decoding_enhanced_bert.pdf|DeBERTa: Decoding-enhanced BERT with Disentangled Attention.]]: (cite: journals/corr/abs-2006-03654/He/2020) . [[papers/dl/transformer/disentangling/deberta_decoding_enhanced_bert.md|Notes]]
 - [[pdfs/dl/transformer/disentangling/exploiting_the_inductive_bias_in_transformers_for_unsupervised_disentanglement_of_syntax_and_semantics.pdf|Exploiting the Inductive Bias in Transformers for Unsupervised Disentanglement of Syntax and Semantics]]: . [[papers/dl/transformer/disentangling/exploiting_the_inductive_bias_in_transformers_for_unsupervised_disentanglement_of_syntax_and_semantics.md|Notes]]
### fourier
 - [[pdfs/dl/transformer/fourier/fnet_mixing_tokens_fourier_transforms.pdf|FNet: Mixing Tokens with Fourier Transforms.]]: (cite: conf/naacl/Lee-ThorpAEO22) . [[papers/dl/transformer/fourier/fnet_mixing_tokens_fourier_transforms.md|Notes]]
 - [[pdfs/dl/transformer/fourier/fourierformer_transformer_meets_generalized_fourier_integral_theorem.pdf|fourierformer_transformer_meets_generalized_fourier_integral_theorem]]: . [[papers/dl/transformer/fourier/fourierformer_transformer_meets_generalized_fourier_integral_theorem.md|Notes]]
### grokking
 - [[pdfs/dl/transformer/grokking/grokking_generalization_beyond_overfitting_on_small_algorithmic_datasets.pdf|Grokking - Generalization Beyond Overfitting on Small Algorithmic Datasets.]]: (cite: journals/corr/abs-2201-02177/Power/2022) Shows the power of the Transformer architecture to generalize to datasets generated by applying rules to the input. Improvements in generalization happen past the point of overfitting. In particular, transformers can generalize to empty lots in a variety of binary op tables, but the amount of optimization required is an inverse function of datset size. Weight decay seems to help a lot in improving data efficiency on this problem. [[papers/dl/transformer/grokking/grokking_generalization_beyond_overfitting_on_small_algorithmic_datasets.md|Notes]]
 - [[pdfs/dl/transformer/grokking/omnigrok_grokking_beyond_algorithmic_data.pdf|Omnigrok: Grokking Beyond Algorithmic Data.]]: (cite: journals/corr/abs-2210-01117/Liu/2022) . [[papers/dl/transformer/grokking/omnigrok_grokking_beyond_algorithmic_data.md|Notes]]
 - [[pdfs/dl/transformer/grokking/towards_understanding_grokking_an_effective_theory_of_representation_learning.pdf|Towards Understanding Grokking: An Effective Theory of Representation Learning.]]: (cite: journals/corr/abs-2205-10343/Liu/2022) . [[papers/dl/transformer/grokking/towards_understanding_grokking_an_effective_theory_of_representation_learning.md|Notes]]
### initialization
 - [[pdfs/dl/transformer/initialization/t_fixup_improving_transformer_optimization_through_better_initialization.pdf|Improving Transformer Optimization Through Better Initialization.]]: (cite: conf/icml/HuangPBV20) Introduces T-Fixup initialization scheme . [[papers/dl/transformer/initialization/t_fixup_improving_transformer_optimization_through_better_initialization.md|Notes]]
 - [[pdfs/dl/transformer/initialization/admin_initialization_understanding_difficulty_training_transformers.pdf|Understanding the Difficulty of Training Transformers.]]: (cite: conf/emnlp/LiuLGCH20) Introduces the ADMIN initialization scheme. [[papers/dl/transformer/initialization/admin_initialization_understanding_difficulty_training_transformers.md|Notes]]
### linear
 - [[pdfs/dl/transformer/linear/adaptive_attention_transformer.pdf|Adaptive Attention Span in Transformers.]]: (cite: conf/acl/SukhbaatarGBJ19) . [[papers/dl/transformer/linear/adaptive_attention_transformer.md|Notes]]
 - [[pdfs/dl/transformer/linear/attention_free_transformer.pdf|An Attention Free Transformer.]]: (cite: journals/corr/abs-2105-14103/Zhai/2021) . [[papers/dl/transformer/linear/attention_free_transformer.md|Notes]]
 - [[pdfs/dl/transformer/linear/bigbird.pdf|Big Bird - Transformers for Longer Sequences.]]: (cite: conf/nips/ZaheerGDAAOPRWY20) . [[papers/dl/transformer/linear/bigbird.md|Notes]]
 - [[pdfs/dl/transformer/linear/flowformer_linearizing_transformers_with_conservation_flows.pdf|Flowformer: Linearizing Transformers with Conservation Flows.]]: (cite: conf/icml/WuWXWL22) Use flow-theory to linearize transformers, without the tradeoff of having to assume a local receptive field or decomposition in a way that might result in a degenerate attention distribution without any competition. [[papers/dl/transformer/linear/flowformer_linearizing_transformers_with_conservation_flows.md|Notes]]
 - [[pdfs/dl/transformer/linear/sparse_transformer.pdf|Generating Long Sequences with Sparse Transformers.]]: (cite: journals/corr/abs-1904-10509/Child/2019) . [[papers/dl/transformer/linear/sparse_transformer.md|Notes]]
 - [[pdfs/dl/transformer/linear/linformer.pdf|Linformer: Self-Attention with Linear Complexity.]]: (cite: journals/corr/abs-2006-04768/Wang/2020) . [[papers/dl/transformer/linear/linformer.md|Notes]]
 - [[pdfs/dl/transformer/linear/longformer.pdf|Longformer - The Long-Document Transformer.]]: (cite: journals/corr/abs-2004-05150/Beltagy/2020) . [[papers/dl/transformer/linear/longformer.md|Notes]]
 - [[pdfs/dl/transformer/linear/reformer.pdf|Reformer - The Efficient Transformer.]]: (cite: conf/iclr/KitaevKL20) Approximates attention by computing a sparse attention mask with locality sensitive hashing, then only computes attention between tokens that fall into the same LSH bucket. [[papers/dl/transformer/linear/reformer.md|Notes]]
 - [[pdfs/dl/transformer/linear/liutkus_relative_pos_encoding_linear_complex.pdf|Relative Positional Encoding for Transformers with Linear Complexity.]]: (cite: conf/icml/LiutkusCWSYR21) . [[papers/dl/transformer/linear/liutkus_relative_pos_encoding_linear_complex.md|Notes]]
 - [[pdfs/dl/transformer/linear/performer.pdf|Rethinking Attention with Performers.]]: (cite: conf/iclr/ChoromanskiLDSG21) Introduces the Performer Architecture. The big problem with attention is $\text{softmax}(QK^T)V$, eg $QK^T$ is $O(N^2)$ . However $K^TV$ is $O(D^2)$ which has nicer performance properties than $QK^T$. This paper presents a kernel-based approximation $Q'K'^TV' \approx \text{softmax}(QK^T)V$ which enables the use of the $O(D^2)$ formulation. [[papers/dl/transformer/linear/performer.md|Notes]]
 - [[pdfs/dl/transformer/linear/star_transformer.pdf|Star-Transformer.]]: (cite: conf/naacl/GuoQLSXZ19) . [[papers/dl/transformer/linear/star_transformer.md|Notes]]
 - [[pdfs/dl/transformer/linear/transformers_are_rnns.pdf|Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention.]]: (cite: conf/icml/KatharopoulosV020) . [[papers/dl/transformer/linear/transformers_are_rnns.md|Notes]]
### memory
 - [[pdfs/dl/transformer/memory/memorizing_transformers.pdf|Memorizing Transformers.]]: (cite: journals/corr/abs-2203-08913/Wu/2022) Augments the transformer with an external memory, where we do k-nearest-neighbours to look up similar tokens in that external memory. Combine the kNN-attention and local attention using a learned gate function (sigmoid). To deal with staleness in the memory, normalize queries and keys, which doesn't completely deal with the problem but at least helps to stabilize training. To update the memory, take the local context before the kNN Memory Attention layer and append it to the memory after the next model update . [[papers/dl/transformer/memory/memorizing_transformers.md|Notes]]
### meta
 - [[pdfs/dl/transformer/meta/data_distributional_properties_drive_emergent_few_shot_learning_in_transformers.pdf|Data Distributional Properties Drive Emergent Few-Shot Learning in Transformers]]: In-context learning comes from burstiness in the training data (class repeated many times in the context is also likely to be in the output) and from zipfian distribution of classes, which means that you don't remember stuff in the weights but instead rely on the context instead. [[papers/dl/transformer/meta/data_distributional_properties_drive_emergent_few_shot_learning_in_transformers.md|Notes]]
 - [[pdfs/dl/transformer/meta/what_can_transformers_learn_in_context_a_case_study_of_simple_function_classes.pdf|What Can Transformers Learn In-Context? A Case Study of Simple Function Classes.]]: (cite: journals/corr/abs-2208-01066/Garg/2022) . [[papers/dl/transformer/meta/what_can_transformers_learn_in_context_a_case_study_of_simple_function_classes.md|Notes]]
 - [[pdfs/dl/transformer/meta/general_purpose_in_context_learning_by_meta_learning_transformers.pdf|general_purpose_in_context_learning_by_meta_learning_transformers]]: . [[papers/dl/transformer/meta/general_purpose_in_context_learning_by_meta_learning_transformers.md|Notes]]
### nonparametric
 - [[pdfs/dl/transformer/nonparametric/npt_non_parametric_transformer_self_attention_going_beyond_individual_pairs.pdf|Self-Attention Between Datapoints: Going Beyond Individual Input-Output Pairs in Deep Learning.]]: (cite: "conf/nips/KossenBLGRG21",) Introduces the "Non-parametric Transformer" idea, which takes the entire dataset as input and predicts by explicitly learning interactions between the datapoints in a meta-learning sense . [[papers/dl/transformer/nonparametric/npt_non_parametric_transformer_self_attention_going_beyond_individual_pairs.md|Notes]]
### normalization
 - [[pdfs/dl/transformer/normalization/foundation_transformers.pdf|Foundation Transformers.]]: (cite: journals/corr/abs-2210-06423/Wang/2022) . [[papers/dl/transformer/normalization/foundation_transformers.md|Notes]]
 - [[pdfs/dl/transformer/normalization/normformer_improved_transformer_pretraining_with_extra_normalization.pdf|NormFormer: Improved Transformer Pretraining with Extra Normalization.]]: (cite: journals/corr/abs-2110-09456/Shleifer/2021) . [[papers/dl/transformer/normalization/normformer_improved_transformer_pretraining_with_extra_normalization.md|Notes]]
 - [[pdfs/dl/transformer/normalization/on_layer_normalization_in_the_transformer_architecture.pdf|On Layer Normalization in the Transformer Architecture.]]: (cite: conf/icml/XiongYHZZXZLWL20) . Do pre-normalization instead of post-normalization. Its more in-line with the residual nature of transformers. . [[papers/dl/transformer/normalization/on_layer_normalization_in_the_transformer_architecture.md|Notes]]
 - [[pdfs/dl/transformer/normalization/transformers_without_tears_improving_the_normalization_of_self_attention.pdf|Transformers without Tears: Improving the Normalization of Self-Attention.]]: (cite: conf/iwslt/NguyenS19) . [[papers/dl/transformer/normalization/transformers_without_tears_improving_the_normalization_of_self_attention.md|Notes]]
 - [[pdfs/dl/transformer/normalization/deepnet_scaling_transformers_to_1000_layers.pdf|deepnet_scaling_transformers_to_1000_layers]]: . [[papers/dl/transformer/normalization/deepnet_scaling_transformers_to_1000_layers.md|Notes]]
### perceiver
 - [[pdfs/dl/transformer/perceiver/hierarchical_perceiver.pdf|Hierarchical Perceiver.]]: (cite: journals/corr/abs-2202-10890/Carreira/2022) . [[papers/dl/transformer/perceiver/hierarchical_perceiver.md|Notes]]
 - [[pdfs/dl/transformer/perceiver/perceiver_io.pdf|PerceiverIO: A General Architecture for Structured Inputs and Outputs]]: Similar to [[set_transformer]], you have input sequences and output sequences likes [[vaswani_attention]] but there is a latent array (eg inducing points) which forms the queries for the inputs (instead of self-attention you have latent-key-value attention), then you do self-attention over the latent array at each layer instead of the input array. At the decoder you do cross-attention between the latent array and the output array, where the output array is the query. This is then applied to lots of different tasks to show general applicability. Its a nice way of dealing with the long sequence problem in transformers. . [[papers/dl/transformer/perceiver/perceiver_io.md|Notes]]
### performance
 - [[pdfs/dl/transformer/performance/rezero_is_all_you_need_fast_convergence_at_large_depth.pdf|ReZero is all you need: fast convergence at large depth.]]: (cite: conf/uai/BachlechnerMMCM21) . [[papers/dl/transformer/performance/rezero_is_all_you_need_fast_convergence_at_large_depth.md|Notes]]
 - [[pdfs/dl/transformer/performance/tempo_accelerating_transformer_based_model_training_through_memory_footprint_reduction.pdf|Tempo: Accelerating Transformer-Based Model Training through Memory Footprint Reduction.]]: (cite: journals/corr/abs-2210-10246/Andoorveedu/2022) . [[papers/dl/transformer/performance/tempo_accelerating_transformer_based_model_training_through_memory_footprint_reduction.md|Notes]]
### positional_encodings
 - [[pdfs/dl/transformer/positional_encodings/conditional_positional_encodings_vision_transformers.pdf|Conditional Positional Encodings for Vision Transformers]]: Conditional Positional Encodings are dynamically generated and conditioned on the local neighbourhood of the input tokens . [[papers/dl/transformer/positional_encodings/conditional_positional_encodings_vision_transformers.md|Notes]]
 - [[pdfs/dl/transformer/positional_encodings/conditional_positional_encodings_vit.pdf|Conditional Positional Encodings for Vision Transformers]]: . [[papers/dl/transformer/positional_encodings/conditional_positional_encodings_vit.md|Notes]]
 - [[pdfs/dl/transformer/positional_encodings/enhancing_the_transformer_with_explicit_relational_encodings_for_math_problem_solving.pdf|Enhancing the Transformer with Explicit Relational Encoding for Math Problem Solving.]]: (cite: journals/corr/abs-1910-06611/Schlag/2019) Incorporates Tensor-product represnetaitons within the Transformer to better support explicit representation of relation structure (TP-Transformer). Works well on math problems, goes beyond linear combinations. . [[papers/dl/transformer/positional_encodings/enhancing_the_transformer_with_explicit_relational_encodings_for_math_problem_solving.md|Notes]]
 - [[pdfs/dl/transformer/positional_encodings/permuteformer_efficient_relative_position_encoding_for_long_sequences.pdf|PermuteFormer: Efficient Relative Position Encoding for Long Sequences.]]: (cite: conf/emnlp/Chen21) . [[papers/dl/transformer/positional_encodings/permuteformer_efficient_relative_position_encoding_for_long_sequences.md|Notes]]
 - [[pdfs/dl/transformer/positional_encodings/rethinking_improving_relative_position_encoding_for_vision_transformer.pdf|Rethinking and Improving Relative Position Encoding for Vision Transformer.]]: (cite: conf/iccv/WuPCFC21) . [[papers/dl/transformer/positional_encodings/rethinking_improving_relative_position_encoding_for_vision_transformer.md|Notes]]
 - [[pdfs/dl/transformer/positional_encodings/roformer_transformer_rotary_position_embedding.pdf|RoFormer: Enhanced Transformer with Rotary Position Embedding.]]: (cite: journals/corr/abs-2104-09864/Su/2021) . [[papers/dl/transformer/positional_encodings/roformer_transformer_rotary_position_embedding.md|Notes]]
 - [[pdfs/dl/transformer/positional_encodings/self_attention_relative_positions.pdf|Self-Attention with Relative Position Representations.]]: (cite: conf/naacl/ShawUV18) . [[papers/dl/transformer/positional_encodings/self_attention_relative_positions.md|Notes]]
 - [[pdfs/dl/transformer/positional_encodings/towards_more_efficient_insertion_transformer_with_fractional_positional_encoding.pdf|Towards More Efficient Insertion Transformer with Fractional Positional Encoding.]]: (cite: journals/corr/abs-2112-06295/Zhang/2021) . [[papers/dl/transformer/positional_encodings/towards_more_efficient_insertion_transformer_with_fractional_positional_encoding.md|Notes]]
 - [[pdfs/dl/transformer/positional_encodings/your_transformer_may_not_be_as_powerful_as_you_expect.pdf|Your Transformer May Not be as Powerful as You Expect.]]: (cite: journals/corr/abs-2205-13401/Luo/2022) . [[papers/dl/transformer/positional_encodings/your_transformer_may_not_be_as_powerful_as_you_expect.md|Notes]]
### sparse
 - [[pdfs/dl/transformer/sparse/attention_with_sparsity_regularization.pdf|Attention With Sparsity Regularization for Neural Machine Translation and Summarization.]]: (cite: journals/taslp/ZhangZLZ19) Proposes a sparse attention model in which the sparsity regularization term is designed to augment the objective function. Two kinds of regularization explored: $L_{\infty}$  and entropy minimization. The L1 norm is not really suitable for regularizing the attention mask because it is always 1 (note: you can use it on the outer product before the attention mask is computed!). The $L_{\infty}$ norm regularizer effectively maximizes the biggest value and penalizes everything else. The minimum entropy regularizer takes an information theoretic approach and tries to make the attention distribution as sparse as possible . [[papers/dl/transformer/sparse/attention_with_sparsity_regularization.md|Notes]]
 - [[pdfs/dl/transformer/sparse/explicit_sparse_transformer_concentrated_attention_tthrough_explicit_selection.pdf|Explicit Sparse Transformer - Concentrated Attention Through Explicit Selection.]]: (cite: journals/corr/abs-1912-11637/Zhao/2019) Studies the usage of top-k attention on various problems and shows imporved performance and inference time. [[papers/dl/transformer/sparse/explicit_sparse_transformer_concentrated_attention_tthrough_explicit_selection.md|Notes]]
 - [[pdfs/dl/transformer/sparse/flashattention_fast_and_memory_efficient_exact_attention_with_io_awareness.pdf|FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness.]]: (cite: journals/corr/abs-2205-14135/Dao/2022) . [[papers/dl/transformer/sparse/flashattention_fast_and_memory_efficient_exact_attention_with_io_awareness.md|Notes]]
 - [[pdfs/dl/transformer/sparse/from_block_toeplitz_matrices_to_differential_equations_on_graphs_towards_a_general_theory_for_scalable_masked_transformers.pdf|From block-Toeplitz matrices to differential equations on graphs: towards a general theory for scalable masked Transformers.]]: (cite: conf/icml/ChoromanskiLCZS22) . [[papers/dl/transformer/sparse/from_block_toeplitz_matrices_to_differential_equations_on_graphs_towards_a_general_theory_for_scalable_masked_transformers.md|Notes]]
 - [[pdfs/dl/transformer/sparse/kroneckerbert_learning_kronecker_decomposition_for_pre_trained_language_models_via_knowledge_distillation.pdf|KroneckerBERT: Learning Kronecker Decomposition for Pre-trained Language Models via Knowledge Distillation.]]: (cite: journals/corr/abs-2109-06243/Tahaei/2021) . [[papers/dl/transformer/sparse/kroneckerbert_learning_kronecker_decomposition_for_pre_trained_language_models_via_knowledge_distillation.md|Notes]]
 - [[pdfs/dl/transformer/sparse/learning_multiscale_transformer_models_for_sequence_generation.pdf|Learning Multiscale Transformer Models for Sequence Generation.]]: (cite: conf/icml/LiZJJXZ22) Redefines "scale" to include sub-word scale, word scale, phrase scale. At which level do you apply the attention? Universal Multiscale Transfromer extracts features from different scales. [[papers/dl/transformer/sparse/learning_multiscale_transformer_models_for_sequence_generation.md|Notes]]
 - [[pdfs/dl/transformer/sparse/sact_learning_when_to_concentrate_or_divert_attention_self_adaptive_attention_temperature_for_neural_machine_translation.pdf|Learning When to Concentrate or Divert Attention: Self-Adaptive Attention Temperature for Neural Machine Translation.]]: (cite: conf/emnlp/Lin0RLS18) Introduce SACT, which is "self-adaptive control of temperature". Temperature parameter is learned based on information of the decoding timestep as well as attention in previous timesteps . [[papers/dl/transformer/sparse/sact_learning_when_to_concentrate_or_divert_attention_self_adaptive_attention_temperature_for_neural_machine_translation.md|Notes]]
 - [[pdfs/dl/transformer/sparse/resan_reinforced_self_attention_network_a_hybrid_of_hard_and_soft_attention_for_sequence_modeling.pdf|Reinforced Self-Attention Network: a Hybrid of Hard and Soft Attention for Sequence Modeling.]]: (cite: conf/ijcai/ShenZLJWZ18) Introduces RESA "Reinforced Self-Attention". Hard Attention trims the sequence for soft self-attention to process, while the soft-attention feeds the reward signal back to facilite training of the hard attention . [[papers/dl/transformer/sparse/resan_reinforced_self_attention_network_a_hybrid_of_hard_and_soft_attention_for_sequence_modeling.md|Notes]]
 - [[pdfs/dl/transformer/sparse/sdbert_sparse_distilbert_a_faster_and_smaller_bert.pdf|SDBERT: SparseDistilBERT, a faster and smaller BERT model.]]: (cite: journals/corr/abs-2208-10246/Vinoda/2022) . [[papers/dl/transformer/sparse/sdbert_sparse_distilbert_a_faster_and_smaller_bert.md|Notes]]
 - [[pdfs/dl/transformer/sparse/scatterbrain_unifying_sparse_and_low_rank_attention_approximation.pdf|Scatterbrain: Unifying Sparse and Low-rank Attention Approximation.]]: (cite: journals/corr/abs-2110-15343/Chen/2021) . [[papers/dl/transformer/sparse/scatterbrain_unifying_sparse_and_low_rank_attention_approximation.md|Notes]]
 - [[pdfs/dl/transformer/sparse/entmax_sparse_sequence_to_sequence_models.pdf|Sparse Sequence-to-Sequence Models.]]: (cite: conf/acl/PetersNM19) Introduces EntMax Sparse Output Layer and EntMax Sparse Attention. [[papers/dl/transformer/sparse/entmax_sparse_sequence_to_sequence_models.md|Notes]]
 - [[pdfs/dl/transformer/sparse/sparse_is_enough_in_scaling_transformers.pdf|Sparse is Enough in Scaling Transformers.]]: (cite: journals/corr/abs-2111-12763/Jaszczur/2021) . [[papers/dl/transformer/sparse/sparse_is_enough_in_scaling_transformers.md|Notes]]
 - [[pdfs/dl/transformer/sparse/top_kast_pascanu.pdf|Top-KAST - Top-K Always Sparse Training.]]: (cite: conf/nips/JayakumarPROE20) Proposes a method that maintains constant sparsity throughout training. Also demonstrates how sparser versions of common architectures can run with significantly fewer resources. It does not require computing the dense parameters first and then sparsifying later. Instead, it consists of selecting some subset of the parameters that correspond to the top-K parameters by parameter magnitude for each training step, then applying gradient steps to a superset of those. Then there's an auxiliary exploration loss to encourage the sparsity mask to adapt during training. To put it another way, you still keep all those parameters in memory, but you select one set to use for the foward pass and a superset of those to update using gradient descent. [[papers/dl/transformer/sparse/top_kast_pascanu.md|Notes]]
 - [[pdfs/dl/transformer/sparse/transformers_meet_stochastic_block_models_attention_with_data_adaptive_sparsity_and_cost.pdf|Transformers meet Stochastic Block Models: Attention with Data-Adaptive Sparsity and Cost.]]: (cite: journals/corr/abs-2210-15541/Cho/2022) . [[papers/dl/transformer/sparse/transformers_meet_stochastic_block_models_attention_with_data_adaptive_sparsity_and_cost.md|Notes]]
### theory
 - [[pdfs/dl/transformer/theory/a_mathematical_framework_for_transformer_circuits.pdf|A Mathematical Framework for Transformer Circuits]]: . [[papers/dl/transformer/theory/a_mathematical_framework_for_transformer_circuits.md|Notes]]
 - [[pdfs/dl/transformer/theory/formal_algorithms_for_transformers.pdf|Formal Algorithms for Transformers.]]: (cite: journals/corr/abs-2207-09238/Phuong/2022) . [[papers/dl/transformer/theory/formal_algorithms_for_transformers.md|Notes]]
 - [[pdfs/dl/transformer/theory/in_context_learning_and_induction_heads.pdf|In-context Learning and Induction Heads.]]: (cite: journals/corr/abs-2209-11895/Olsson/2022) . [[papers/dl/transformer/theory/in_context_learning_and_induction_heads.md|Notes]]
 - [[pdfs/dl/transformer/theory/signal_propagation_in_transformers_theoretical_perspective_and_the_role_of_rank_collapse.pdf|Signal Propagation in Transformers: Theoretical Perspectives and the Role of Rank Collapse.]]: (cite: journals/corr/abs-2206-03126/Noci/2022) . [[papers/dl/transformer/theory/signal_propagation_in_transformers_theoretical_perspective_and_the_role_of_rank_collapse.md|Notes]]
 - [[pdfs/dl/transformer/theory/thinking_like_transformers.pdf|Thinking Like Transformers.]]: (cite: conf/icml/WeissGY21) . [[papers/dl/transformer/theory/thinking_like_transformers.md|Notes]]
 - [[pdfs/dl/transformer/theory/transformers_from_an_optimization_perspective.pdf|Transformers from an Optimization Perspective.]]: (cite: journals/corr/abs-2205-13891/Yang/2022) . [[papers/dl/transformer/theory/transformers_from_an_optimization_perspective.md|Notes]]
### vision
 - [[pdfs/dl/transformer/vision/image_worth_16x16_words_transformers_for_image_recognition_at_scale.pdf|An Image is Worth 16x16 Words - Transformers for Image Recognition at Scale.]]: (cite: conf/iclr/DosovitskiyB0WZ21) First study to show that we can make use of a pure transformer network without baseline convolutions. Studies the scaling properties, in particular transfer learning properties when used with different pre-training dataset sizes. Argues that inductive bias stops mattering at the point where you have tons of data. [[papers/dl/transformer/vision/image_worth_16x16_words_transformers_for_image_recognition_at_scale.md|Notes]]
 - [[pdfs/dl/transformer/vision/crossvit_cross_attention_multi_scale_vision_transformer_for_image_classification.pdf|CrossViT: Cross-Attention Multi-Scale Vision Transformer for Image Classification.]]: (cite: conf/iccv/ChenFP21) . [[papers/dl/transformer/vision/crossvit_cross_attention_multi_scale_vision_transformer_for_image_classification.md|Notes]]
 - [[pdfs/dl/transformer/vision/do_vision_transformers_see_like_cnns.pdf|Do Vision Transformers See Like Convolutional Neural Networks?]]: (cite: conf/nips/RaghuUKZD21) . [[papers/dl/transformer/vision/do_vision_transformers_see_like_cnns.md|Notes]]
 - [[pdfs/dl/transformer/vision/efficientformer_vision_transformers_at_mobilenet_speed.pdf|EfficientFormer: Vision Transformers at MobileNet Speed.]]: (cite: journals/corr/abs-2206-01191/Li/2022) . [[papers/dl/transformer/vision/efficientformer_vision_transformers_at_mobilenet_speed.md|Notes]]
 - [[pdfs/dl/transformer/vision/emerging_properties_in_self_supervised_vision_transformers.pdf|Emerging Properties in Self-Supervised Vision Transformers.]]: (cite: conf/iccv/CaronTMJMBJ21) . [[papers/dl/transformer/vision/emerging_properties_in_self_supervised_vision_transformers.md|Notes]]
 - [[pdfs/dl/transformer/vision/detr_detectron_transformer_end_to_end_object_detection_with_transformers.pdf|End-to-End Object Detection with Transformers.]]: (cite: conf/eccv/CarionMSUKZ20) Introduces DETR (which is the "Detectron Transformer"). The output of the model is a set of box predictions and then there is a bipartite matching loss . [[papers/dl/transformer/vision/detr_detectron_transformer_end_to_end_object_detection_with_transformers.md|Notes]]
 - [[pdfs/dl/transformer/vision/robustness_vision_transformers.pdf|Understanding The Robustness of Vision Transformers for Image Classification.]]: . [[papers/dl/transformer/vision/robustness_vision_transformers.md|Notes]]
### vision_text
 - [[pdfs/dl/transformer/vision_text/causal_attention_catt.pdf|Causal Attention for Vision-Language Tasks.]]: (cite: conf/cvpr/YangZQ021) Dataset bias and skew can be a cofounding factor in attention due to lack of grounding. Proposes to include a global view of other training data points in the self-attention and cross-attention, so that you can disambiguate the confounding factor. [[papers/dl/transformer/vision_text/causal_attention_catt.md|Notes]]
 - [[pdfs/dl/transformer/vision_text/crrn_cross_modal_relational_reasoning_network_vqa.pdf|Cross-modal Relational Reasoning Network for Visual Question Answering.]]: (cite: conf/iccvw/ChenLP21a) CRRN network architecture, masks inconsistent attention map and highlights full latent alignments of corresponding word-region pairs. [[papers/dl/transformer/vision_text/crrn_cross_modal_relational_reasoning_network_vqa.md|Notes]]
 - [[pdfs/dl/transformer/vision_text/explainable_semantic_space_by_grounding_language_to_vision_with_cross_modal_contrastive_learning.pdf|Explainable Semantic Space by Grounding Language to Vision with Cross-Modal Contrastive Learning.]]: (cite: journals/corr/abs-2111-07180/Zhang/2021) . Empircal evaluation of language representations learned using vision-language grounding. Proposes a model that encodes images with VGG16 and text with BERT, then does contrastive learning in the shared representational space. Also proposes a cross-modal attention module to get "visually-grounded object representations" for each word, then computes relations using the proposed "Bilinear Relation Module". [[papers/dl/transformer/vision_text/explainable_semantic_space_by_grounding_language_to_vision_with_cross_modal_contrastive_learning.md|Notes]]
 - [[pdfs/dl/transformer/vision_text/flamingo.pdf|Flamingo: a Visual Language Model for Few-Shot Learning.]]: (cite: journals/corr/abs-2204-14198/Alayrac/2022) . [[papers/dl/transformer/vision_text/flamingo.md|Notes]]
 - [[pdfs/dl/transformer/vision_text/global_fusion_attention_for_vision_and_language_understanding.pdf|Global Fusion Attention for Vision and Language Understanding (Student Abstract).]]: (cite: conf/aaai/GuoLWB21) . [[papers/dl/transformer/vision_text/global_fusion_attention_for_vision_and_language_understanding.md|Notes]]
 - [[pdfs/dl/transformer/vision_text/illiterate_dall_e_learns_to_compose.pdf|Illiterate DALL-E Learns to Compose.]]: (cite: journals/corr/abs-2110-11405/Singh/2021) Aims to deal with object-centric learning. We don't just want to reconstruct the image but we want to recombine the slots with novel combinations. Existing methods have inconsistent composition problems, eg, if you take the floor slot from one, the wall slot from another and the object slot from a third, then mixing them together results in an inconsistent rendering. DALL-E can smoothly stitch together things by using a transformer decoder. (SLATE: Slot-Attention Transformer). Instead of a mixture decoder use a transformer decoder which renders each pixel one-by-one autoregressively conditioned on the input slots. The model can still discover objects like the mixture-decoder based models. This model renders consistently compared to [[slot_attention]]. Its a text-free DALL-E model, the inputs are slots instead of text descriptions. [[papers/dl/transformer/vision_text/illiterate_dall_e_learns_to_compose.md|Notes]]
 - [[pdfs/dl/transformer/vision_text/lxmert.pdf|LXMERT - Learning Cross-Modality Encoder Representations from Transformers.]]: (cite: conf/emnlp/TanB19) Pre-training of transformer with encoder for "object embeddings" (that came form an object detector) and sequence of word-embeddings.. [[papers/dl/transformer/vision_text/lxmert.md|Notes]]
 - [[pdfs/dl/transformer/vision_text/clip_transferable_visual_models_from_natural_language_supervision.pdf|Learning Transferable Visual Models From Natural Language Supervision.]]: (cite: conf/icml/RadfordKHRGASAM21) the CLIP paper. [[papers/dl/transformer/vision_text/clip_transferable_visual_models_from_natural_language_supervision.md|Notes]]
 - [[pdfs/dl/transformer/vision_text/oscar_object_semantics_aligned_pretraining_for_vision_language_tasks.pdf|Oscar: Object-Semantics Aligned Pre-training for Vision-Language Tasks.]]: (cite: conf/eccv/Li0LZHZWH0WCG20) . [[papers/dl/transformer/vision_text/oscar_object_semantics_aligned_pretraining_for_vision_language_tasks.md|Notes]]
 - [[pdfs/dl/transformer/vision_text/uniter.pdf|UNITER - UNiversal Image-TExt Representation Learning.]]: (cite: conf/eccv/ChenLYK0G0020) Use object-detection features and word embeddings like LXMERT and throw them all into one big transformer encoder with self-attention over everything. Four pre-training tasks, conditional masked language modelling (see the image, only see parts of the text), conditional masked region modelling (same thing in reverse), optimal transport between image sequence and word sequence and sentence/image matching. [[papers/dl/transformer/vision_text/uniter.md|Notes]]
 - [[pdfs/dl/transformer/vision_text/unicoder_vl_a_universal_encoder_for_vision_and_language_cross_modal_pre_training.pdf|Unicoder-VL: A Universal Encoder for Vision and Language by Cross-modal Pre-training.]]: (cite: journals/corr/abs-1908-06066/Li/2019) . [[papers/dl/transformer/vision_text/unicoder_vl_a_universal_encoder_for_vision_and_language_cross_modal_pre_training.md|Notes]]
 - [[pdfs/dl/transformer/vision_text/visual_question_answering_basedon_on_formal_logic.pdf|Visual Question Answering based on Formal Logic.]]: (cite: conf/icmla/SethuramanPFK21) . [[papers/dl/transformer/vision_text/visual_question_answering_basedon_on_formal_logic.md|Notes]]
 - [[pdfs/dl/transformer/vision_text/word2pix_word_to_pixel_cross_attention_transformer_in_visual_grounding.pdf|Word2Pix - Word to Pixel Cross Attention Transformer in Visual Grounding.]]: (cite: journals/corr/abs-2108-00205/Zhao/2021) A one-stage vison-language bounding box prediction network (for language queries intpo an image). Process the image with a CNN, then use pixels-to-words attention to build a representation on the (cls) token, such that you can use that to regress the bounding box, class and attributes. [[papers/dl/transformer/vision_text/word2pix_word_to_pixel_cross_attention_transformer_in_visual_grounding.md|Notes]]
 - [[pdfs/dl/transformer/vision_text/xdbert_distilling_visual_information_to_bert_from_cross_modal_systems_to_improve_language_understanding.pdf|XDBERT: Distilling Visual Information to BERT from Cross-Modal Systems to Improve Language Understanding.]]: (cite: conf/acl/HsuL022) . [[papers/dl/transformer/vision_text/xdbert_distilling_visual_information_to_bert_from_cross_modal_systems_to_improve_language_understanding.md|Notes]]
 - [[pdfs/dl/transformer/vision_text/dall_e.pdf|Zero-Shot Text-to-Image Generation.]]: (cite: conf/icml/RameshPGGVRCS21) DALL-E model. Trains a discrete VAE (VQ-VAE) to compress images into a 32x32 grid of tokens, each of which assumes some finite set of values. Concatenate 256 BPE encoded text tokens and train an autoregressive transforer to model the joint distribution over the two. To generate samples, give a caption and a generate some likely images, ranking them. [[papers/dl/transformer/vision_text/dall_e.md|Notes]]
## uncertainty
 - [[pdfs/dl/uncertainty/epistemic_neural_networks.pdf|Epistemic Neural Networks.]]: (cite: journals/corr/abs-2107-08924/Osband/2021) . [[papers/dl/uncertainty/epistemic_neural_networks.md|Notes]]
 - [[pdfs/dl/uncertainty/uncertainty_duq.pdf|Uncertainty Estimation Using a Single Deep Deterministic Neural Network.]]: (cite: conf/icml/AmersfoortSTG20) . [[papers/dl/uncertainty/uncertainty_duq.md|Notes]]
 - [[pdfs/dl/uncertainty/vos_learning_what_you_dont_know_by_virtual_outlier_synthesis.pdf|VOS: Learning What You Don&apos;t Know by Virtual Outlier Synthesis.]]: (cite: conf/iclr/DuWCL22) . [[papers/dl/uncertainty/vos_learning_what_you_dont_know_by_virtual_outlier_synthesis.md|Notes]]
 - [[pdfs/dl/uncertainty/out_of_distribution_detection_with_an_adaptive_likelihood_ratio_on_information_hierarchical_vae.pdf|out_of_distribution_detection_with_an_adaptive_likelihood_ratio_on_information_hierarchical_vae]]: . [[papers/dl/uncertainty/out_of_distribution_detection_with_an_adaptive_likelihood_ratio_on_information_hierarchical_vae.md|Notes]]
# ethics
 - [[pdfs/ethics/ai_now_2017.pdf|AI Now 2017 Report.]]: . [[papers/ethics/ai_now_2017.md|Notes]]
 - [[pdfs/ethics/ai_now_2019.pdf|AI Now 2019 Report.]]: . [[papers/ethics/ai_now_2019.md|Notes]]
 - [[pdfs/ethics/ai_and_global_south.pdf|AI and the Global South: Designing for Other Worlds.]]: . [[papers/ethics/ai_and_global_south.md|Notes]]
 - [[pdfs/ethics/india_case_studies.pdf|Big Data Governance in India: Case Studies.]]: . [[papers/ethics/india_case_studies.md|Notes]]
 - [[pdfs/ethics/data_feminism.pdf|Data Feminism: Teaching and Learning for Justice.]]: (cite: conf/iticse/DIgnazio21) . [[papers/ethics/data_feminism.md|Notes]]
 - [[pdfs/ethics/energy_policy_considerations.pdf|Energy and Policy Considerations for Deep Learning in NLP.]]: (cite: conf/acl/StrubellGM19) . [[papers/ethics/energy_policy_considerations.md|Notes]]
 - [[pdfs/ethics/politics_facial_recognition.pdf|Facial Recognition Technology can expose political orientation from naturalistic facial images]]: . [[papers/ethics/politics_facial_recognition.md|Notes]]
 - [[pdfs/ethics/hitchhikers_guide_3.pdf|Hitchhikers Guide to AI Ethics Part 3: What AI Does & Its Impact]]: . [[papers/ethics/hitchhikers_guide_3.md|Notes]]
 - [[pdfs/ethics/hitchhikers_guide_1.pdf|Hitchhikers guide to AI Ethics.]]: . [[papers/ethics/hitchhikers_guide_1.md|Notes]]
 - [[pdfs/ethics/hitchhikers_guide_2.pdf|Hitchikers Guide to AI Ethics Part 2: What AI Is]]: . [[papers/ethics/hitchhikers_guide_2.md|Notes]]
 - [[pdfs/ethics/litigatingalgorithms-2019-us.pdf|Litigating Algorithms: 2019 US Report]]: . [[papers/ethics/litigatingalgorithms-2019-us.md|Notes]]
 - [[pdfs/ethics/situation_method_in_magic.pdf|Situating Methods in the Magic of Big Data and Artificial Intelligence]]: . [[papers/ethics/situation_method_in_magic.md|Notes]]
 - [[pdfs/ethics/social_and_governance_implicaitons_of_improved_data_efficiency.pdf|Social and Governance Implications of Improved Data Efficiency.]]: (cite: conf/aies/TuckerAD20) Explores the socio-economic impacts of increased data efficiency. Examines the intuition that increased data efficiency will "erode the barriers to entry protecting incumbent data-rich AI firms" and finds that this intuition is only partially correct. The "access effect" is such that improved data efficiency enables new applications in data limited domains. The "performance effect" (not be confused with the "access effect") is about how much data is required to get superior performance, and here the power law and law of diminishing returns still applies - the base amount of data required to get started is lower and the exponential curve might be slightly flatter, but it is still exponential. . [[papers/ethics/social_and_governance_implicaitons_of_improved_data_efficiency.md|Notes]]
 - [[pdfs/ethics/bottom_of_the_data_pyramid.pdf|The Bottom of the Data Pyramid: Big Data and the Global South.]]: . [[papers/ethics/bottom_of_the_data_pyramid.md|Notes]]
## law
 - [[pdfs/ethics/law/ec-ai-regs-annexes.pdf|Annexes to the EC AI Act Proposal (2021)]]: . [[papers/ethics/law/ec-ai-regs-annexes.md|Notes]]
 - [[pdfs/ethics/law/ec-ai-regs-proposal.pdf|EC AI Act Proposal (2021)]]: . [[papers/ethics/law/ec-ai-regs-proposal.md|Notes]]
# explainability
 - [[pdfs/explainability/parameter_space_saliency_maps_explainability.pdf|Where do Models go Wrong? Parameter-Space Saliency Maps for Explainability.]]: (cite: journals/corr/abs-2108-01335/Levin/2021) . [[papers/explainability/parameter_space_saliency_maps_explainability.md|Notes]]
# gnn
 - [[pdfs/gnn/deep_path_knowledge_graph_reasoning.pdf|DeepPath: A Reinforcement Learning Method for Knowledge Graph Reasoning.]]: (cite: conf/emnlp/XiongHW17) . [[papers/gnn/deep_path_knowledge_graph_reasoning.md|Notes]]
 - [[pdfs/gnn/gnn_explainer.pdf|GNN Explainer: Generating Explanations for Graph Neural Networks.]]: . [[papers/gnn/gnn_explainer.md|Notes]]
 - [[pdfs/gnn/graph_neural_networks_are_dynamic_programmers.pdf|Graph Neural Networks are Dynamic Programmers.]]: (cite: journals/corr/abs-2203-15544/Dudzik/2022) . [[papers/gnn/graph_neural_networks_are_dynamic_programmers.md|Notes]]
 - [[pdfs/gnn/gnn_learnable_structural_and_positional_representations.pdf|Graph Neural Networks with Learnable Structural and Positional Representations.]]: (cite: journals/corr/abs-2110-07875/Dwivedi/2021) Have a separate learned position encoding plus position initializations based on $k$-hop random-walk features. [[papers/gnn/gnn_learnable_structural_and_positional_representations.md|Notes]]
 - [[pdfs/gnn/graph_star_net.pdf|Graph Star Net for Generalized Multi-Task Learning.]]: (cite: journals/corr/abs-1906-12330/Lu/2019) . [[papers/gnn/graph_star_net.md|Notes]]
 - [[pdfs/gnn/relational_gcn.pdf|Modeling Relational Data with Graph Convolutional Networks.]]: (cite: conf/esws/SchlichtkrullKB18) . [[papers/gnn/relational_gcn.md|Notes]]
## applications
### chemistry
 - [[pdfs/gnn/applications/chemistry/equivariant_3d_conditional_diffusion_models_for_molecular_linker_design.pdf|Equivariant 3D-Conditional Diffusion Models for Molecular Linker Design.]]: (cite: journals/corr/abs-2210-05274/Igashov/2022) . [[papers/gnn/applications/chemistry/equivariant_3d_conditional_diffusion_models_for_molecular_linker_design.md|Notes]]
### physics
 - [[pdfs/gnn/applications/physics/symbolic_regression_graph_inductive_bias.pdf|Discovering Symbolic Models from Deep Learning with Inductive Biases.]]: (cite: conf/nips/CranmerSBXCSH20) Similar idea to [[symbolic_physics_gnn]]. [[papers/gnn/applications/physics/symbolic_regression_graph_inductive_bias.md|Notes]]
 - [[pdfs/gnn/applications/physics/symbolic_physics_gnn.pdf|Learning Symbolic Physics with Graph Networks.]]: (cite: journals/corr/abs-1909-05862/Cranmer/2019) Take a graph network, then search for some equation that seems to fit what the graph network says, use the equation to try to generalize . [[papers/gnn/applications/physics/symbolic_physics_gnn.md|Notes]]
 - [[pdfs/gnn/applications/physics/simulate_physics_gnn.pdf|Learning to Simulated Complex Physics with Graph Networks]]: . [[papers/gnn/applications/physics/simulate_physics_gnn.md|Notes]]
# hw
 - [[pdfs/hw/accelerating_sparse_matrix_matrix_multiplication_with_gpu_tensor_cores.pdf|Accelerating sparse matrix-matrix multiplication with GPU Tensor Cores.]]: (cite: journals/cee/ZachariadisSGO20) . [[papers/hw/accelerating_sparse_matrix_matrix_multiplication_with_gpu_tensor_cores.md|Notes]]
 - [[pdfs/hw/heat_hardware_efficient_automatic_tensor_decomposition_for_transformer_compression.pdf|HEAT: Hardware-Efficient Automatic Tensor Decomposition for Transformer Compression.]]: (cite: journals/corr/abs-2211-16749/Gu/2022) . [[papers/hw/heat_hardware_efficient_automatic_tensor_decomposition_for_transformer_compression.md|Notes]]
 - [[pdfs/hw/pathways_asynchronous_distributed_dataflow_from_ml.pdf|Pathways: Asynchronous Distributed Dataflow for ML.]]: (cite: conf/mlsys/0001CDGHHILP0SS22) Google's big dataflow graph for training big models . [[papers/hw/pathways_asynchronous_distributed_dataflow_from_ml.md|Notes]]
 - [[pdfs/hw/scalable_training_of_language_models_using_jax_pjit_and_tpuv4.pdf|Scalable Training of Language Models using JAX pjit and TPUv4.]]: (cite: journals/corr/abs-2204-06514/Yoo/2022) . [[papers/hw/scalable_training_of_language_models_using_jax_pjit_and_tpuv4.md|Notes]]
# loss
 - [[pdfs/loss/unbiased_loss_functions.pdf|Unbiased Loss Functions for Extreme Classification With Missing Labels.]]: (cite: journals/corr/abs-2007-00237/Schultheis/2020) . [[papers/loss/unbiased_loss_functions.md|Notes]]
# math
 - [[pdfs/math/dl_derivative_solver_symbolic_seq2seq.pdf|Deep Learning for Symbolic Mathematics.]]: (cite: journals/corr/abs-1912-01412/Lample/2019) Do symbolic differentiation with a trained seq2seq network . [[papers/math/dl_derivative_solver_symbolic_seq2seq.md|Notes]]
 - [[pdfs/math/nau.pdf|Neural Arithmetic Units.]]: (cite: conf/iclr/MadsenJ20) . [[papers/math/nau.md|Notes]]
 - [[pdfs/math/thor_wielding_hammers_to_integrate_language_models_and_theorem_provers.pdf|Thor: Wielding Hammers to Integrate Language Models and Automated Theorem Provers.]]: (cite: journals/corr/abs-2205-10893/Jiang/2022) . [[papers/math/thor_wielding_hammers_to_integrate_language_models_and_theorem_provers.md|Notes]]
# meta
 - [[pdfs/meta/concept_learners.pdf|Concept Learners for Generalizable Few-Shot Learning.]]: (cite: journals/corr/abs-2007-07375/Cao/2020) . [[papers/meta/concept_learners.md|Notes]]
 - [[pdfs/meta/meta_few_shot_nlp.pdf|Meta-learning for Few-shot Natural Language Processing: A Survey.]]: (cite: journals/corr/abs-2007-09604/Yin/2020) . [[papers/meta/meta_few_shot_nlp.md|Notes]]
 - [[pdfs/meta/model_agnostic_meta_learning_for_fast_adaptation_of_deep_networks.pdf|Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.]]: (cite: conf/icml/FinnAL17) . [[papers/meta/model_agnostic_meta_learning_for_fast_adaptation_of_deep_networks.md|Notes]]
 - [[pdfs/meta/tasknorm_meta_learning.pdf|TaskNorm: Rethinking Batch Normalization for Meta-Learning.]]: (cite: conf/icml/Bronskill0RNT20) . [[papers/meta/tasknorm_meta_learning.md|Notes]]
# ml
 - [[pdfs/ml/identifying_and_correcting_label_bias_in_machine_learning.pdf|Identifying and Correcting Label Bias in Machine Learning.]]: (cite: conf/aistats/JiangN20) . [[papers/ml/identifying_and_correcting_label_bias_in_machine_learning.md|Notes]]
# nlp
 - [[pdfs/nlp/layout_lm_doc_understanding.pdf|LayoutLM: Pre-training of Text and Layout for Document Image Understanding.]]: (cite: conf/kdd/XuL0HW020) . [[papers/nlp/layout_lm_doc_understanding.md|Notes]]
 - [[pdfs/nlp/transferrable_visual_models_from_nl_supervision.pdf|Learning Transferrable Visual Models from Natural Language Supervision]]: . [[papers/nlp/transferrable_visual_models_from_nl_supervision.md|Notes]]
 - [[pdfs/nlp/out_of_distribution_detection_and_selective_generation_for_conditional_language_models.pdf|Out-of-Distribution Detection and Selective Generation for Conditional Language Models.]]: (cite: journals/corr/abs-2209-15558/Ren/2022) . [[papers/nlp/out_of_distribution_detection_and_selective_generation_for_conditional_language_models.md|Notes]]
 - [[pdfs/nlp/prado_on_device_doc_classification.pdf|PRADO: Projection Attention Networks for Document Classification On-Device.]]: (cite: conf/emnlp/KrishnamoorthiR19) . [[papers/nlp/prado_on_device_doc_classification.md|Notes]]
## applications
 - [[pdfs/nlp/applications/deep_neural_networks_for_youtube_recommendations.pdf|Deep Neural Networks for YouTube Recommendations.]]: (cite: conf/recsys/CovingtonAS16) . [[papers/nlp/applications/deep_neural_networks_for_youtube_recommendations.md|Notes]]
## causal
 - [[pdfs/nlp/causal/informativeness_and_invariance_two_perspectives_on_spurious_correlations_in_natural_language.pdf|Informativeness and Invariance: Two Perspectives on Spurious Correlations in Natural Language.]]: (cite: conf/naacl/Eisenstein22) . [[papers/nlp/causal/informativeness_and_invariance_two_perspectives_on_spurious_correlations_in_natural_language.md|Notes]]
## chatbots
 - [[pdfs/nlp/chatbots/towards_a_human_like_open_domain_chatbot.pdf|Towards a Human-like Open-Domain Chatbot.]]: (cite: journals/corr/abs-2001-09977/Adiwardana/2020) . [[papers/nlp/chatbots/towards_a_human_like_open_domain_chatbot.md|Notes]]
## compositional
 - [[pdfs/nlp/compositional/a_minimalist_dataset_for_systematic_generalization_of_perception_syntax_and_semantics.pdf|A minimalist dataset for systematic generalization of perception, syntax and semantics]]: New dataset, Handwritten Arithmetic with Integers (HINT). You get images and have to do arithmetic on them. They do experiments with RNN, Transformer, GPT3 and show that current models really struggle with this.. [[papers/nlp/compositional/a_minimalist_dataset_for_systematic_generalization_of_perception_syntax_and_semantics.md|Notes]]
 - [[pdfs/nlp/compositional/beyond_iid_three_levels_of_generalization_for_question_answering_on_knowledge_bases.pdf|Beyond I.I.D.: Three Levels of Generalization for Question Answering on Knowledge Bases.]]: (cite: conf/www/GuKVSLY021) . [[papers/nlp/compositional/beyond_iid_three_levels_of_generalization_for_question_answering_on_knowledge_bases.md|Notes]]
 - [[pdfs/nlp/compositional/cogs_a_compositional_generalization_challenge_based_on_semantic_interpretation.pdf|COGS: A Compositional Generalization Challenge Based on Semantic Interpretation.]]: (cite: conf/emnlp/KimL20) . [[papers/nlp/compositional/cogs_a_compositional_generalization_challenge_based_on_semantic_interpretation.md|Notes]]
 - [[pdfs/nlp/compositional/can_transformers_jump_around_right_in_natural_language_assessing_performance_transfromer_from_scan.pdf|Can Transformers Jump Around Right in Natural Language? Assessing Performance Transfer from SCAN.]]: (cite: conf/blackboxnlp/ChaabouniDK21) . [[papers/nlp/compositional/can_transformers_jump_around_right_in_natural_language_assessing_performance_transfromer_from_scan.md|Notes]]
 - [[pdfs/nlp/compositional/can_transformer_be_too_compositional_analyzing_idiom_processing_in_neural_machine_translation.pdf|Can Transformers be Too Compositional? Analyzing Idiom Processing in Neural Machine Translation]]: They study the case of an idiom, where the meaning does not follow directly from parts. NMT models canât really translate idioms accurately, usually they tend to overgeneralise and translate them part-by-part.. [[papers/nlp/compositional/can_transformer_be_too_compositional_analyzing_idiom_processing_in_neural_machine_translation.md|Notes]]
 - [[pdfs/nlp/compositional/categorizing_semantic_representations_for_neural_machine_translation.pdf|Categorizing Semantic Representations for Neural Machine Translation.]]: (cite: conf/coling/YinLMZ022) There is weakend performance during inference on unseen compositions during NMT. They address the issue by introuding categorisation to the source contextualized representations. They find prototypes of token representations over the training set and then integrate the embeddings into the encoding. Results in a 24% error rate reduction on CoGnition. They use a thing called a Proto-transformer. Proto-transformer does something called âprototype-attentionâ. You cluster the contextualized representations of each token to obtain prototype representations eg using kmeans. Then in the prototype transformer you do attention between prototypes and prototypes based on the lookup table. [[papers/nlp/compositional/categorizing_semantic_representations_for_neural_machine_translation.md|Notes]]
 - [[pdfs/nlp/compositional/compositional_generalization_for_neural_semantic_parsing_via_span_level_supervised_attention.pdf|Compositional Generalization for Neural Semantic Parsing via Span-level Supervised Attention.]]: (cite: conf/naacl/YinFNPPSTA21) . [[papers/nlp/compositional/compositional_generalization_for_neural_semantic_parsing_via_span_level_supervised_attention.md|Notes]]
 - [[pdfs/nlp/compositional/compositional_semantic_parsing_with_large_language_models.pdf|Compositional Semantic Parsing with Large Language Models.]]: (cite: journals/corr/abs-2209-15003/Drozdov/2022) . [[papers/nlp/compositional/compositional_semantic_parsing_with_large_language_models.md|Notes]]
 - [[pdfs/nlp/compositional/compositional_generalization_in_a_deep_seq2seq_model_by_separating_syntax_and_semantics.pdf|Compositional generalization in a deep seq2seq model by separating syntax and semantics.]]: (cite: journals/corr/abs-1904-09708/Russin/2019) . [[papers/nlp/compositional/compositional_generalization_in_a_deep_seq2seq_model_by_separating_syntax_and_semantics.md|Notes]]
 - [[pdfs/nlp/compositional/discovering_the_compositional_structure_of_vector_representations_with_role_learning_networks.pdf|Discovering the Compositional Structure of Vector Representations with Role Learning Networks.]]: (cite: conf/blackboxnlp/SoulosMLS20) They create an analysis technique called ROLE and show that RNNs can handle certain kinds of compositional tasks well. The method works by assigning structural worles to words, then combines word and role vectors using a closed form equation with learned parameters (elementwise product plus bias). Role embeddings can be seen like positional embeddings. ROLE learns to compute the role labels. It learns a dictionary of $n_R$ role embeddings and or each input symbol, does soft attention over these role vectors. Role-attention is encouraged to be one-hot. They also trained on some partly-compositional tasks (InferSent, Skip-thought, Stanford Sentiment Model and SPINN). [[papers/nlp/compositional/discovering_the_compositional_structure_of_vector_representations_with_role_learning_networks.md|Notes]]
 - [[pdfs/nlp/compositional/disentangled_sequence_to_sequence_learning_for_compositional_generalization.pdf|Disentangled Sequence to Sequence Learning for Compositional Generalization.]]: (cite: conf/acl/ZhengL22) One of the reasons why compositional generalization is hard is because of entangled representations. So they proposesequence-to-sequence models that are disentangled. The disentanglement happens by adaptively re-encoding the source input (eg, condition the source representations on the newly decoded target context, rather than capturing it all in a single forward pass). Basically their architecture is that on every decoding step, you pass the previously decoded targets to the encoder as well as part of the context (as  opposed to doing causal prediction in the decoder). They also applied their approach on CoGnition. [[papers/nlp/compositional/disentangled_sequence_to_sequence_learning_for_compositional_generalization.md|Notes]]
 - [[pdfs/nlp/compositional/evaluating_compositionality_of_sentence_representation_models.pdf|Evaluating Compositionality of Sentence Representation Models.]]: (cite: conf/rep4nlp/BhathenaWD20) . [[papers/nlp/compositional/evaluating_compositionality_of_sentence_representation_models.md|Notes]]
 - [[pdfs/nlp/compositional/generate_and_retrieve_use_your_predictions_to_improve_retrieval_for_semantic_parsing.pdf|Generate-and-Retrieve: use your predictions to improve retrieval for semantic parsing.]]: (cite: journals/corr/abs-2209-14899/Zemlyanskiy/2022) . [[papers/nlp/compositional/generate_and_retrieve_use_your_predictions_to_improve_retrieval_for_semantic_parsing.md|Notes]]
 - [[pdfs/nlp/compositional/geca_good_enough_compositional_data_augmentation.pdf|Good-Enough Compositional Data Augmentation.]]: (cite: conf/acl/Andreas20) . [[papers/nlp/compositional/geca_good_enough_compositional_data_augmentation.md|Notes]]
 - [[pdfs/nlp/compositional/hierarchical_poset_decoding_for_compositional_generalization_in_language.pdf|Hierarchical Poset Decoding for Compositional Generalization in Language.]]: (cite: conf/nips/GuoLLZ20) . [[papers/nlp/compositional/hierarchical_poset_decoding_for_compositional_generalization_in_language.md|Notes]]
 - [[pdfs/nlp/compositional/iterative_decoding_for_compositional_generalization_in_transformers.pdf|Iterative Decoding for Compositional Generalization in Transformers.]]: (cite: journals/corr/abs-2110-04169/Ruiz/2021) Length generalization is hard. Instead of seq2seq, do iterative decoding, eg, predict autoregressively one chunk until an end-of-chunk token, then clear the context and predict autoregressively the next chunk and so on. . [[papers/nlp/compositional/iterative_decoding_for_compositional_generalization_in_transformers.md|Notes]]
 - [[pdfs/nlp/compositional/jump_to_better_conclusions_scan_both_left_and_right.pdf|Jump to better conclusions: SCAN both left and right.]]: (cite: conf/emnlp/BastingsBWCK18) . [[papers/nlp/compositional/jump_to_better_conclusions_scan_both_left_and_right.md|Notes]]
 - [[pdfs/nlp/compositional/linda_unsupervised_learning_to_interpolate_in_natural_language_processing.pdf|LINDA: Unsupervised Learning to Interpolate in Natural Language Processing.]]: (cite: journals/corr/abs-2112-13969/Kim/2021) . [[papers/nlp/compositional/linda_unsupervised_learning_to_interpolate_in_natural_language_processing.md|Notes]]
 - [[pdfs/nlp/compositional/learning_to_generalize_compositionally_by_transferring_across_semantic_parsing_tasks.pdf|Learning to Generalize Compositionally by Transferring Across Semantic Parsing Tasks.]]: (cite: journals/corr/abs-2111-05013/Zhu/2021) . [[papers/nlp/compositional/learning_to_generalize_compositionally_by_transferring_across_semantic_parsing_tasks.md|Notes]]
 - [[pdfs/nlp/compositional/lexicon_learning_for_few_shot_neural_sequence_modeling.pdf|Lexicon Learning for Few-Shot Neural Sequence Modeling.]]: (cite: journals/corr/abs-2106-03993/Akyurek/2021) . [[papers/nlp/compositional/lexicon_learning_for_few_shot_neural_sequence_modeling.md|Notes]]
 - [[pdfs/nlp/compositional/measuring_compositional_generalization_a_comprehensive_method_on_realistic_data.pdf|Measuring Compositional Generalization: A Comprehensive Method on Realistic Data.]]: (cite: conf/iclr/KeysersSSBFKMSS20) . [[papers/nlp/compositional/measuring_compositional_generalization_a_comprehensive_method_on_realistic_data.md|Notes]]
 - [[pdfs/nlp/compositional/measuring_and_improving_compositional_generalization_in_text_to_sql_via_component_alignment.pdf|Measuring and Improving Compositional Generalization in Text-to-SQL via Component Alignment.]]: (cite: conf/naacl/GanCHP22) . [[papers/nlp/compositional/measuring_and_improving_compositional_generalization_in_text_to_sql_via_component_alignment.md|Notes]]
 - [[pdfs/nlp/compositional/on_compositional_generalization_of_neural_machine_translation.pdf|On Compositional Generalization of Neural Machine Translation.]]: (cite: conf/acl/LiYCZ20) . [[papers/nlp/compositional/on_compositional_generalization_of_neural_machine_translation.md|Notes]]
 - [[pdfs/nlp/compositional/on_the_ability_and_limitations_of_transfromers_to_recognize_formal_languages.pdf|On the Ability and Limitations of Transformers to Recognize Formal Languages.]]: (cite: conf/emnlp/BhattamishraAG20) . [[papers/nlp/compositional/on_the_ability_and_limitations_of_transfromers_to_recognize_formal_languages.md|Notes]]
 - [[pdfs/nlp/compositional/on_the_potential_of_lexico_logical_alignments_for_semantic_parsing_to_sql_queries.pdf|On the Potential of Lexico-logical Alignments for Semantic Parsing to SQL Queries.]]: (cite: conf/emnlp/ShiZBDL20) . [[papers/nlp/compositional/on_the_potential_of_lexico_logical_alignments_for_semantic_parsing_to_sql_queries.md|Notes]]
 - [[pdfs/nlp/compositional/posing_fair_generalization_tasks_for_natural_language_inference.pdf|Posing Fair Generalization Tasks for Natural Language Inference.]]: (cite: conf/emnlp/GeigerCKP19) Looks at providing a benchmark task for generalization tasks (eg, tasks that you expect the model to generalize to), but does so through the lens of fairness, where fairness means that the model actually has sufficient training data to solve the task. Defines a formal notion of fairness and applies these ideas to natural language inference by construction challenging but provably fair artificial datasets  Composition trees are defined using formal logic. A function $F$ with respect to a dataset is fair if the baseline model (not statistical! rule based) can learn $F$ from the training data. The paper then looks at statistical models on a provably fair function and dataset. The standard statistical models and attention based models don't do all that well on test data. The paper concludes that the problem is with the architecture, eg, recursive computation is required . [[papers/nlp/compositional/posing_fair_generalization_tasks_for_natural_language_inference.md|Notes]]
 - [[pdfs/nlp/compositional/rearranging_the_familiar_testing_compositional_generalization_in_recurrent_networks.pdf|Rearranging the Familiar: Testing Compositional Generalization in Recurrent Networks.]]: (cite: conf/emnlp/LoulaBL18) . [[papers/nlp/compositional/rearranging_the_familiar_testing_compositional_generalization_in_recurrent_networks.md|Notes]]
 - [[pdfs/nlp/compositional/revisit_systematic_generalization_via_meaningful_learning.pdf|Revisiting Systematic Generalization via Meaningful Learning]]: They suggest that models can successfully one-shot generalize to novel concepts and compositions after semantic linking either inductively or deductively. A semantic link is a lexical variant, co-hyponym or synonym. They also have some discussion of how they can solve systematic generalization problems on real data. They have this thing called vocabulary agumentation, where basically you make semantic links between primitives and their variants. They evaluate on Semantic Parsing and Machine Translation.. [[papers/nlp/compositional/revisit_systematic_generalization_via_meaningful_learning.md|Notes]]
 - [[pdfs/nlp/compositional/revisiting_the_compositional_generalization_abilities_of_neural_sequence_models.pdf|Revisiting the Compositional Generalization Abilities of Neural Sequence Models.]]: (cite: conf/acl/PatelBBG22) . [[papers/nlp/compositional/revisiting_the_compositional_generalization_abilities_of_neural_sequence_models.md|Notes]]
 - [[pdfs/nlp/compositional/seqzero_few_shot_compositional_semantic_parsing_with_sequential_prompts_and_zero_shot_models.pdf|SeqZero: Few-shot Compositional Semantic Parsing with Sequential Prompts and Zero-shot Models.]]: (cite: journals/corr/abs-2205-07381/Yang/2022) . [[papers/nlp/compositional/seqzero_few_shot_compositional_semantic_parsing_with_sequential_prompts_and_zero_shot_models.md|Notes]]
 - [[pdfs/nlp/compositional/sequence_level_mixed_sample_data_augmentation.pdf|Sequence-Level Mixed Sample Data Augmentation.]]: (cite: conf/emnlp/GuoKR20) . [[papers/nlp/compositional/sequence_level_mixed_sample_data_augmentation.md|Notes]]
 - [[pdfs/nlp/compositional/sequence_to_sequence_learning_with_latent_neural_grammars.pdf|Sequence-to-Sequence Learning with Latent Neural Grammars.]]: (cite: conf/nips/Kim21a) . [[papers/nlp/compositional/sequence_to_sequence_learning_with_latent_neural_grammars.md|Notes]]
 - [[pdfs/nlp/compositional/substructure_substitution_structured_data_augmentation_for_nlp.pdf|Substructure Substitution: Structured Data Augmentation for NLP.]]: (cite: conf/acl/ShiLG21) . [[papers/nlp/compositional/substructure_substitution_structured_data_augmentation_for_nlp.md|Notes]]
 - [[pdfs/nlp/compositional/syntactic_structure_from_deep_learning.pdf|Syntactic Structure from Deep Learning.]]: (cite: journals/corr/abs-2004-10827/Linzen/2020) Still issues with robustness, domain generalization etc in NMT. They made a dataset called CoGnition and demonstrate that NMT fails basely on compositional generalization splits. Bigger compound lengths lead to larger error. . [[papers/nlp/compositional/syntactic_structure_from_deep_learning.md|Notes]]
 - [[pdfs/nlp/compositional/systematic_generalization_emerges_in_seq2seq_models_with_variability_in_data.pdf|Systematic Generalization Emerges in Seq2Seq Models with Variability in Data]]: (cite: conf/acl/Andreas20) . [[papers/nlp/compositional/systematic_generalization_emerges_in_seq2seq_models_with_variability_in_data.md|Notes]]
 - [[pdfs/nlp/compositional/the_paradox_of_compositionality_in_natural_language_a_neural_machine_translation_case_study.pdf|The Paradox of Compositionality in Natural Language: A Neural Machine Translation Case Study]]: Compositionality in natural language is much more complex than the rigid arithmetic-like version that some datasets adhere to. The results highlight that models trained on more data are more compositional, models are sometimes less compositional than expected, some of the non-compositional beahviours are mistakes whereas others reflect variation in the data. For lower-resource settings, being compositional is particularly relevant. [[papers/nlp/compositional/the_paradox_of_compositionality_in_natural_language_a_neural_machine_translation_case_study.md|Notes]]
 - [[pdfs/nlp/compositional/towards_synthesizing_complex_programs_from_input_output_examples.pdf|Towards Synthesizing Complex Programs From Input-Output Examples.]]: (cite: conf/iclr/ChenLS18) . [[papers/nlp/compositional/towards_synthesizing_complex_programs_from_input_output_examples.md|Notes]]
 - [[pdfs/nlp/compositional/understanding_robust_generalization_in_learning_regular_languages.pdf|Understanding Robust Generalization in Learning Regular Languages.]]: (cite: conf/icml/DanBR22) Generalization in the contetx of using RNNs to learn a regular language. Predict intermediate states of a DFA when parsing a string. [[papers/nlp/compositional/understanding_robust_generalization_in_learning_regular_languages.md|Notes]]
 - [[pdfs/nlp/compositional/from_scan_to_real_data_systematic_generalization_via_meaningful_learning.pdf|from_scan_to_real_data_systematic_generalization_via_meaningful_learning]]: Same paper as â[[revisit_systematic_generalization_via_meaningful_learning|Revisiting Systematic Generalization via Meaningful Learning]â, ICLR submission]].. [[papers/nlp/compositional/from_scan_to_real_data_systematic_generalization_via_meaningful_learning.md|Notes]]
## data_augmentation
 - [[pdfs/nlp/data_augmentation/a_survey_of_data_augmentation_approaches_for_nlp.pdf|A Survey of Data Augmentation Approaches for NLP.]]: (cite: conf/acl/FengGWCVMH21) . [[papers/nlp/data_augmentation/a_survey_of_data_augmentation_approaches_for_nlp.md|Notes]]
 - [[pdfs/nlp/data_augmentation/grondal_text_oversampling_aug.pdf|A little goes a long way: Improving toxic language classification despite data scarcity.]]: (cite: conf/emnlp/JuutiGFA20) Oversampling the majority class into the minority class method for data augmentation . [[papers/nlp/data_augmentation/grondal_text_oversampling_aug.md|Notes]]
 - [[pdfs/nlp/data_augmentation/coda_data_augmentation_in_nlp.pdf|CoDA: Contrast-enhanced and Diversity-promoting Data Augmentation for Natural Language Understanding.]]: (cite: conf/iclr/QuSSSC021) . [[papers/nlp/data_augmentation/coda_data_augmentation_in_nlp.md|Notes]]
 - [[pdfs/nlp/data_augmentation/grondahl_combinatorial_paraphrasing.pdf|Effective writing style transfer via combinatorial paraphrasing.]]: (cite: journals/popets/GrondahlA20) . [[papers/nlp/data_augmentation/grondahl_combinatorial_paraphrasing.md|Notes]]
 - [[pdfs/nlp/data_augmentation/ssmba_self_supervised_manifold_based_data_augmentation_for_improving_out_of_domain_robustness.pdf|SSMBA: Self-Supervised Manifold Based Data Augmentation for Improving Out-of-Domain Robustness.]]: (cite: conf/emnlp/NgCG20) . [[papers/nlp/data_augmentation/ssmba_self_supervised_manifold_based_data_augmentation_for_improving_out_of_domain_robustness.md|Notes]]
 - [[pdfs/nlp/data_augmentation/treemix_compositional_constituency_based_data_augmentation_for_natural_language_understanding.pdf|TreeMix: Compositional Constituency-based Data Augmentation for Natural Language Understanding.]]: (cite: conf/naacl/ZhangYY22) . [[papers/nlp/data_augmentation/treemix_compositional_constituency_based_data_augmentation_for_natural_language_understanding.md|Notes]]
## datasets
 - [[pdfs/nlp/datasets/alchemy_a_benchmark_and_analysis_toolkit_for_meta_reinforcement_learning_agents.pdf|Alchemy: A benchmark and analysis toolkit for meta-reinforcement learning agents.]]: (cite: conf/nips/0001KPKZDCCRSBR21) . [[papers/nlp/datasets/alchemy_a_benchmark_and_analysis_toolkit_for_meta_reinforcement_learning_agents.md|Notes]]
 - [[pdfs/nlp/datasets/beyond_the_imitation_game_quantifying_and_extrapolating_the_capabilities_of_language_models.pdf|Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models.]]: (cite: journals/corr/abs-2206-04615/Srivastava/2022) . [[papers/nlp/datasets/beyond_the_imitation_game_quantifying_and_extrapolating_the_capabilities_of_language_models.md|Notes]]
 - [[pdfs/nlp/datasets/open_subtitles_paraphrase_corpus_for_six_languages.pdf|Open Subtitles Paraphrase Corpus for Six Languages.]]: (cite: conf/lrec/Creutz18) . [[papers/nlp/datasets/open_subtitles_paraphrase_corpus_for_six_languages.md|Notes]]
 - [[pdfs/nlp/datasets/question_and_answer_test_train_overlap_in_open_domain_question_answering_datasets.pdf|Question and Answer Test-Train Overlap in Open-Domain Question Answering Datasets.]]: (cite: conf/eacl/LewisSR21) . [[papers/nlp/datasets/question_and_answer_test_train_overlap_in_open_domain_question_answering_datasets.md|Notes]]
 - [[pdfs/nlp/datasets/right_for_the_wrong_reasons_diagnosing_syntactic_heuristics_in_natural_language_inference.pdf|Right for the Wrong Reasons: Diagnosing Syntactic Heuristics in Natural Language Inference.]]: (cite: conf/acl/McCoyPL19) . [[papers/nlp/datasets/right_for_the_wrong_reasons_diagnosing_syntactic_heuristics_in_natural_language_inference.md|Notes]]
 - [[pdfs/nlp/datasets/synthbio_a_case_study_in_human_ai_collaborative_curation_of_text_datasets.pdf|SynthBio - A Case Study in Human-AI Collaborative Curation of Text Datasets.]]: (cite: journals/corr/abs-2111-06467/Yuan/2021) . Use a language model to invent "fake facts" and balance attributes of the generated dataset with humans and evaluate on that. The point of this paper is more to say that evaluating NLG performance on hold-out sets of known-entities when you have a pretrained model on "the whole internet" is potentially problematic, since you have training/test distribution overlap. In this case, the model isn't actually learning to generate text from the infobox. Its learning to substitute common phrases in relation to the entity in question which it saw elsewhere in its training set. [[papers/nlp/datasets/synthbio_a_case_study_in_human_ai_collaborative_curation_of_text_datasets.md|Notes]]
 - [[pdfs/nlp/datasets/synthetic_data_generation_for_grammatical_error_correction_with_tagged_corruption_models.pdf|Synthetic Data Generation for Grammatical Error Correction with Tagged Corruption Models.]]: (cite: conf/bea/StahlbergK21) . [[papers/nlp/datasets/synthetic_data_generation_for_grammatical_error_correction_with_tagged_corruption_models.md|Notes]]
 - [[pdfs/nlp/datasets/textworld_a_learning_environment_for_text_based_games.pdf|TextWorld: A Learning Environment for Text-based Games.]]: (cite: journals/corr/abs-1806-11532/Cote/2018) . [[papers/nlp/datasets/textworld_a_learning_environment_for_text_based_games.md|Notes]]
## ethics
 - [[pdfs/nlp/ethics/ethical_and_social_risks_of_harm_from_language_models.pdf|Ethical and social risks of harm from Language Models.]]: (cite: journals/corr/abs-2112-04359/Weidinger/2021) . [[papers/nlp/ethics/ethical_and_social_risks_of_harm_from_language_models.md|Notes]]
 - [[pdfs/nlp/ethics/language_technology_is_power_a_critical_survey_of_bias_in_nlp.pdf|Language (Technology) is Power - A Critical Survey of &quot;Bias&quot; in NLP.]]: (cite: conf/acl/BlodgettBDW20) . [[papers/nlp/ethics/language_technology_is_power_a_critical_survey_of_bias_in_nlp.md|Notes]]
 - [[pdfs/nlp/ethics/on_the_danger_of_stochastic_parrots_can_language_models_be_too_big.pdf|On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?]]: (cite: conf/fat/BenderGMS21) . [[papers/nlp/ethics/on_the_danger_of_stochastic_parrots_can_language_models_be_too_big.md|Notes]]
## explainability
 - [[pdfs/nlp/explainability/inherently_explainable_reinforcement_learning_in_natural_language.pdf|Inherently Explainable Reinforcement Learning in Natural Language.]]: (cite: journals/corr/abs-2112-08907/Peng/2021) . [[papers/nlp/explainability/inherently_explainable_reinforcement_learning_in_natural_language.md|Notes]]
 - [[pdfs/nlp/explainability/lm_debugger_an_interactive_tool_for_inspection_and_intervention_in_transformer_based_language_models.pdf|LM-Debugger: An Interactive Tool for Inspection and Intervention in Transformer-Based Language Models.]]: (cite: journals/corr/abs-2204-12130/Geva/2022) . [[papers/nlp/explainability/lm_debugger_an_interactive_tool_for_inspection_and_intervention_in_transformer_based_language_models.md|Notes]]
 - [[pdfs/nlp/explainability/rethinking_attention_model_explainability_through_faithfulness_violation_test.pdf|Rethinking Attention-Model Explainability through Faithfulness Violation Test.]]: (cite: conf/icml/LiuLGKL022) Proposes the *faithfulness violation test* to be used in conjunction with attention-based explainability, because attention weights don't tell you anything about the polarity of the resulting operation, just the magnitude of importance. [[papers/nlp/explainability/rethinking_attention_model_explainability_through_faithfulness_violation_test.md|Notes]]
 - [[pdfs/nlp/explainability/tracing_knowledge_in_language_models_back_to_the_training_data.pdf|Tracing Knowledge in Language Models Back to the Training Data.]]: (cite: journals/corr/abs-2205-11482/Akyurek/2022) . [[papers/nlp/explainability/tracing_knowledge_in_language_models_back_to_the_training_data.md|Notes]]
## failure_modes
 - [[pdfs/nlp/failure_modes/real_toxicity_prompts_evaluating_neural_toxic_degeneration_in_language_models.pdf|RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models.]]: (cite: conf/emnlp/GehmanGSCS20) . [[papers/nlp/failure_modes/real_toxicity_prompts_evaluating_neural_toxic_degeneration_in_language_models.md|Notes]]
 - [[pdfs/nlp/failure_modes/red_teaming_language_models_with_language_models.pdf|Red Teaming Language Models with Language Models.]]: (cite: journals/corr/abs-2202-03286/Perez/2022) . [[papers/nlp/failure_modes/red_teaming_language_models_with_language_models.md|Notes]]
 - [[pdfs/nlp/failure_modes/survey_of_hallucination_in_natural_language_generation.pdf|Survey of Hallucination in Natural Language Generation.]]: (cite: journals/corr/abs-2202-03629/Ji/2022) . [[papers/nlp/failure_modes/survey_of_hallucination_in_natural_language_generation.md|Notes]]
 - [[pdfs/nlp/failure_modes/the_curious_case_of_neural_text_degeneration.pdf|The Curious Case of Neural Text Degeneration.]]: (cite: conf/iclr/HoltzmanBDFC20) . [[papers/nlp/failure_modes/the_curious_case_of_neural_text_degeneration.md|Notes]]
## generation
 - [[pdfs/nlp/generation/dont_take_it_literally_an_edit_invariant_sequence_loss_for_text_generation.pdf|Don&apos;t Take It Literally: An Edit-Invariant Sequence Loss for Text Generation.]]: (cite: conf/naacl/LiuYTL000CH22) . [[papers/nlp/generation/dont_take_it_literally_an_edit_invariant_sequence_loss_for_text_generation.md|Notes]]
 - [[pdfs/nlp/generation/genpet_few_shot_text_generation_with_natural_language_instructions.pdf|Few-Shot Text Generation with Natural Language Instructions.]]: (cite: conf/emnlp/SchickS21) . [[papers/nlp/generation/genpet_few_shot_text_generation_with_natural_language_instructions.md|Notes]]
 - [[pdfs/nlp/generation/lamda_language_models_for_dialog_applications.pdf|LaMDA - Language Models for Dialog Applications.]]: (cite: journals/corr/abs-2201-08239/Thoppilan/2022) . [[papers/nlp/generation/lamda_language_models_for_dialog_applications.md|Notes]]
 - [[time_control_language_modeling_via_stochastic_processes.pdf|Language modeling via stochastic processes.]]: (cite: journals/corr/abs-2203-11370/Wang/2022) Introduces the Time Control architecture. . [[papers/nlp/generation/time_control_language_modeling_via_stochastic_processes.md|Notes]]
 - [[pdfs/nlp/generation/smart_reply_automated_response_suggestion_for_email.pdf|Smart Reply - Automated Response Suggestion for Email.]]: (cite: conf/kdd/KannanKRKTMCLGY16) . [[papers/nlp/generation/smart_reply_automated_response_suggestion_for_email.md|Notes]]
 - [[pdfs/nlp/generation/surface_form_completion_why_the_highest_probability_answer_isnt_always_right.pdf|surface_form_completion_why_the_highest_probability_answer_isnt_always_right]]: . [[papers/nlp/generation/surface_form_completion_why_the_highest_probability_answer_isnt_always_right.md|Notes]]
### controlled
 - [[pdfs/nlp/generation/controlled/a_survey_of_controllable_text_generation_using_transformer_based_pre_trained_language_models.pdf|A Survey of Controllable Text Generation using Transformer-based Pre-trained Language Models.]]: (cite: journals/corr/abs-2201-05337/Zhang/2022) They look at different usecases, different approaches (finetuing, retrain/refactor PLMs, Adapters, guided-decoding, reinforcement learning approaches, ranking), future directions including prompt-based learning, fine-grained decoding control, incorporation of knowledge graphs,  . [[papers/nlp/generation/controlled/a_survey_of_controllable_text_generation_using_transformer_based_pre_trained_language_models.md|Notes]]
 - [[pdfs/nlp/generation/controlled/bert_has_a_mouth_and_it_must_speak_bert_as_a_markov_random_field_language_model.pdf|BERT has a Mouth, and It Must Speak: BERT as a Markov Random Field Language Model.]]: (cite: journals/corr/abs-1902-04094/Wang/2019) . [[papers/nlp/generation/controlled/bert_has_a_mouth_and_it_must_speak_bert_as_a_markov_random_field_language_model.md|Notes]]
 - [[pdfs/nlp/generation/controlled/mucoco_controlled_text_generation_as_continuous_optimization_with_multiple_constraints.pdf|Controlled Text Generation as Continuous Optimization with Multiple Constraints.]]: (cite: conf/nips/KumarMST21) Introduces MuCoCo: A flexible and modular algorithm for controllable inference from pretrained models. The decoding process is effectively an optimization problem which allows for differentiable constraints . [[papers/nlp/generation/controlled/mucoco_controlled_text_generation_as_continuous_optimization_with_multiple_constraints.md|Notes]]
 - [[pdfs/nlp/generation/controlled/diffusion_lm_improves_controllable_text_generation.pdf|Diffusion-LM Improves Controllable Text Generation.]]: (cite: journals/corr/abs-2205-14217/Li/2022) . [[papers/nlp/generation/controlled/diffusion_lm_improves_controllable_text_generation.md|Notes]]
 - [[pdfs/nlp/generation/controlled/dont_say_what_you_dont_know_improving_the_consistency_of_abstractive_summarization_by_constraining_beam_search.pdf|Don&apos;t Say What You Don&apos;t Know: Improving the Consistency of Abstractive Summarization by Constraining Beam Search.]]: (cite: journals/corr/abs-2203-08436/King/2022) . [[papers/nlp/generation/controlled/dont_say_what_you_dont_know_improving_the_consistency_of_abstractive_summarization_by_constraining_beam_search.md|Notes]]
 - [[pdfs/nlp/generation/controlled/pplm_plug_and_play_language_models_simple_approach_to_controlled_text_generation.pdf|Plug and Play Language Models - A Simple Approach to Controlled Text Generation.]]: (cite: conf/iclr/DathathriMLHFMY20) MPC for Natural Language Generation. On each step, update hidden states according to gradients of a classifier, which can be simple. But also try to maintain low perplexity so that we don't generate adversarial examples. [[papers/nlp/generation/controlled/pplm_plug_and_play_language_models_simple_approach_to_controlled_text_generation.md|Notes]]
 - [[pdfs/nlp/generation/controlled/robust_controlled_table_to_text_generation_with_structure_aware_equivariance_learning.pdf|Robust (Controlled) Table-to-Text Generation with Structure-Aware Equivariance Learning.]]: (cite: conf/naacl/WangXSC22) . [[papers/nlp/generation/controlled/robust_controlled_table_to_text_generation_with_structure_aware_equivariance_learning.md|Notes]]
 - [[pdfs/nlp/generation/controlled/step_by_step_separating_planning_from_realization_in_neural_data_to_text_generation.pdf|Step-by-Step: Separating Planning from Realization in Neural Data-to-Text Generation.]]: (cite: conf/naacl/MoryossefGD19) . [[papers/nlp/generation/controlled/step_by_step_separating_planning_from_realization_in_neural_data_to_text_generation.md|Notes]]
 - [[pdfs/nlp/generation/controlled/zero_shot_sonnet_generation_with_discourse_level_planning_and_aesthetics_features.pdf|Zero-shot Sonnet Generation with Discourse-level Planning and Aesthetics Features.]]: (cite: conf/naacl/TianP22) . [[papers/nlp/generation/controlled/zero_shot_sonnet_generation_with_discourse_level_planning_and_aesthetics_features.md|Notes]]
### decoding
 - [[pdfs/nlp/generation/decoding/if_beam_search_is_the_answer_what_was_the_question.pdf|If beam search is the answer, what was the question?]]: (cite: conf/emnlp/MeisterCV20) . [[papers/nlp/generation/decoding/if_beam_search_is_the_answer_what_was_the_question.md|Notes]]
 - [[pdfs/nlp/generation/decoding/machine_translation_decoding_beyond_beam_search.pdf|Machine Translation Decoding beyond Beam Search.]]: (cite: conf/emnlp/LeblondASPLASV21) . [[papers/nlp/generation/decoding/machine_translation_decoding_beyond_beam_search.md|Notes]]
 - [[pdfs/nlp/generation/decoding/neurologic_a*esque_decoding_constrained_text_generation_with_lookahead_heuristics.pdf|NeuroLogic A*esque Decoding: Constrained Text Generation with Lookahead Heuristics.]]: (cite: conf/naacl/LuWWJKKBQYZSC22) Draws inspiration from the A* algorithm and applies it to beam search decoding. Its a method of doing controllable text generation - assuming that you have some estimator of future cost, you can pick which nodes to expand in the decoding process, and this can be much more efficient than maintaining multiple beams or expanding the tree. You can also use this method of decoding to incorporate constraints that can't be expressed in differentiable terms, for example logical constraints.  . [[papers/nlp/generation/decoding/neurologic_a*esque_decoding_constrained_text_generation_with_lookahead_heuristics.md|Notes]]
 - [[pdfs/nlp/generation/decoding/ppl_mcts_constrained_textual_generation_through_discriminator_guided_mcts_decoding.pdf|PPL-MCTS: Constrained Textual Generation Through Discriminator-Guided MCTS Decoding.]]: (cite: conf/naacl/ChaffinCK22) . [[papers/nlp/generation/decoding/ppl_mcts_constrained_textual_generation_through_discriminator_guided_mcts_decoding.md|Notes]]
 - [[pdfs/nlp/generation/decoding/to_beam_or_not_to_beam_that_is_a_question_of_cooperation_for_language_gans.pdf|To Beam Or Not To Beam: That is a Question of Cooperation for Language GANs.]]: (cite: conf/nips/ScialomDSLP21) . [[papers/nlp/generation/decoding/to_beam_or_not_to_beam_that_is_a_question_of_cooperation_for_language_gans.md|Notes]]
 - [[pdfs/nlp/generation/decoding/planning_with_large_language_models_for_code_generation.pdf|planning_with_large_language_models_for_code_generation]]: . [[papers/nlp/generation/decoding/planning_with_large_language_models_for_code_generation.md|Notes]]
### prompts
 - [[pdfs/nlp/generation/prompts/learning_to_transfer_prompts_for_text_generation.pdf|Learning to Transfer Prompts for Text Generation.]]: (cite: conf/naacl/LiTNWZ22) . [[papers/nlp/generation/prompts/learning_to_transfer_prompts_for_text_generation.md|Notes]]
 - [[pdfs/nlp/generation/prompts/prompt_driven_neural_machine_translation.pdf|Prompt-Driven Neural Machine Translation.]]: (cite: conf/acl/LiYL022) Incorporate prompts for enhancing neural machine translation control and enriching flexibility. . [[papers/nlp/generation/prompts/prompt_driven_neural_machine_translation.md|Notes]]
### rl
 - [[pdfs/nlp/generation/rl/offline_rl_for_natural_language_generation_with_implicit_q_learning.pdf|Offline RL for Natural Language Generation with Implicit Language Q Learning.]]: (cite: journals/corr/abs-2206-11871/Snell/2022) . [[papers/nlp/generation/rl/offline_rl_for_natural_language_generation_with_implicit_q_learning.md|Notes]]
 - [[pdfs/nlp/generation/rl/quark_controllable_text_generation_with_reinforced_unlearning.pdf|Quark: Controllable Text Generation with Reinforced Unlearning.]]: (cite: journals/corr/abs-2205-13636/Lu/2022) Take a language model and condition it on some sort of "reward" token. "Bad" generations get a small reward token and "Good" generations get a "good" reward token. the loss function is still language modelling - despite the use of RL terminology, the point is just to learn to generate the language conditioned on those tokens. Then at test time you can ask for "good" generations.. [[papers/nlp/generation/rl/quark_controllable_text_generation_with_reinforced_unlearning.md|Notes]]
## graph
 - [[pdfs/nlp/graph/gnn_interpreting_nlp_edge_masking.pdf|Interpreting Graph Neural Networks for NLP With Differentiable Edge Masking.]]: (cite: conf/iclr/SchlichtkrullCT21) . [[papers/nlp/graph/gnn_interpreting_nlp_edge_masking.md|Notes]]
 - [[pdfs/nlp/graph/linkbert_pretraining_language_models_with_document_links.pdf|LinkBERT: Pretraining Language Models with Document Links.]]: (cite: conf/acl/YasunagaLL22) . [[papers/nlp/graph/linkbert_pretraining_language_models_with_document_links.md|Notes]]
## grounding
 - [[pdfs/nlp/grounding/grounding_grounding_in_nlp.pdf|Grounding &apos;Grounding&apos; in NLP.]]: (cite: conf/acl/ChanduBB21) . [[papers/nlp/grounding/grounding_grounding_in_nlp.md|Notes]]
## image_captioning
 - [[pdfs/nlp/image_captioning/cross_modal_retrieval_augmentation_for_multi_modal_classification.pdf|Cross-Modal Retrieval Augmentation for Multi-Modal Classification.]]: (cite: conf/emnlp/GurNSLKR21) . [[papers/nlp/image_captioning/cross_modal_retrieval_augmentation_for_multi_modal_classification.md|Notes]]
 - [[pdfs/nlp/image_captioning/film.pdf|FiLM: Visual Reasoning with a General Conditioning Layer.]]: (cite: conf/aaai/PerezSVDC18) . [[papers/nlp/image_captioning/film.md|Notes]]
 - [[pdfs/nlp/image_captioning/modern_modulating_early_visual_processing_by_language.pdf|Modulating early visual processing by language.]]: (cite: conf/nips/VriesSMLPC17) . [[papers/nlp/image_captioning/modern_modulating_early_visual_processing_by_language.md|Notes]]
 - [[pdfs/nlp/image_captioning/scan_hierarchical_compositional_visual_concepts.pdf|SCAN: Learning Hierarchical Compositional Visual Concepts.]]: (cite: conf/iclr/HigginsSMPBBSBH18) . [[papers/nlp/image_captioning/scan_hierarchical_compositional_visual_concepts.md|Notes]]
 - [[pdfs/nlp/image_captioning/show_attend_tell.pdf|Show, Attend and Tell - Neural Image Caption Generation with Visual Attention.]]: (cite: conf/icml/XuBKCCSZB15) . [[papers/nlp/image_captioning/show_attend_tell.md|Notes]]
 - [[pdfs/nlp/image_captioning/text_neural_operator_image_manip.pdf|Text as Neural Operator: Image Manipulation by Text Instruction.]]: (cite: conf/mm/ZhangTJYLE21) . [[papers/nlp/image_captioning/text_neural_operator_image_manip.md|Notes]]
 - [[pdfs/nlp/image_captioning/vilbert_pretraining_task_agnostic_visiolinguistic_representations_for_vision_and_language_tasks.pdf|ViLBERT: Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks.]]: (cite: conf/nips/LuBPL19) . [[papers/nlp/image_captioning/vilbert_pretraining_task_agnostic_visiolinguistic_representations_for_vision_and_language_tasks.md|Notes]]
 - [[pdfs/nlp/image_captioning/kim_vilt_vision_language_transformer_without_convolution.pdf|ViLT: Vision-and-Language Transformer Without Convolution or Region Supervision.]]: (cite: conf/icml/KimSK21) . [[papers/nlp/image_captioning/kim_vilt_vision_language_transformer_without_convolution.md|Notes]]
## knowledge_graph
 - [[pdfs/nlp/knowledge_graph/glomo_unsupervised_learning_of_transferrable_relational_graphs.pdf|GLoMo: Unsupervised Learning of Transferable Relational Graphs.]]: (cite: conf/nips/YangZDHCSL18) . [[papers/nlp/knowledge_graph/glomo_unsupervised_learning_of_transferrable_relational_graphs.md|Notes]]
 - [[pdfs/nlp/knowledge_graph/interpreting_knowledge_graph_relation_representations_from_word_embeddings.pdf|Interpreting Knowledge Graph Relation Representation from Word Embeddings.]]: (cite: conf/iclr/AllenBH21) . [[papers/nlp/knowledge_graph/interpreting_knowledge_graph_relation_representations_from_word_embeddings.md|Notes]]
 - [[pdfs/nlp/knowledge_graph/language_models_knowledge_bases.pdf|Language Models as Knowledge Bases?]]: (cite: conf/emnlp/PetroniRRLBWM19) . [[papers/nlp/knowledge_graph/language_models_knowledge_bases.md|Notes]]
 - [[pdfs/nlp/knowledge_graph/seq2kg_e2e_knowledge_graph_creation.pdf|Seq2KG: An End-to-End Neural Model for Domain Agnostic Knowledge Graph (not Text Graph) Construction from Text.]]: (cite: conf/kr/Stewart020) . [[papers/nlp/knowledge_graph/seq2kg_e2e_knowledge_graph_creation.md|Notes]]
### multimodal
 - [[pdfs/nlp/knowledge_graph/multimodal/kat_a_knowledge_augmented_transformer_for_vision_and_language.pdf|KAT: A Knowledge Augmented Transformer for Vision-and-Language.]]: (cite: conf/naacl/GuiWH0BG22) A big model that incorporates both "explicit" (eg from a knowledge base) and "implicit" knowledge (from GPT-3), then combines both to produce an answer to a VQA problem. . [[papers/nlp/knowledge_graph/multimodal/kat_a_knowledge_augmented_transformer_for_vision_and_language.md|Notes]]
## learning
 - [[pdfs/nlp/learning/is_reinforcement_learning_not_for_natural_language_processing_benchmarks_baselines_and_building_blocks_for_natural_language_policy_optimization.pdf|Is Reinforcement Learning (Not) for Natural Language Processing?: Benchmarks, Baselines, and Building Blocks for Natural Language Policy Optimization.]]: (cite: journals/corr/abs-2210-01241/Ramamurthy/2022) . [[papers/nlp/learning/is_reinforcement_learning_not_for_natural_language_processing_benchmarks_baselines_and_building_blocks_for_natural_language_policy_optimization.md|Notes]]
## logicalforms
 - [[pdfs/nlp/logicalforms/improving_text_to_sql_evaluation_methodology.pdf|Improving Text-to-SQL Evaluation Methodology.]]: (cite: conf/acl/RadevKZZFRS18) . [[papers/nlp/logicalforms/improving_text_to_sql_evaluation_methodology.md|Notes]]
 - [[pdfs/nlp/logicalforms/language_to_logical_forms_with_neural_attention.pdf|Language to Logical Form with Neural Attention.]]: (cite: conf/acl/DongL16) . [[papers/nlp/logicalforms/language_to_logical_forms_with_neural_attention.md|Notes]]
 - [[pdfs/nlp/logicalforms/learning_a_neural_semantic_parser_from_user_feedback.pdf|Learning a Neural Semantic Parser from User Feedback.]]: (cite: conf/acl/IyerKCKZ17) . [[papers/nlp/logicalforms/learning_a_neural_semantic_parser_from_user_feedback.md|Notes]]
## meta
 - [[pdfs/nlp/meta/few_shot_sequence_learning_with_transformers.pdf|Few-shot Sequence Learning with Transformers.]]: (cite: journals/corr/abs-2012-09543/Logeswaran/2020) Append a token to an input sequence which represents a particular task and show that the embedding of this token can be optimized on the fly given a few labeled examples. They look at compositional task representations in Section 5.4. Eg, if you have a new token $T_1 = \text{add 3}$, then $T_1 T_2 T_3$ should be solveable with a few examples if $T_2$ and $T_3$ are known. You can do well in the 10 to 20-shot setting. See appendix B2 for a compositional path-finding task. [[papers/nlp/meta/few_shot_sequence_learning_with_transformers.md|Notes]]
 - [[pdfs/nlp/meta/meta_learning_for_natural_language_processing_a_survey.pdf|Meta Learning for Natural Language Processing: A Survey.]]: (cite: conf/naacl/Lee0V22) . [[papers/nlp/meta/meta_learning_for_natural_language_processing_a_survey.md|Notes]]
 - [[pdfs/nlp/meta/universal_linguistic_inductive_biases_via_meta_learning.pdf|Universal linguistic inductive biases via meta-learning.]]: (cite: conf/cogsci/McCoyGSGL20) Introduces a framework for giving particular linguistic inductive biases to a neural network model. Initial state that encodes the inductive biases is found with meta-learning. Expose the model to many possible languages and learn to learn new languages on the fly. By controlling the properties of the training languages, you can control the inductive baises that the meta-learning imparts. For example, syllable structure.. [[papers/nlp/meta/universal_linguistic_inductive_biases_via_meta_learning.md|Notes]]
## methodology
 - [[pdfs/nlp/methodology/allentune_show_your_work_improved_reporting_of_experimental_results_acl.pdf|Show Your Work: Improved Reporting of Experimental Results.]]: (cite: conf/emnlp/DodgeGCSS19) The paper for the AllenTune metric and methodology (eg, expected validation performance of the best found model as a function of computation budget). This can help to show the compute budget/performance tradeoff . [[papers/nlp/methodology/allentune_show_your_work_improved_reporting_of_experimental_results_acl.md|Notes]]
## metrics
 - [[pdfs/nlp/metrics/better_evaluation_for_grammatical_error_correction.pdf|Better Evaluation for Grammatical Error Correction.]]: (cite: conf/naacl/DahlmeierN12) . [[papers/nlp/metrics/better_evaluation_for_grammatical_error_correction.md|Notes]]
## multimodal
 - [[pdfs/nlp/multimodal/foundations_and_recent_trends_in_multimodal_machine_learning_princiles_challenges_and_open_questions.pdf|Foundations and Recent Trends in Multimodal Machine Learning: Principles, Challenges, and Open Questions.]]: (cite: journals/corr/abs-2209-03430/Liang/2022) . [[papers/nlp/multimodal/foundations_and_recent_trends_in_multimodal_machine_learning_princiles_challenges_and_open_questions.md|Notes]]
### image
 - [[pdfs/nlp/multimodal/image/analyzing_compositionality_of_visual_question_answering.pdf|Analyzing Compositionality of Visual Question Answering]]: . [[papers/nlp/multimodal/image/analyzing_compositionality_of_visual_question_answering.md|Notes]]
 - [[pdfs/nlp/multimodal/image/attributes_as_operators_factoring_unseen_attribute_object_compositions.pdf|Attributes as Operators: Factorizing Unseen Attribute-Object Compositions.]]: (cite: conf/eccv/NagarajanG18) . [[papers/nlp/multimodal/image/attributes_as_operators_factoring_unseen_attribute_object_compositions.md|Notes]]
 - [[pdfs/nlp/multimodal/image/tirg_composing_text_and_image_for_image_retrieval_an_empircal_odyssey.pdf|Composing Text and Image for Image Retrieval - An Empirical Odyssey.]]: (cite: journals/corr/abs-1812-07119/Vo/2018) TIRG approach to combine image and text features. Stands for "Text-Image Residual Gating" . [[papers/nlp/multimodal/image/tirg_composing_text_and_image_for_image_retrieval_an_empircal_odyssey.md|Notes]]
 - [[pdfs/nlp/multimodal/image/dependency_induction_through_the_lens_of_visual_perception.pdf|Dependency Induction Through the Lens of Visual Perception.]]: (cite: conf/conll/SuRZHWBN21) . [[papers/nlp/multimodal/image/dependency_induction_through_the_lens_of_visual_perception.md|Notes]]
 - [[pdfs/nlp/multimodal/image/falcon_fast_visual_concept_learning_by_integrating_images_linguistic_descriptions_and_conceptual_relations.pdf|FALCON: Fast Visual Concept Learning by Integrating Images, Linguistic descriptions, and Conceptual Relations.]]: (cite: journals/corr/abs-2203-16639/Mei/2022) . [[papers/nlp/multimodal/image/falcon_fast_visual_concept_learning_by_integrating_images_linguistic_descriptions_and_conceptual_relations.md|Notes]]
 - [[pdfs/nlp/multimodal/image/vqa.pdf|IQ-VQA: Intelligent Visual Question Answering.]]: (cite: conf/icpr/GoelCAG20) . [[papers/nlp/multimodal/image/vqa.md|Notes]]
 - [[pdfs/nlp/multimodal/image/imagination_augmented_natural_language_understanding.pdf|Imagination-Augmented Natural Language Understanding.]]: (cite: conf/naacl/LuZ0EW22) . [[papers/nlp/multimodal/image/imagination_augmented_natural_language_understanding.md|Notes]]
 - [[pdfs/nlp/multimodal/image/language_driven_semantic_segmentation.pdf|Language-driven Semantic Segmentation.]]: (cite: journals/corr/abs-2201-03546/Li/2022) Similar to other observations in robotics, if you use use labels to do the segmentation, this makes the model more rigid, since you have a fixed number of classes. In this work use CLIP to encoder images and then something like FiLM to do the segmentation of the image based on different passed in phrases. Can work well on a zero-shot setup as well. [[papers/nlp/multimodal/image/language_driven_semantic_segmentation.md|Notes]]
 - [[pdfs/nlp/multimodal/image/socratic_models_composing_zero_shot_multimodal_reasoning_with_language.pdf|Socratic Models - Composing Zero-Shot Multimodal Reasoning with Language.]]: (cite: journals/corr/abs-2204-00598/Zeng/2022) This paper describes making an agent which can make use of large models in different domain (eg, image/text, text and audio/text) by having a "text mental model and log" (eg, everything gets converted to text), then you do reasoning in the text domain and possibly convert the results back into one of the other domains for retrieval) . [[papers/nlp/multimodal/image/socratic_models_composing_zero_shot_multimodal_reasoning_with_language.md|Notes]]
 - [[pdfs/nlp/multimodal/image/torwards_general_purpose_vision_systems_an_end_to_end_task_agnostic_vision_language_architecture.pdf|Towards General Purpose Vision Systems: An End-to-End Task-Agnostic Vision-Language Architecture.]]: (cite: conf/cvpr/GuptaKKH22) . [[papers/nlp/multimodal/image/torwards_general_purpose_vision_systems_an_end_to_end_task_agnostic_vision_language_architecture.md|Notes]]
 - [[pdfs/nlp/multimodal/image/training_vision_language_transformers_from_captions_alone.pdf|Training Vision-Language Transformers from Captions Alone.]]: (cite: journals/corr/abs-2205-09256/Gui/2022) . [[papers/nlp/multimodal/image/training_vision_language_transformers_from_captions_alone.md|Notes]]
 - [[pdfs/nlp/multimodal/image/unified_io_a_unified_model_for_vision_language_and_multimodal_tasks.pdf|Unified-IO: A Unified Modal for Vision-Language and Multimodal Tasks]]: . [[papers/nlp/multimodal/image/unified_io_a_unified_model_for_vision_language_and_multimodal_tasks.md|Notes]]
 - [[pdfs/nlp/multimodal/image/visual_commonsense_in_pretrained_unimodal_and_multimodal_models.pdf|Visual Commonsense in Pretrained Unimodal and Multimodal Models.]]: (cite: conf/naacl/ZhangDLS22) . [[papers/nlp/multimodal/image/visual_commonsense_in_pretrained_unimodal_and_multimodal_models.md|Notes]]
 - [[pdfs/nlp/multimodal/image/visually_augmented_language_modeling.pdf|Visually-Augmented Language Modeling.]]: (cite: journals/corr/abs-2205-10178/Wang/2022) . [[papers/nlp/multimodal/image/visually_augmented_language_modeling.md|Notes]]
#### causal
 - [[pdfs/nlp/multimodal/image/causal/cosim_commonsense_reasoning_for_counterfactual_scene_recognition.pdf|CoSIm: Commonsense Reasoning for Counterfactual Scene Recognition]]: . [[papers/nlp/multimodal/image/causal/cosim_commonsense_reasoning_for_counterfactual_scene_recognition.md|Notes]]
 - [[pdfs/nlp/multimodal/image/causal/towards_causal_vqa_revealing_and_reducing_spurious_correlation_by_invariant_and_covariant_semantic_editing.pdf|Towards Causal VQA: Revealing and Reducing Spurious Correlations by Invariant and Covariant Semantic Editing.]]: (cite: conf/cvpr/AgarwalSF20) . [[papers/nlp/multimodal/image/causal/towards_causal_vqa_revealing_and_reducing_spurious_correlation_by_invariant_and_covariant_semantic_editing.md|Notes]]
 - [[pdfs/nlp/multimodal/image/causal/vqa_lol_visual_question_answering_through_the_lens_of_logic.pdf|VQA-LOL: Visual Question Answering through the Lens of Logic]]: . [[papers/nlp/multimodal/image/causal/vqa_lol_visual_question_answering_through_the_lens_of_logic.md|Notes]]
#### compositional
 - [[pdfs/nlp/multimodal/image/compositional/a_benchmark_for_compositional_visual_reasoning.pdf|A Benchmark for Compositional Visual Reasoning.]]: (cite: journals/corr/abs-2206-05379/Zerroug/2022) . [[papers/nlp/multimodal/image/compositional/a_benchmark_for_compositional_visual_reasoning.md|Notes]]
 - [[pdfs/nlp/multimodal/image/compositional/learning_by_abstraction_the_neural_state_machine.pdf|Learning by Abstraction: The Neural State Machine.]]: (cite: conf/nips/HudsonM19) . [[papers/nlp/multimodal/image/compositional/learning_by_abstraction_the_neural_state_machine.md|Notes]]
 - [[pdfs/nlp/multimodal/image/compositional/learning_to_compose_and_reason_language_tree_structures_for_visual_grounding.pdf|Learning to Compose and Reason with Language Tree Structures for Visual Grounding.]]: (cite: journals/pami/HongLMHZ22) . [[papers/nlp/multimodal/image/compositional/learning_to_compose_and_reason_language_tree_structures_for_visual_grounding.md|Notes]]
 - [[pdfs/nlp/multimodal/image/compositional/transformer_module_networks_for_systematic_generalization_in_visual_question_answering.pdf|Transformer Module Networks for Systematic Generalization in Visual Question Answering.]]: (cite: journals/corr/abs-2201-11316/Yamada/2022) They introduce the âTransformer Modular Networkâ, which is compositions of transformers. They can do about 30% better than normal transformers. [[papers/nlp/multimodal/image/compositional/transformer_module_networks_for_systematic_generalization_in_visual_question_answering.md|Notes]]
 - [[pdfs/nlp/multimodal/image/compositional/vlmbench_a_compositional_benchmark_for_vision_and_language_manipulation.pdf|VLMbench: A Compositional Benchmark for Vision-and-Language Manipulation.]]: (cite: journals/corr/abs-2206-08522/Zheng/2022) . [[papers/nlp/multimodal/image/compositional/vlmbench_a_compositional_benchmark_for_vision_and_language_manipulation.md|Notes]]
 - [[pdfs/nlp/multimodal/image/compositional/clever_ref_diagnoizing_visual_reasoning_with_referring_expressions.pdf|clever_ref_diagnoizing_visual_reasoning_with_referring_expressions]]: . [[papers/nlp/multimodal/image/compositional/clever_ref_diagnoizing_visual_reasoning_with_referring_expressions.md|Notes]]
 - [[pdfs/nlp/multimodal/image/compositional/the_something_something_video_database_for_learning_and_evaluating_common_sense.pdf|the_something_something_video_database_for_learning_and_evaluating_common_sense]]: . [[papers/nlp/multimodal/image/compositional/the_something_something_video_database_for_learning_and_evaluating_common_sense.md|Notes]]
#### contrastive
 - [[pdfs/nlp/multimodal/image/contrastive/exploring_the_limits_of_video_text_models_through_contrast_sets.pdf|Exploring the Limits of Video-Text Models through Contrast Sets]]: . [[papers/nlp/multimodal/image/contrastive/exploring_the_limits_of_video_text_models_through_contrast_sets.md|Notes]]
 - [[pdfs/nlp/multimodal/image/contrastive/mcse_multimodal_contrastive_learning_of_sentence_embeddings.pdf|MCSE: Multimodal Contrastive Learning of Sentence Embeddings.]]: (cite: conf/naacl/ZhangMAHK22) . [[papers/nlp/multimodal/image/contrastive/mcse_multimodal_contrastive_learning_of_sentence_embeddings.md|Notes]]
#### datasets
 - [[pdfs/nlp/multimodal/image/datasets/clevr_a_diagnostic_dataset_for_compositional_language_and_elementary_visual_reasoning.pdf|CLEVR - A Diagnostic Dataset for Compositional Language and Elementary Visual Reasoning.]]: (cite: conf/cvpr/JohnsonHMFZG17) . [[papers/nlp/multimodal/image/datasets/clevr_a_diagnostic_dataset_for_compositional_language_and_elementary_visual_reasoning.md|Notes]]
 - [[pdfs/nlp/multimodal/image/datasets/closure_assessing_systematic_generalization_of_clevr_models.pdf|CLOSURE - Assessing Systematic Generalization of CLEVR Models.]]: (cite: conf/nips/VriesBMCB19) . [[papers/nlp/multimodal/image/datasets/closure_assessing_systematic_generalization_of_clevr_models.md|Notes]]
 - [[pdfs/nlp/multimodal/image/datasets/winoground_probing_vision_and_language_models_for_visio_linguistic_complexity.pdf|Winoground: Probing Vision and Language Models for Visio-Linguistic Complexity]]: . [[papers/nlp/multimodal/image/datasets/winoground_probing_vision_and_language_models_for_visio_linguistic_complexity.md|Notes]]
#### fusion
 - [[pdfs/nlp/multimodal/image/fusion/efficient_low_rank_multimodal_fusion_with_modality_specific_factors.pdf|Efficient Low-rank Multimodal Fusion with Modality-Specific Factors.]]: (cite: journals/corr/abs-1806-00064/Liu/2018) . [[papers/nlp/multimodal/image/fusion/efficient_low_rank_multimodal_fusion_with_modality_specific_factors.md|Notes]]
 - [[pdfs/nlp/multimodal/image/fusion/on_the_benefits_of_early_fusion_in_multimodal_representation_learning.pdf|On the Benefits of Early Fusion in Multimodal Representation Learning.]]: (cite: journals/corr/abs-2011-07191/Barnum/2020) . [[papers/nlp/multimodal/image/fusion/on_the_benefits_of_early_fusion_in_multimodal_representation_learning.md|Notes]]
#### generation
 - [[pdfs/nlp/multimodal/image/generation/learning_factorized_multimodal_representations.pdf|Learning Factorized Multimodal Representations.]]: (cite: conf/iclr/TsaiLZMS19) . [[papers/nlp/multimodal/image/generation/learning_factorized_multimodal_representations.md|Notes]]
 - [[pdfs/nlp/multimodal/image/generation/unifying_vision_and_language_tasks_via_text_generation.pdf|Unifying Vision-and-Language Tasks via Text Generation.]]: (cite: conf/icml/ChoLTB21) . [[papers/nlp/multimodal/image/generation/unifying_vision_and_language_tasks_via_text_generation.md|Notes]]
#### interaction
 - [[pdfs/nlp/multimodal/image/interaction/flava_a_foundational_language_and_vision_alignment_model.pdf|FLAVA: A Foundational Language And Vision Alignment Model.]]: (cite: journals/corr/abs-2112-04482/Singh/2021) . [[papers/nlp/multimodal/image/interaction/flava_a_foundational_language_and_vision_alignment_model.md|Notes]]
 - [[pdfs/nlp/multimodal/image/interaction/mm_vit_multi_modal_video_transformer_for_compressed_video_action_recognition.pdf|MM-ViT: Multi-Modal Video Transformer for Compressed Video Action Recognition.]]: (cite: conf/wacv/ChenH22) . [[papers/nlp/multimodal/image/interaction/mm_vit_multi_modal_video_transformer_for_compressed_video_action_recognition.md|Notes]]
 - [[pdfs/nlp/multimodal/image/interaction/polyvit_co_training_vision_transformers_on_images_videos_and_audio.pdf|PolyViT: Co-training Vision Transformers on Images, Videos and Audio.]]: (cite: journals/corr/abs-2111-12993/Likhosherstov/2021) . [[papers/nlp/multimodal/image/interaction/polyvit_co_training_vision_transformers_on_images_videos_and_audio.md|Notes]]
 - [[pdfs/nlp/multimodal/image/interaction/vatt_transformers_for_multimodal_self_supervised_learning_from_raw_video_audio_and_text.pdf|VATT: Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text.]]: (cite: conf/nips/AkbariYQCCCG21) . [[papers/nlp/multimodal/image/interaction/vatt_transformers_for_multimodal_self_supervised_learning_from_raw_video_audio_and_text.md|Notes]]
 - [[pdfs/nlp/multimodal/image/interaction/coarse_to_fine_vision_language_pretraining_with_fusion_in_the_backbone.pdf|coarse_to_fine_vision_language_pretraining_with_fusion_in_the_backbone]]: . [[papers/nlp/multimodal/image/interaction/coarse_to_fine_vision_language_pretraining_with_fusion_in_the_backbone.md|Notes]]
#### interpretability
 - [[pdfs/nlp/multimodal/image/interpretability/m2lens_visualizing_and_explaining_multimodal_models_for_sentiment_analysis.pdf|M2Lens: Visualizing and Explaining Multimodal Models for Sentiment Analysis.]]: (cite: journals/tvcg/WangHJYWQ22) . [[papers/nlp/multimodal/image/interpretability/m2lens_visualizing_and_explaining_multimodal_models_for_sentiment_analysis.md|Notes]]
 - [[pdfs/nlp/multimodal/image/interpretability/multiviz_an_analysis_benchmark_for_visualizing_and_understanding_multimodal_models.pdf|MultiViz: An Analysis Benchmark for Visualizing and Understanding Multimodal Models.]]: (cite: journals/corr/abs-2207-00056/Liang/2022) . [[papers/nlp/multimodal/image/interpretability/multiviz_an_analysis_benchmark_for_visualizing_and_understanding_multimodal_models.md|Notes]]
 - [[pdfs/nlp/multimodal/image/interpretability/vl_interpret_an_interactive_visualization_tool_for_interpreting_vision_language_transformers.pdf|VL-InterpreT: An Interactive Visualization Tool for Interpreting Vision-Language Transformers.]]: (cite: journals/corr/abs-2203-17247/Aflalo/2022) . [[papers/nlp/multimodal/image/interpretability/vl_interpret_an_interactive_visualization_tool_for_interpreting_vision_language_transformers.md|Notes]]
#### representations
 - [[pdfs/nlp/multimodal/image/representations/found_in_translation_learning_robust_joint_representations_by_cyclic_translations_between_modalities.pdf|Found in Translation: Learning Robust Joint Representations by Cyclic Translations between Modalities.]]: (cite: conf/aaai/PhamLMMP19) . [[papers/nlp/multimodal/image/representations/found_in_translation_learning_robust_joint_representations_by_cyclic_translations_between_modalities.md|Notes]]
 - [[pdfs/nlp/multimodal/image/representations/hubert_self_supervised_speech_representation_learning_by_masked_prediction_of_hidden_units.pdf|HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units.]]: (cite: journals/taslp/HsuBTLSM21) . [[papers/nlp/multimodal/image/representations/hubert_self_supervised_speech_representation_learning_by_masked_prediction_of_hidden_units.md|Notes]]
 - [[pdfs/nlp/multimodal/image/representations/on_deep_multi_view_representation_learning_objectives_and_optimization.pdf|On Deep Multi-View Representation Learning: Objectives and Optimization.]]: (cite: journals/corr/WangALB16/Wang/2016) . [[papers/nlp/multimodal/image/representations/on_deep_multi_view_representation_learning_objectives_and_optimization.md|Notes]]
##### fission
 - [[pdfs/nlp/multimodal/image/representations/fission/deep_multimodal_clustering_for_unsupervised_audiovisual_learning.pdf|Deep Multimodal Clustering for Unsupervised Audiovisual Learning.]]: (cite: conf/cvpr/HuNL19) . [[papers/nlp/multimodal/image/representations/fission/deep_multimodal_clustering_for_unsupervised_audiovisual_learning.md|Notes]]
#### training
 - [[pdfs/nlp/multimodal/image/training/characterizing_and_overcoming_the_greedy_nature_of_learning_in_multi_modal_deep_neural_networks.pdf|Characterizing and overcoming the greedy nature of learning in multi-modal deep neural networks.]]: (cite: journals/corr/abs-2202-05306/Wu/2022) . [[papers/nlp/multimodal/image/training/characterizing_and_overcoming_the_greedy_nature_of_learning_in_multi_modal_deep_neural_networks.md|Notes]]
 - [[pdfs/nlp/multimodal/image/training/making_the_v_in_vqa_matter_elevating_the_role_of_image_understanding_in_visual_question_answering.pdf|Making the V in VQA Matter: Elevating the Role of Image Understanding in Visual Question Answering.]]: (cite: conf/cvpr/GoyalKSBP17) . [[papers/nlp/multimodal/image/training/making_the_v_in_vqa_matter_elevating_the_role_of_image_understanding_in_visual_question_answering.md|Notes]]
 - [[pdfs/nlp/multimodal/image/training/mitigating_modality_collapse_in_multimodal_vaes_via_impartial_optimization.pdf|Mitigating Modality Collapse in Multimodal VAEs via Impartial Optimization.]]: (cite: conf/icml/JavaloyMV22) . [[papers/nlp/multimodal/image/training/mitigating_modality_collapse_in_multimodal_vaes_via_impartial_optimization.md|Notes]]
### transfer
 - [[pdfs/nlp/multimodal/transfer/highmmt_towards_modality_and_task_generation_for_high_modality_representation_learning.pdf|HighMMT: Towards Modality and Task Generalization for High-Modality Representation Learning.]]: (cite: journals/corr/abs-2203-01311/Liang/2022) . [[papers/nlp/multimodal/transfer/highmmt_towards_modality_and_task_generation_for_high_modality_representation_learning.md|Notes]]
## parsing
 - [[pdfs/nlp/parsing/few_shot_semantic_parsing_with_language_models_trained_on_code.pdf|Few-Shot Semantic Parsing with Language Models Trained on Code.]]: (cite: conf/naacl/ShinD22) . [[papers/nlp/parsing/few_shot_semantic_parsing_with_language_models_trained_on_code.md|Notes]]
## prompt
 - [[pdfs/nlp/prompt/autoprompt_eliciting_knowledge_from_language_models_with_automatically_generated_prompts.pdf|AutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts.]]: (cite: conf/emnlp/ShinRLWS20) . [[papers/nlp/prompt/autoprompt_eliciting_knowledge_from_language_models_with_automatically_generated_prompts.md|Notes]]
 - [[pdfs/nlp/prompt/rlprompt_optimizing_discrete_text_prompts_with_reinforcement_learning.pdf|RLPrompt: Optimizing Discrete Text Prompts With Reinforcement Learning.]]: (cite: journals/corr/abs-2205-12548/Deng/2022) . [[papers/nlp/prompt/rlprompt_optimizing_discrete_text_prompts_with_reinforcement_learning.md|Notes]]
 - [[pdfs/nlp/prompt/efficient_soft_q_learning_for_text_generation_with_limited_good_data.pdf|efficient_soft_q_learning_for_text_generation_with_limited_good_data]]: . [[papers/nlp/prompt/efficient_soft_q_learning_for_text_generation_with_limited_good_data.md|Notes]]
## reasoning
 - [[pdfs/nlp/reasoning/atomic_an_atlas_of_machine_commonsense_for_if_then_reasoning.pdf|ATOMIC: An Atlas of Machine Commonsense for If-Then Reasoning.]]: (cite: conf/aaai/SapBABLRRSC19) . [[papers/nlp/reasoning/atomic_an_atlas_of_machine_commonsense_for_if_then_reasoning.md|Notes]]
 - [[pdfs/nlp/reasoning/chain_of_thought_prompting_elicits_reasoning_in_large_language_models.pdf|Chain of Thought Prompting Elicits Reasoning in Large Language Models.]]: (cite: journals/corr/abs-2201-11903/Wei/2022) . [[papers/nlp/reasoning/chain_of_thought_prompting_elicits_reasoning_in_large_language_models.md|Notes]]
 - [[pdfs/nlp/reasoning/dream_improving_situational_qa_by_first_elaborating_the_situation.pdf|DREAM: Improving Situational QA by First Elaborating the Situation.]]: (cite: conf/naacl/GuDC22) . [[papers/nlp/reasoning/dream_improving_situational_qa_by_first_elaborating_the_situation.md|Notes]]
 - [[pdfs/nlp/reasoning/decomposed_prompting_a_modular_approach_for_solving_complex_tasks.pdf|Decomposed Prompting: A Modular Approach for Solving Complex Tasks.]]: (cite: journals/corr/abs-2210-02406/Khot/2022) . [[papers/nlp/reasoning/decomposed_prompting_a_modular_approach_for_solving_complex_tasks.md|Notes]]
 - [[pdfs/nlp/reasoning/deep_a2_a_modular_framework_for_deep_argument_analysis_with_pretrained_neural_text2text_language_models.pdf|Deep A2: A modular Framework for Deep Argument Analysis with Neural Text2Text Language Models]]: . [[papers/nlp/reasoning/deep_a2_a_modular_framework_for_deep_argument_analysis_with_pretrained_neural_text2text_language_models.md|Notes]]
 - [[pdfs/nlp/reasoning/improving_coherence_and_consistency_in_neural_sequence_models_with_dual_system_neuro_symbolic_reasoning.pdf|Improving Coherence and Consistency in Neural Sequence Models with Dual-System, Neuro-Symbolic Reasoning.]]: (cite: conf/nips/NyeTTL21) . [[papers/nlp/reasoning/improving_coherence_and_consistency_in_neural_sequence_models_with_dual_system_neuro_symbolic_reasoning.md|Notes]]
 - [[pdfs/nlp/reasoning/language_models_show_human_like_content_effects_on_reasoning.pdf|Language models show human-like content effects on reasoning.]]: (cite: journals/corr/abs-2207-07051/Dasgupta/2022) . [[papers/nlp/reasoning/language_models_show_human_like_content_effects_on_reasoning.md|Notes]]
 - [[pdfs/nlp/reasoning/andreas_models_of_meaning.pdf|Models of Meaning? (Presentation at NAACL).]]: . [[papers/nlp/reasoning/andreas_models_of_meaning.md|Notes]]
 - [[pdfs/nlp/reasoning/q2_evaluating_factual_consistency_in_knowledge_grounded_dialogues_via_question_generation_and_question_answering.pdf|Q2: Evaluating Factual Consistency in Knowledge-Grounded Dialogues via Question Generation and Question Answering.]]: (cite: journals/corr/abs-2104-08202/Honovich/2021) . [[papers/nlp/reasoning/q2_evaluating_factual_consistency_in_knowledge_grounded_dialogues_via_question_generation_and_question_answering.md|Notes]]
 - [[pdfs/nlp/reasoning/r3_reverse_retrieve_and_rank_for_sarcasm_generation_with_commonsense_knowledge.pdf|R3: Reverse, Retrieve, and Rank for Sarcasm Generation with Commonsense Knowledge]]: . [[papers/nlp/reasoning/r3_reverse_retrieve_and_rank_for_sarcasm_generation_with_commonsense_knowledge.md|Notes]]
 - [[pdfs/nlp/reasoning/react_synergizing_reasoning_and_acting_in_language_models.pdf|ReAct: Synergizing Reasoning and Acting in Language Models.]]: (cite: journals/corr/abs-2210-03629/Yao/2022) Synergizing Reasoning and Acting in Language Models: Explores the use of LLMs to generate both reasoning traces and task-specific actions in an interleaved manner. On Question Answering and Fact Verification, ReACT overcomes the issues of hallucination and error propagation which can be prevalent in chain-of-thought prompting. ReACT can also do well on ALFWorld and WebShop decisionmaking benchmarks. Basically it combines reasoning with actions, where the actions are things like searching a database for mroe information. An example âAside from Apple Remote, what other device can control the program that Apple Remote was originally designed forâ -> to solve this task you need to search âthe program Apple Remote was originally designed forâ, then find the âother device that can control that programâ. Chain-of-thought prompting means that you donât search the database, so you hallucinate. If you just have a database search, the database might not give you the exact answer you want. . [[papers/nlp/reasoning/react_synergizing_reasoning_and_acting_in_language_models.md|Notes]]
 - [[pdfs/nlp/reasoning/star_self_taught_reasoner_bootstrapping_reasoning_with_reasoning.pdf|STaR: Self-Taught Reasoner Bootstrapping Reasoning With Reasoning]]: . [[papers/nlp/reasoning/star_self_taught_reasoner_bootstrapping_reasoning_with_reasoning.md|Notes]]
 - [[pdfs/nlp/reasoning/symbolic_knowledge_distillation_from_general_language_models_to_commonsense_models.pdf|Symbolic Knowledge Distillation from Generic Language Models to Commonsense Models]]: . [[papers/nlp/reasoning/symbolic_knowledge_distillation_from_general_language_models_to_commonsense_models.md|Notes]]
 - [[pdfs/nlp/reasoning/winogrande_an_adversarial_winograd_schema_challenge_at_scale.pdf|WinoGrande: An Adversarial Winograd Schema Challenge at Scale.]]: (cite: conf/aaai/SakaguchiBBC20) . [[papers/nlp/reasoning/winogrande_an_adversarial_winograd_schema_challenge_at_scale.md|Notes]]
## retrieval
 - [[pdfs/nlp/retrieval/task_aware_retrieval_with_instructions.pdf|Task-aware Retrieval with Instructions.]]: (cite: journals/corr/abs-2211-09260/Asai/2022) . [[papers/nlp/retrieval/task_aware_retrieval_with_instructions.md|Notes]]
## rnn
 - [[pdfs/nlp/rnn/neural_machine_translation_jointly_learning_to_align_and_translate.pdf|Neural Machine Translation by Jointly Learning to Align and Translate.]]: (cite: journals/corr/BahdanauCB14/Bahdanau/2015) . [[papers/nlp/rnn/neural_machine_translation_jointly_learning_to_align_and_translate.md|Notes]]
## speech
 - [[pdfs/nlp/speech/end_to_end_adversarial_text_to_speech.pdf|End-to-End Adversarial Text-to-Speech.]]: (cite: journals/corr/abs-2006-03575/Donahue/2020) . Tries to solve the "can we do TTS End-to-End" without lots of different pipeline stages. The main idea to set the problem up as a kind of adversarial learning problem. The authors propose a two-stage pipeline; one stage that generates aligned tokens and latents and another stage which decodes waveforms from those. . [[papers/nlp/speech/end_to_end_adversarial_text_to_speech.md|Notes]]
 - [[pdfs/nlp/speech/on_generative_spoken_language_modeling_from_raw_audio.pdf|On Generative Spoken Language Modeling from Raw Audio]]: . [[papers/nlp/speech/on_generative_spoken_language_modeling_from_raw_audio.md|Notes]]
## tokenization
 - [[pdfs/nlp/tokenization/between_words_and_characters_a_brief_history_of_open_vocabulary_for_modelling_and_tokenization_in_nlp.pdf|Between words and characters - A Brief History of Open-Vocabulary Modeling and Tokenization in NLP.]]: (cite: journals/corr/abs-2112-10508/Mielke/2021) . [[papers/nlp/tokenization/between_words_and_characters_a_brief_history_of_open_vocabulary_for_modelling_and_tokenization_in_nlp.md|Notes]]
## transfer
 - [[pdfs/nlp/transfer/distributionally_robust_language_modeling.pdf|Distributionally Robust Language Modeling.]]: (cite: conf/emnlp/OrenSHL19) . [[papers/nlp/transfer/distributionally_robust_language_modeling.md|Notes]]
 - [[pdfs/nlp/transfer/efficient_hierarchical_domain_adaptation_for_pretrained_language_models.pdf|Efficient Hierarchical Domain Adaptation for Pretrained Language Models.]]: (cite: conf/naacl/ChronopoulouPD22) . [[papers/nlp/transfer/efficient_hierarchical_domain_adaptation_for_pretrained_language_models.md|Notes]]
### adapters
 - [[pdfs/nlp/transfer/adapters/multilingual_unsupervised_neural_machine_translation_with_denoising_adapters.pdf|Multilingual Unsupervised Neural Machine Translation with Denoising Adapters.]]: (cite: conf/emnlp/UstunBBG21) . [[papers/nlp/transfer/adapters/multilingual_unsupervised_neural_machine_translation_with_denoising_adapters.md|Notes]]
 - [[pdfs/nlp/transfer/adapters/parameter_efficient_transfer_learning_for_nlp.pdf|Parameter-Efficient Transfer Learning for NLP.]]: (cite: conf/icml/HoulsbyGJMLGAG19) . [[papers/nlp/transfer/adapters/parameter_efficient_transfer_learning_for_nlp.md|Notes]]
 - [[pdfs/nlp/transfer/adapters/udapter_language_adaptation_for_truly_universal_dependency_parsing.pdf|UDapter: Language Adaptation for Truly Universal Dependency Parsing.]]: (cite: conf/emnlp/UstunBBN20) . [[papers/nlp/transfer/adapters/udapter_language_adaptation_for_truly_universal_dependency_parsing.md|Notes]]
 - [[pdfs/nlp/transfer/adapters/when_does_parameter_efficient_transfer_learning_work_for_machine_translation.pdf|When does Parameter-Efficient Transfer Learning Work for Machine Translation?]]: (cite: journals/corr/abs-2205-11277/Ustun/2022) . [[papers/nlp/transfer/adapters/when_does_parameter_efficient_transfer_learning_work_for_machine_translation.md|Notes]]
## transformer
 - [[pdfs/nlp/transformer/competition_level_code_generation_with_alphacode.pdf|Competition-Level Code Generation with AlphaCode.]]: (cite: journals/corr/abs-2203-07814/Li/2022) Code generation for programming competitions. Makes many studies about scalability (eg, more solution proposals can give better results). Two interesting architectural nodes are activation sparsity using tempering and the use of GOLD as a pseudo-RL objective. [[papers/nlp/transformer/competition_level_code_generation_with_alphacode.md|Notes]]
 - [[pdfs/nlp/transformer/transformer_training_tips.pdf|Training Tips for the Transformer Model.]]: (cite: journals/pbml/PopelB18) . [[papers/nlp/transformer/transformer_training_tips.md|Notes]]
### fewshot
 - [[pdfs/nlp/transformer/fewshot/can_language_models_learned_from_explanations_in_context.pdf|Can language models learn from explanations in context?]]: (cite: journals/corr/abs-2204-02329/Lampinen/2022) . [[papers/nlp/transformer/fewshot/can_language_models_learned_from_explanations_in_context.md|Notes]]
 - [[pdfs/nlp/transformer/fewshot/few_shot_sequence_learning_with_transfromers.pdf|Few-shot Sequence Learning with Transformers.]]: (cite: journals/corr/abs-2012-09543/Logeswaran/2020) . [[papers/nlp/transformer/fewshot/few_shot_sequence_learning_with_transfromers.md|Notes]]
 - [[pdfs/nlp/transformer/fewshot/gpt3.pdf|Language Models are Few-Shot Learners.]]: (cite: conf/nips/BrownMRSKDNSSAA20) None. [[papers/nlp/transformer/fewshot/gpt3.md|Notes]]
 - [[pdfs/nlp/transformer/fewshot/least_to_most_prompting_enables_complex_reasoning_in_large_language_models.pdf|Least-to-Most Prompting Enables Complex Reasoning in Large Language Models.]]: (cite: journals/corr/abs-2205-10625/Zhou/2022) . [[papers/nlp/transformer/fewshot/least_to_most_prompting_enables_complex_reasoning_in_large_language_models.md|Notes]]
 - [[pdfs/nlp/transformer/fewshot/metaicl_learning_to_learn_in_context.pdf|MetaICL: Learning to Learn In Context.]]: (cite: conf/naacl/MinLZH22) . [[papers/nlp/transformer/fewshot/metaicl_learning_to_learn_in_context.md|Notes]]
### foundational
 - [[pdfs/nlp/transformer/foundational/vaswani_attention.pdf|Attention is All you Need.]]: (cite: conf/nips/VaswaniSPUJGKP17) Introduces the Transformer Architecture, a fully-attentional sequence-to-sequence processing architecture with positional encodings. [[papers/nlp/transformer/foundational/vaswani_attention.md|Notes]]
 - [[pdfs/nlp/transformer/foundational/bart_denoising_sequence_to_sequence_pretraining_for_natural_language_generation_translation_and_comprehension.pdf|BART - Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension.]]: (cite: conf/acl/LewisLGGMLSZ20) . [[papers/nlp/transformer/foundational/bart_denoising_sequence_to_sequence_pretraining_for_natural_language_generation_translation_and_comprehension.md|Notes]]
 - [[pdfs/nlp/transformer/foundational/bert_pretraining_of_bidirectional_transformers_for_language_understanding.pdf|BERT - Pre-training of Deep Bidirectional Transformers for Language Understanding.]]: (cite: conf/naacl/DevlinCLT19) . [[papers/nlp/transformer/foundational/bert_pretraining_of_bidirectional_transformers_for_language_understanding.md|Notes]]
 - [[pdfs/nlp/transformer/foundational/instruct_gpt_training_language_models_to_follow_instructions_with_human_feedback.pdf|Training language models to follow instructions with human feedback.]]: (cite: journals/corr/abs-2203-02155/Ouyang/2022) InstructGPT model. A method to align language models based on feedback. . [[papers/nlp/transformer/foundational/instruct_gpt_training_language_models_to_follow_instructions_with_human_feedback.md|Notes]]
### model_parallel
 - [[pdfs/nlp/transformer/model_parallel/deepspeed_moe_advancing_mixture_of_experts_in_inference_and_trianing_to_power_next_generation_ai_scale.pdf|DeepSpeed-MoE: Advancing Mixture-of-Experts Inference and Training to Power Next-Generation AI Scale.]]: (cite: conf/icml/RajbhandariLYZA22) How to do fast inference on mixture-of-experts models, eg, parameter efficiency through pyramid residual mixture of experts and chunked GPU computation and reductions. [[papers/nlp/transformer/model_parallel/deepspeed_moe_advancing_mixture_of_experts_in_inference_and_trianing_to_power_next_generation_ai_scale.md|Notes]]
 - [[pdfs/nlp/transformer/model_parallel/zero_offload_democratizing_billion_scale_model_training.pdf|ZeRO-Offload: Democratizing Billion-Scale Model Training.]]: (cite: conf/usenix/0015RARYZ0H21) . [[papers/nlp/transformer/model_parallel/zero_offload_democratizing_billion_scale_model_training.md|Notes]]
### moe
 - [[pdfs/nlp/transformer/moe/confident_adaptive_language_modeling.pdf|Confident Adaptive Language Modeling.]]: (cite: journals/corr/abs-2207-07061/Schuster/2022) . [[papers/nlp/transformer/moe/confident_adaptive_language_modeling.md|Notes]]
 - [[pdfs/nlp/transformer/moe/glam_efficient_scaling_of_language_models_with_mixture_of_experts.pdf|GLaM - Efficient Scaling of Language Models with Mixture-of-Experts.]]: (cite: journals/corr/abs-2112-06905/Du/2021) Mixture of experts model, but you don't delegate to all experts. [[papers/nlp/transformer/moe/glam_efficient_scaling_of_language_models_with_mixture_of_experts.md|Notes]]
 - [[pdfs/nlp/transformer/moe/palm_scaling_language_models_with_pathways.pdf|PaLM: Scaling Language Modeling with Pathways.]]: (cite: journals/corr/abs-2204-02311/Chowdhery/2022) . [[papers/nlp/transformer/moe/palm_scaling_language_models_with_pathways.md|Notes]]
### nonautoregressive
 - [[pdfs/nlp/transformer/nonautoregressive/non_autoregressive_neural_machine_translation.pdf|Non-Autoregressive Neural Machine Translation.]]: (cite: conf/iclr/Gu0XLS18) . [[papers/nlp/transformer/nonautoregressive/non_autoregressive_neural_machine_translation.md|Notes]]
### properties
 - [[pdfs/nlp/transformer/properties/exploring_length_generalization_in_large_language_models.pdf|Exploring Length Generalization in Large Language Models.]]: (cite: journals/corr/abs-2207-04901/Anil/2022) . [[papers/nlp/transformer/properties/exploring_length_generalization_in_large_language_models.md|Notes]]
 - [[pdfs/nlp/transformer/properties/how_much_does_attention_actually_attend_questioning_the_importance_of_attention_in_pretrained_transformers.pdf|How Much Does Attention Actually Attend? Questioning the Importance of Attention in Pretrained Transformers.]]: (cite: journals/corr/abs-2211-03495/Hassid/2022) . [[papers/nlp/transformer/properties/how_much_does_attention_actually_attend_questioning_the_importance_of_attention_in_pretrained_transformers.md|Notes]]
 - [[pdfs/nlp/transformer/properties/meaning_without_reference_in_language_language_models.pdf|Meaning without reference in large language models.]]: (cite: journals/corr/abs-2208-02957/Piantadosi/2022) . [[papers/nlp/transformer/properties/meaning_without_reference_in_language_language_models.md|Notes]]
 - [[pdfs/nlp/transformer/properties/memorization_without_overfitting_analyzing_the_training_dynamics_of_large_language_models.pdf|Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models.]]: (cite: journals/corr/abs-2205-10770/Tirumala/2022) . [[papers/nlp/transformer/properties/memorization_without_overfitting_analyzing_the_training_dynamics_of_large_language_models.md|Notes]]
 - [[pdfs/nlp/transformer/properties/transformer_feed_forward_layers_build_predictions_by_promoting_concepts_in_the_vocabulary_space.pdf|Transformer Feed-Forward Layers Are Key-Value Memories.]]: (cite: conf/emnlp/GevaSBL21) . [[papers/nlp/transformer/properties/transformer_feed_forward_layers_build_predictions_by_promoting_concepts_in_the_vocabulary_space.md|Notes]]
### retrieval
 - [[pdfs/nlp/transformer/retrieval/retro_improving_language_models_by_retrieving_from_trillions_of_tokens.pdf|Improving Language Models by Retrieving from Trillions of Tokens.]]: (cite: conf/icml/BorgeaudMHCRM0L22) . [[papers/nlp/transformer/retrieval/retro_improving_language_models_by_retrieving_from_trillions_of_tokens.md|Notes]]
 - [[pdfs/nlp/transformer/retrieval/generalization_properties_of_retrieval_based_transformers.pdf|generalization_properties_of_retrieval_based_transformers]]: . [[papers/nlp/transformer/retrieval/generalization_properties_of_retrieval_based_transformers.md|Notes]]
 - [[pdfs/nlp/transformer/retrieval/low_resource_retrieval_augmented_adaptive_neural_machine_translation.pdf|low_resource_retrieval_augmented_adaptive_neural_machine_translation]]: . [[papers/nlp/transformer/retrieval/low_resource_retrieval_augmented_adaptive_neural_machine_translation.md|Notes]]
### scaling
 - [[pdfs/nlp/transformer/scaling/t5_exploring_the_limits_of_transfer_learning_with_unified_text_to_text_transformer.pdf|Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.]]: (cite: journals/jmlr/RaffelSRLNMZLL20) None. [[papers/nlp/transformer/scaling/t5_exploring_the_limits_of_transfer_learning_with_unified_text_to_text_transformer.md|Notes]]
 - [[pdfs/nlp/transformer/scaling/staged_training_for_transformer_language_models.pdf|Staged Training for Transformer Language Models.]]: (cite: conf/icml/ShenWKDPB22) When we compare language scales, we compare from different initializations. This paper proposes "seeding" from one smaller model and "expanding" the number of weights such that the loss and training dynamics are preserved. [[papers/nlp/transformer/scaling/staged_training_for_transformer_language_models.md|Notes]]
 - [[pdfs/nlp/transformer/scaling/chinchilla_training_compute_optimal_large_language_models.pdf|Training Compute-Optimal Large Language Models.]]: (cite: journals/corr/abs-2203-15556/Hoffmann/2022) Chinchilla paper from DeepMind. [[papers/nlp/transformer/scaling/chinchilla_training_compute_optimal_large_language_models.md|Notes]]
 - [[pdfs/nlp/transformer/scaling/unified_scaling_laws_for_routed_language_models.pdf|Unified Scaling Laws for Routed Language Models.]]: (cite: conf/icml/ClarkCGMPHDHCB022) . [[papers/nlp/transformer/scaling/unified_scaling_laws_for_routed_language_models.md|Notes]]
## translation
 - [[pdfs/nlp/translation/generating_similes_like_a_pro_a_style_transfer_approach_for_simile_generation.pdf|Generating similes like a Pro - A Style Transfer Approach for Simile Generation.]]: (cite: journals/corr/abs-2009-08942/Chakrabarty/2020) . [[papers/nlp/translation/generating_similes_like_a_pro_a_style_transfer_approach_for_simile_generation.md|Notes]]
 - [[pdfs/nlp/translation/cho_neural_machine_translation_by_learning_to_jointly_align_and_translate.pdf|Neural Machine Translation by Jointly Learning to Align and Translate.]]: (cite: journals/corr/BahdanauCB14/Bahdanau/2015) . [[papers/nlp/translation/cho_neural_machine_translation_by_learning_to_jointly_align_and_translate.md|Notes]]
 - [[pdfs/nlp/translation/on_using_very_large_target_vocabulary_for_neural_machine_translation.pdf|On Using Very Large Target Vocabulary for Neural Machine Translation.]]: (cite: conf/acl/JeanCMB15) . [[papers/nlp/translation/on_using_very_large_target_vocabulary_for_neural_machine_translation.md|Notes]]
 - [[pdfs/nlp/translation/reformulating_unsupervised_style_transfer_as_paraphrase_generation.pdf|Reformulating Unsupervised Style Transfer as Paraphrase Generation.]]: (cite: conf/emnlp/KrishnaWI20) . [[papers/nlp/translation/reformulating_unsupervised_style_transfer_as_paraphrase_generation.md|Notes]]
 - [[pdfs/nlp/translation/unsuperivsed_neural_machine_translation_with_generative_language_models_only.pdf|Unsupervised Neural Machine Translation with Generative Language Models Only.]]: (cite: journals/corr/abs-2110-05448/Han/2021) . Distillation of a machine-translation model from a large language model using a few shots of amplication and then distillation (eg, fine-tuning the model on its own outputs) . [[papers/nlp/translation/unsuperivsed_neural_machine_translation_with_generative_language_models_only.md|Notes]]
 - [[pdfs/nlp/translation/unsupervised_text_style_transfer_with_padded_masked_language_models.pdf|Unsupervised Text Style Transfer with Padded Masked Language Models.]]: (cite: conf/emnlp/MalmiSR20) . [[papers/nlp/translation/unsupervised_text_style_transfer_with_padded_masked_language_models.md|Notes]]
 - [[pdfs/nlp/translation/zero_shot_translation_using_diffusion_models.pdf|Zero-Shot Translation using Diffusion Models.]]: (cite: journals/corr/abs-2111-01471/Nachmani/2021) . [[papers/nlp/translation/zero_shot_translation_using_diffusion_models.md|Notes]]
 - [[pdfs/nlp/translation/mgpt_few_shot_learners_go_multilingual.pdf|mGPT: Few-Shot Learners Go Multilingual.]]: (cite: journals/corr/abs-2204-07580/Shliazhko/2022) . [[papers/nlp/translation/mgpt_few_shot_learners_go_multilingual.md|Notes]]
### editing
 - [[pdfs/nlp/translation/editing/data_to_text_generation_with_iterative_text_editing.pdf|Data-to-Text Generation with Iterative Text Editing.]]: (cite: conf/inlg/KasnerD20) . [[papers/nlp/translation/editing/data_to_text_generation_with_iterative_text_editing.md|Notes]]
 - [[pdfs/nlp/translation/editing/editor_an_edit_based_transformer_with_repositioning_for_neural_machine_translation_with_soft_lexical_constraints.pdf|EDITOR: an Edit-Based Transformer with Repositioning for Neural Machine Translation with Soft Lexical Constraints.]]: (cite: journals/tacl/XuC21) . [[papers/nlp/translation/editing/editor_an_edit_based_transformer_with_repositioning_for_neural_machine_translation_with_soft_lexical_constraints.md|Notes]]
 - [[pdfs/nlp/translation/editing/edit5_semi_autoregressive_text_editing_with_t5_warm_start.pdf|EdiT5: Semi-Autoregressive Text-Editing with T5 Warm-Start.]]: (cite: journals/corr/abs-2205-12209/Mallinson/2022) . [[papers/nlp/translation/editing/edit5_semi_autoregressive_text_editing_with_t5_warm_start.md|Notes]]
 - [[pdfs/nlp/translation/editing/lasertagger_encode_tag_realize_high_precision_text_editting.pdf|Encode, Tag, Realize - High-Precision Text Editing.]]: (cite: conf/emnlp/MalmiKRMS19) . [[papers/nlp/translation/editing/lasertagger_encode_tag_realize_high_precision_text_editting.md|Notes]]
 - [[pdfs/nlp/translation/editing/encoder_decoder_models_can_benefit_from_pre_trained_masked_language_models_in_grammatical_error_correction.pdf|Encoder-Decoder Models Can Benefit from Pre-trained Masked Language Models in Grammatical Error Correction.]]: (cite: conf/acl/KanekoMKSI20) . [[papers/nlp/translation/editing/encoder_decoder_models_can_benefit_from_pre_trained_masked_language_models_in_grammatical_error_correction.md|Notes]]
 - [[pdfs/nlp/translation/editing/felix_flexible_text_editing_through_tagging_and_insertion.pdf|Felix: Flexible Text Editing Through Tagging and Insertion.]]: (cite: journals/corr/abs-2003-10687/Mallinson/2020) . [[papers/nlp/translation/editing/felix_flexible_text_editing_through_tagging_and_insertion.md|Notes]]
 - [[pdfs/nlp/translation/editing/gector_grammatical_error_correction_tag_not_rewrite.pdf|GECToR - Grammatical Error Correction: Tag, Not Rewrite.]]: (cite: conf/bea/OmelianchukACS20) . [[papers/nlp/translation/editing/gector_grammatical_error_correction_tag_not_rewrite.md|Notes]]
 - [[pdfs/nlp/translation/editing/hierarchical_context_tagging_for_utterance_rewriting.pdf|Hierarchical Context Tagging for Utterance Rewriting.]]: (cite: conf/aaai/JinSJ0G22) . [[papers/nlp/translation/editing/hierarchical_context_tagging_for_utterance_rewriting.md|Notes]]
 - [[pdfs/nlp/translation/editing/jointly_learning_to_align_and_translate_with_transformer_models.pdf|Jointly Learning to Align and Translate with Transformer Models.]]: (cite: conf/emnlp/GargPNP19) . [[papers/nlp/translation/editing/jointly_learning_to_align_and_translate_with_transformer_models.md|Notes]]
 - [[pdfs/nlp/translation/editing/lewis_levensthein_editing_for_unsupervised_text_style_transfer.pdf|LEWIS: Levenshtein Editing for Unsupervised Text Style Transfer.]]: (cite: conf/acl/ReidZ21) . [[papers/nlp/translation/editing/lewis_levensthein_editing_for_unsupervised_text_style_transfer.md|Notes]]
 - [[pdfs/nlp/translation/editing/lm_critic_language_models_for_unsupervised_grammatical_error_correction.pdf|LM-Critic: Language Models for Unsupervised Grammatical Error Correction.]]: (cite: conf/emnlp/YasunagaLL21) . [[papers/nlp/translation/editing/lm_critic_language_models_for_unsupervised_grammatical_error_correction.md|Notes]]
 - [[pdfs/nlp/translation/editing/levenshtein_transformers.pdf|Levenshtein Transformer.]]: (cite: conf/nips/GuWZ19) . [[papers/nlp/translation/editing/levenshtein_transformers.md|Notes]]
 - [[pdfs/nlp/translation/editing/pie_parallel_iterative_edit_models_for_local_sequence_transduction.pdf|Parallel Iterative Edit Models for Local Sequence Transduction.]]: (cite: conf/emnlp/AwasthiSGGP19) Does non-autoregressive decoding of edit tokens, instead does them in parallel. It predicts edits instead of tokens. . [[papers/nlp/translation/editing/pie_parallel_iterative_edit_models_for_local_sequence_transduction.md|Notes]]
 - [[pdfs/nlp/translation/editing/seq2edits_sequence_transduction_using_span_level_edit_operations.pdf|Seq2Edits: Sequence Transduction Using Span-level Edit Operations.]]: (cite: conf/emnlp/StahlbergK20) . [[papers/nlp/translation/editing/seq2edits_sequence_transduction_using_span_level_edit_operations.md|Notes]]
 - [[pdfs/nlp/translation/editing/stronger_baselines_for_grammatical_error_correction_using_a_pretrained_encoder_decoder_model.pdf|Stronger Baselines for Grammatical Error Correction Using a Pretrained Encoder-Decoder Model.]]: (cite: conf/ijcnlp/KatsumataK20) . [[papers/nlp/translation/editing/stronger_baselines_for_grammatical_error_correction_using_a_pretrained_encoder_decoder_model.md|Notes]]
 - [[pdfs/nlp/translation/editing/masker_unsupervised_text_style_transfer_with_padded_masked_language_models.pdf|Unsupervised Text Style Transfer with Padded Masked Language Models.]]: (cite: conf/emnlp/MalmiSR20) MASKER architecture for text-editing for style transfer. Train MLM for both source and target domain, then find text spans where the models disagree the most, such that we can identify what to delete in the source to match the style of the target. [[papers/nlp/translation/editing/masker_unsupervised_text_style_transfer_with_padded_masked_language_models.md|Notes]]
# programming
 - [[pdfs/programming/catala_programming_for_law.pdf|Catala: a programming language for the law.]]: (cite: journals/pacmpl/MerigouxCP21) . [[papers/programming/catala_programming_for_law.md|Notes]]
# rl
 - [[pdfs/rl/a_markov_decision_process.pdf|A Markovian Decision Process.]]: (cite: bellman1957markovian) . [[papers/rl/a_markov_decision_process.md|Notes]]
 - [[pdfs/rl/bisimulation_metrics_are_optimal_value_functions.pdf|Bisimulation Metrics are Optimal Value Functions.]]: (cite: conf/uai/FernsP14) . [[papers/rl/bisimulation_metrics_are_optimal_value_functions.md|Notes]]
 - [[pdfs/rl/deep_rl_statistical_precipice.pdf|Deep Reinforcement Learning at the Edge of the Statistical Precipice.]]: (cite: journals/corr/abs-2108-13264/Agarwal/2021) Presents a common and robust methodology for reporting scores/improvements using a "handful of runs". [[papers/rl/deep_rl_statistical_precipice.md|Notes]]
 - [[pdfs/rl/embodied_intelligence_via_learning_and_evolution.pdf|Embodied Intelligence via Learning and Evolution.]]: (cite: journals/corr/abs-2102-02202/Gupta/2021) Combines evolutionary algorithms and reinforcement learning to study meta-reinforcement-learning via evolution. [[papers/rl/embodied_intelligence_via_learning_and_evolution.md|Notes]]
 - [[pdfs/rl/estimating_disentangled_belief_meta_rl.pdf|Estimating Disentangled Belief about Hidden State and Hidden Task for Meta-RL.]]: (cite: journals/corr/abs-2105-06660/Akuzawa/2021) . [[papers/rl/estimating_disentangled_belief_meta_rl.md|Notes]]
 - [[pdfs/rl/flambe_representation_low_rank_mdp.pdf|FLAMBE: Structural Complexity and Representation Learning of Low Rank MDPs.]]: (cite: conf/nips/AgarwalKKS20) . [[papers/rl/flambe_representation_low_rank_mdp.md|Notes]]
 - [[pdfs/rl/hindsight_credit_assignment.pdf|Hindsight Credit Assignment.]]: (cite: conf/nips/HarutyunyanDMAP19) . [[papers/rl/hindsight_credit_assignment.md|Notes]]
 - [[pdfs/rl/hyperbolic_deep_reinforcement_learning.pdf|Hyperbolic Deep Reinforcement Learning.]]: (cite: journals/corr/abs-2210-01542/Cetin/2022) . [[papers/rl/hyperbolic_deep_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/laser_latent_action_space_efficient_rl.pdf|LASER: Learning a Latent Action Space for Efficient Reinforcement Learning.]]: (cite: conf/icra/AllshireMLMSG21) . [[papers/rl/laser_latent_action_space_efficient_rl.md|Notes]]
 - [[pdfs/rl/learning_to_synthesize_programs_as_interpretable_and_generalizable_policies.pdf|Learning to Synthesize Programs as Interpretable and Generalizable Policies.]]: (cite: conf/nips/TrivediZSL21) . [[papers/rl/learning_to_synthesize_programs_as_interpretable_and_generalizable_policies.md|Notes]]
 - [[pdfs/rl/reinforcement_learning_an_introduction_sutton_barto.pdf|Reinforcement Learning: An Introduction.]]: (cite: journals/tnn/SuttonB98) . [[papers/rl/reinforcement_learning_an_introduction_sutton_barto.md|Notes]]
 - [[pdfs/rl/reproducibility_of_benchmarked_deep_reinforcement_learning_tasks_for_continous_control.pdf|Reproducibility of Benchmarked Deep Reinforcement Learning Tasks for Continuous Control.]]: (cite: journals/corr/abs-1708-04133/Islam/2017) . [[papers/rl/reproducibility_of_benchmarked_deep_reinforcement_learning_tasks_for_continous_control.md|Notes]]
 - [[pdfs/rl/shortest_path_constrained_rl_sparse_reward.pdf|Shortest-Path Constrained Reinforcement Learning for Sparse Reward Tasks.]]: (cite: conf/icml/SohnLCSFL21) . [[papers/rl/shortest_path_constrained_rl_sparse_reward.md|Notes]]
 - [[pdfs/rl/the_information_geometry_of_unsupervised_reinforcement_learning.pdf|The Information Geometry of Unsupervised Reinforcement Learning.]]: (cite: journals/corr/abs-2110-02719/Eysenbach/2021) . [[papers/rl/the_information_geometry_of_unsupervised_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/act2vec.pdf|The Natural Language of Actions.]]: (cite: conf/icml/TennenholtzM19) . [[papers/rl/act2vec.md|Notes]]
 - [[pdfs/rl/predicting_predictable_frames.pdf|Time-Agnostic Prediction: Predicting Predictable Video Frames.]]: (cite: conf/iclr/JayaramanEEL19) . [[papers/rl/predicting_predictable_frames.md|Notes]]
## augmentation
 - [[pdfs/rl/augmentation/gato_a_generalist_agent.pdf|A Generalist Agent.]]: (cite: journals/corr/abs-2205-06175/Reed/2022) . [[papers/rl/augmentation/gato_a_generalist_agent.md|Notes]]
 - [[pdfs/rl/augmentation/mastering_visual_continuous_continuous_control_improved_data_augmented_reinforcement_learning.pdf|Mastering Visual Continuous Control - Improved Data-Augmented Reinforcement Learning.]]: (cite: journals/corr/abs-2107-09645/Yarats/2021) . [[papers/rl/augmentation/mastering_visual_continuous_continuous_control_improved_data_augmented_reinforcement_learning.md|Notes]]
## causal
 - [[pdfs/rl/causal/hypothesis_verification.pdf|Empirically Verifying Hypotheses Using Reinforcement Learning.]]: (cite: journals/corr/abs-2006-15762/Marino/2020) . [[papers/rl/causal/hypothesis_verification.md|Notes]]
 - [[pdfs/rl/causal/generalizing_goal_conditioned_reinforcement_learning_with_variational_causal_reasoning.pdf|Generalizing Goal-Conditioned Reinforcement Learning with Variational Causal Reasoning.]]: (cite: journals/corr/abs-2207-09081/Ding/2022) . [[papers/rl/causal/generalizing_goal_conditioned_reinforcement_learning_with_variational_causal_reasoning.md|Notes]]
## constraints
 - [[pdfs/rl/constraints/combining_reinfrocement_learning_and_constraint_programming_for_sequence_generation_tasks_with_hard_constraints.pdf|Combining Reinforcement Learning and Constraint Programming for Sequence-Generation Tasks with Hard Constraints.]]: (cite: conf/cp/LafleurCP22) . [[papers/rl/constraints/combining_reinfrocement_learning_and_constraint_programming_for_sequence_generation_tasks_with_hard_constraints.md|Notes]]
## critical_states
 - [[pdfs/rl/critical_states/critical_regions_saliency_maps_planning.pdf|Identifying Critical Regions for Motion Planning using Auto-Generated Saliency Labels with Convolutional Neural Networks.]]: (cite: journals/corr/abs-1903-03258/Molina/2019) . [[papers/rl/critical_states/critical_regions_saliency_maps_planning.md|Notes]]
 - [[pdfs/rl/critical_states/critical_probabilistic_roadmaps.pdf|Learned Critical Probabilistic Roadmaps for Robotic Motion Planning.]]: (cite: conf/icra/IchterSLF20) . [[papers/rl/critical_states/critical_probabilistic_roadmaps.md|Notes]]
 - [[pdfs/rl/critical_states/world_model_graph.pdf|World Model as a Graph - Learning Latent Landmarks for Planning.]]: (cite: conf/icml/Zhang0S21a) Cluster seen states in the latent space, classify landmarks, induce a graph based on a reachability metric and then plan using the graph.  [[papers/rl/critical_states/world_model_graph.md|Notes]]
## curriculum
 - [[pdfs/rl/curriculum/probabilistic_self_based_learning_with_applications_to_rl.pdf|A Probabilistic Interpretation of Self-Paced Learning with Applications to Reinforcement Learning.]]: (cite: journals/jmlr/KlinkABDPP21) . [[papers/rl/curriculum/probabilistic_self_based_learning_with_applications_to_rl.md|Notes]]
 - [[pdfs/rl/curriculum/curriculum_learning_survey.pdf|Curriculum Learning: A Survey.]]: (cite: journals/ijcv/SovianyIRS22) . [[papers/rl/curriculum/curriculum_learning_survey.md|Notes]]
 - [[pdfs/rl/curriculum/task_factorization_in_curriculum_learning.pdf|Task Factorization in Curriculum Learning]]: . [[papers/rl/curriculum/task_factorization_in_curriculum_learning.md|Notes]]
## environments
 - [[pdfs/rl/environments/avalon_a_benchmark_for_rl_generalization_using_procedurally_generated_worlds.pdf|Avalon: A Benchmark for RL Generalization Using Procedurally Generated Worlds.]]: (cite: journals/corr/abs-2210-13417/Albrecht/2022) . [[papers/rl/environments/avalon_a_benchmark_for_rl_generalization_using_procedurally_generated_worlds.md|Notes]]
## exploration
 - [[pdfs/rl/exploration/byol_explore_exploration_by_bootstrapped_prediction.pdf|BYOL-Explore: Exploration by Bootstrapped Prediction.]]: (cite: journals/corr/abs-2206-08332/Guo/2022) . [[papers/rl/exploration/byol_explore_exploration_by_bootstrapped_prediction.md|Notes]]
 - [[pdfs/rl/exploration/cic_contrastive_intrinsic_control_for_unsupervised_skill_discovery.pdf|CIC - Contrastive Intrinsic Control for Unsupervised Skill Discovery.]]: (cite: journals/corr/abs-2202-00161/Laskin/2022) Entropy-of-states conditioned on skills, as opposed to entropy of skills conditioned in on states. . [[papers/rl/exploration/cic_contrastive_intrinsic_control_for_unsupervised_skill_discovery.md|Notes]]
 - [[pdfs/rl/exploration/curl_contrastive_rl.pdf|CURL: Contrastive Unsupervised Representations for Reinforcement Learning.]]: (cite: conf/icml/LaskinSA20) . [[papers/rl/exploration/curl_contrastive_rl.md|Notes]]
 - [[pdfs/rl/exploration/ex2_exploration_exemplar_models.pdf|EX2: Exploration with Exemplar Models for Deep Reinforcement Learning.]]: (cite: conf/nips/FuCL17) . [[papers/rl/exploration/ex2_exploration_exemplar_models.md|Notes]]
 - [[pdfs/rl/exploration/episodic_curiousity_through_reachability.pdf|Episodic Curiousity through Reachability]]: . [[papers/rl/exploration/episodic_curiousity_through_reachability.md|Notes]]
 - [[pdfs/rl/exploration/exploration_via_planning_for_information_about_the_optimal_trajectory.pdf|Exploration via Planning for Information about the Optimal Trajectory.]]: (cite: journals/corr/abs-2210-04642/Mehta/2022) . [[papers/rl/exploration/exploration_via_planning_for_information_about_the_optimal_trajectory.md|Notes]]
 - [[pdfs/rl/exploration/is_curiousity_all_you_need.pdf|Is Curiousity all you need? On the utility of emergent behaviours from curious exploration]]: Curiousity in exploration might overwrite useful behaviours used to reach areas of the state space which are now no longer "interesting", meaning that as an agent explores, it forgets how to reach areas of the state space that it did in the past. This paper proposes a mechanism to try and remember those behaviours, so the the entire state space can still be reached. [[papers/rl/exploration/is_curiousity_all_you_need.md|Notes]]
 - [[pdfs/rl/exploration/imagine_language_cognitive_exploration.pdf|Language as a Cognitive Tool to Imagine Goals in Curiosity Driven Exploration.]]: (cite: conf/nips/ColasKLDMDO20) . [[papers/rl/exploration/imagine_language_cognitive_exploration.md|Notes]]
 - [[pdfs/rl/exploration/novelty_search_representational_space.pdf|Novelty Search in representational space for sample efficient exploration.]]: (cite: journals/corr/abs-2009-13579/Tao/2020) . [[papers/rl/exploration/novelty_search_representational_space.md|Notes]]
 - [[pdfs/rl/exploration/open_ended_reinforcement_learning_with_neural_reward_functions.pdf|Open-Ended Reinforcement Learning with Neural Reward Functions.]]: (cite: journals/corr/abs-2202-08266/Meier/2022) . [[papers/rl/exploration/open_ended_reinforcement_learning_with_neural_reward_functions.md|Notes]]
 - [[pdfs/rl/exploration/provably_efficient_unsupervised.pdf|Provably Efficient Exploration for Reinforcement Learning Using Unsupervised Learning.]]: (cite: conf/nips/FengWYDY20) . [[papers/rl/exploration/provably_efficient_unsupervised.md|Notes]]
 - [[pdfs/rl/exploration/ready_policy_one.pdf|Ready Policy One: World Building Through Active Learning.]]: (cite: conf/icml/BallPPCR20) . [[papers/rl/exploration/ready_policy_one.md|Notes]]
 - [[pdfs/rl/exploration/sample_efficient_rl_pomdp.pdf|Sample-Efficient Reinforcement Learning of Undercomplete POMDPs.]]: (cite: conf/nips/JinKKL20) Shows that partial observability does not preclude efficient reinforcement learning for a rich and interesting subclass of POMDPs. Presents a sample-efficient algorithm called *OOM-UCB* for episodic finite *undercomplete* POMDPs where the number of observation is larger tha the number of latent states and where exploration is essential for learning. OOM-UCB gets an $\epsilon$-optimal sample complexity of $\bar{\mathcal{O}(\frac{1}{\epsilon^2}})$ . [[papers/rl/exploration/sample_efficient_rl_pomdp.md|Notes]]
 - [[pdfs/rl/exploration/self_paced_deep_reinforcement_learning.pdf|Self-Paced Deep Reinforcement Learning.]]: (cite: conf/nips/KlinkD0P20) Curriculum learning can work quite well, but the problem is generating the curriculum. This paper presents a method for interpolating between easy-to-learn and the target task by defining a parameterized distribution over the task space. Parameterize the distribution by the expected reward that the agent will get when performing a task. Then maximize the expected task reward - KL divergence of the task distribution vs the "target" task distribution. Initially the agent will only be able to solve easy tasks, so we take a high KL penalty in order to maximize reward. But as we can solve more tasks, the task distribution drifts closer to the true task distribution. [[papers/rl/exploration/self_paced_deep_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/exploration/rig_imagined_goals.pdf|Visual Reinforcement Learning with Imagined Goals.]]: (cite: conf/nips/NairPDBLL18) Train a VAE using data generated by the exploration policy, then sample goals to train the policy and embed them into a latent space . [[papers/rl/exploration/rig_imagined_goals.md|Notes]]
 - [[pdfs/rl/exploration/learned_intrinsic_rewards.pdf|What Can Learned Intrinsic Rewards Capture?]]: (cite: conf/icml/ZhengOHXKHSS20) . [[papers/rl/exploration/learned_intrinsic_rewards.md|Notes]]
### mapping
 - [[pdfs/rl/exploration/mapping/learning_to_act_with_affordance_aware_multimodal_neural_slam.pdf|Learning to Act with Affordance-Aware Multimodal Neural SLAM.]]: (cite: journals/corr/abs-2201-09862/Jia/2022) . [[papers/rl/exploration/mapping/learning_to_act_with_affordance_aware_multimodal_neural_slam.md|Notes]]
 - [[pdfs/rl/exploration/mapping/learning_to_explore_using_active_neural_slam.pdf|Learning to Explore using Active Neural SLAM.]]: (cite: journals/corr/abs-2004-05155/Chaplot/2020) . [[papers/rl/exploration/mapping/learning_to_explore_using_active_neural_slam.md|Notes]]
## generalists
 - [[pdfs/rl/generalists/agent57_atari.pdf|Agent57: Outperforming the Atari Human Benchmark.]]: (cite: conf/icml/BadiaPKSVGB20) None. [[papers/rl/generalists/agent57_atari.md|Notes]]
## generalization
 - [[pdfs/rl/generalization/a_boolean_task_algebra_for_reinforcement_learning.pdf|A Boolean Task Algebra for Reinforcement Learning.]]: (cite: conf/nips/TasseJR20) . [[papers/rl/generalization/a_boolean_task_algebra_for_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/generalization/survey_generalization_deep_rl_zhang.pdf|A Survey of Generalization in Deep Reinforcement Learning]]: (cite: journals/corr/abs-2111-09794/Kirk/2021) Covers a few different areas, including generalization test environments, metrics for generalization, different types of generalization, un-explored problems in generalization etc. [[papers/rl/generalization/survey_generalization_deep_rl_zhang.md|Notes]]
 - [[pdfs/rl/generalization/agent_do_you_see_it_now_systematic_generaliation_in_deep_reinforcement_learning.pdf|Agent, Do you see it now? Systematic Generalization in Deep Reinforcement Learning]]: . [[papers/rl/generalization/agent_do_you_see_it_now_systematic_generaliation_in_deep_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/generalization/build_generally_reusable_agent_environment_interaction_models.pdf|Build generally reusable agent-environment interaction models.]]: (cite: journals/corr/abs-2211-08234/Jin/2022) . [[papers/rl/generalization/build_generally_reusable_agent_environment_interaction_models.md|Notes]]
 - [[pdfs/rl/generalization/deep_sets_for_generalization_in_rl.pdf|Deep Sets for Generalization in RL.]]: (cite: journals/corr/abs-2003-09443/Karch/2020) . [[papers/rl/generalization/deep_sets_for_generalization_in_rl.md|Notes]]
 - [[pdfs/rl/generalization/distributionally_robust_neural_networks_for_group_shifts_on_the_importance_of_regularization_for_worst_case_generalization.pdf|Distributionally Robust Neural Networks for Group Shifts: On the Importance of Regularization for Worst-Case Generalization.]]: (cite: journals/corr/abs-1911-08731/Sagawa/2019) . [[papers/rl/generalization/distributionally_robust_neural_networks_for_group_shifts_on_the_importance_of_regularization_for_worst_case_generalization.md|Notes]]
 - [[pdfs/rl/generalization/environment_inference_for_invariant_learning.pdf|Environment Inference for Invariant Learning.]]: (cite: conf/icml/CreagerJZ21) . [[papers/rl/generalization/environment_inference_for_invariant_learning.md|Notes]]
 - [[pdfs/rl/generalization/illuminating_generalization_in_deep_rl_through_procedural_generation.pdf|Illuminating Generalization in Deep Reinforcement Learning through Procedural Level Generation]]: . [[papers/rl/generalization/illuminating_generalization_in_deep_rl_through_procedural_generation.md|Notes]]
 - [[pdfs/rl/generalization/measuring_compositionality_in_reinforcement_learning.pdf|Measuring Compositionality in Representation Learning.]]: (cite: conf/iclr/Andreas19) . [[papers/rl/generalization/measuring_compositionality_in_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/generalization/measuring_and_characterizing_generalization_in_deep_rl.pdf|Measuring and Characterizing Generalization in Deep Reinforcement Learning.]]: (cite: journals/corr/abs-1812-02868/Witty/2018) Re-examines what is meant by generalization in reinforcement learning. Proposes several definitions and a set of practical methods for evaluating agents with these definitions on a common benchmark task. Also shows that standard methods really fail to generalize well. The three definitions are based on Repetition, Interpolation and Extrapolation. Generalization Error can be expressed as the the difference between the true and Q value of a state under an optimal policy under a condition and the estimated Q value under that condition . [[papers/rl/generalization/measuring_and_characterizing_generalization_in_deep_rl.md|Notes]]
 - [[pdfs/rl/generalization/neuro_algorithmic_policies_fast_combinatorial_generalization.pdf|Neuro-algorithmic Policies Enable Fast Combinatorial Generalization.]]: (cite: conf/icml/PRM21) . [[papers/rl/generalization/neuro_algorithmic_policies_fast_combinatorial_generalization.md|Notes]]
 - [[pdfs/rl/generalization/neuroevolution_self_interpretable_agents.pdf|Neuroevolution of self-interpretable agents.]]: (cite: conf/gecco/TangNH20) Chop the image up into patches and use attention to select the K most important pathces as a form of sparsity. Agents using this information were robust to changes in the observation such as color perturbations, vertical bars in the input and other distractors in the input. Also showed that such an inductive bias can in some cases be harmful, eg, showed that adding a distractor that was similar to the attended object harmed performance. [[papers/rl/generalization/neuroevolution_self_interpretable_agents.md|Notes]]
 - [[pdfs/rl/generalization/on_the_measure_of_intelligence.pdf|On the Measure of Intelligence.]]: (cite: journals/corr/abs-1911-01547/Chollet/2019) We need to be able to define and evaluate intelligence in a way that enables comparison between two systems as well as comparisons to humans. The contemporary community measures skill, but this falsl short of measuring intelligence, because unlimited training data can buy you skill . In this work, there is a new formal definition of intelligence based on information theory: generalization difficulty, priors and experience. Then this work proposes what a general AI benchmark should look like, for example, through the Abstraction and Reasoning Corpus. . [[papers/rl/generalization/on_the_measure_of_intelligence.md|Notes]]
 - [[pdfs/rl/generalization/quantifying_generalization_in_rl.pdf|Quantifying G eneralization in Reinforcement Learning]]: . [[papers/rl/generalization/quantifying_generalization_in_rl.md|Notes]]
 - [[pdfs/rl/generalization/schema_networks_zero_shot_transfer_generative_causal_model.pdf|Schema Networks - Zero-shot Transfer with a Generative Causal Model of Intuitive Physics.]]: (cite: conf/icml/KanskySMELLDSPG17) Parse input into "entities". A schema is a variable associated with a particular entity-attribute and the next timestep. When all the preconditions are satisfied, the schema is active. Has AND and OR gates for the variables. Use linear programming to solve for the schemas. Paper studies the effectiveness of schema networks in the transfer learning setting, with the hypothesis that if a model learns the dynamics from one variation, the others could be played perfetly by planning. [[papers/rl/generalization/schema_networks_zero_shot_transfer_generative_causal_model.md|Notes]]
 - [[pdfs/rl/generalization/sparse_attention_guided_dynamic_value_estimation.pdf|Sparse Attention Guided Dynamic Value Estimation for Single-Task Multi-Scene Reinforcement Learning.]]: (cite: journals/corr/abs-2102-07266/Singh/2021) Multi-scene RL might improve generalization, but if you re-use the value function for many different scenes you get significant variance in the value function estimate. In reality, the features tend to form clusters, so you can estimate the value function more effectively if you know which cluster you belong to. This work introduces a "attention-based" value function, which basically learns some attention weights to figure out which cluster to pay attention to. The work goes further to introduce a method to *sparsify* that attention over the course of training, with a loss function to ensure that there is both sparsity *and* diversity in terms of chosen clusters over the entire dataset. The authors show through their experiments that the sparse attention model used to estimate value leads to policies that significantly outperform a baseline CNN/LSTM/PPO, and furthermore that sparsity actually helps significantly in this area. [[papers/rl/generalization/sparse_attention_guided_dynamic_value_estimation.md|Notes]]
 - [[pdfs/rl/generalization/systematic_generalization_what_is_required_can_it_be_learned.pdf|Systematic Generalization - What Is Required and Can It Be Learned?]]: (cite: conf/iclr/BahdanauMNNVC19) . [[papers/rl/generalization/systematic_generalization_what_is_required_can_it_be_learned.md|Notes]]
### compositional
 - [[pdfs/rl/generalization/compositional/grounded_compositional_generalization_with_environment_interactions.pdf|Grounded Compositional Generalization with Environment Interactions]]: (cite: conf/iclr/Li21) Improvements on gSCAN Split H with a modular architecture and entropy regularization. Note that this isn't *really* comparable to other works, since they don't predict the ground-truth sequence, but rather step-by-step 3-tuples of direction, action and manner.  [[papers/rl/generalization/compositional/grounded_compositional_generalization_with_environment_interactions.md|Notes]]
 - [[pdfs/rl/generalization/compositional/policy_architectures_for_compositional_generalization_in_control.pdf|Policy Architectures for Compositional Generalization in Control.]]: (cite: journals/corr/abs-2203-05960/Zhou/2022) . [[papers/rl/generalization/compositional/policy_architectures_for_compositional_generalization_in_control.md|Notes]]
## graph_based
 - [[pdfs/rl/graph_based/graph_based_generation_of_abstractions.pdf|Graph Learning based Generation of Abstractions for Reinforcement Learning]]: . [[papers/rl/graph_based/graph_based_generation_of_abstractions.md|Notes]]
 - [[pdfs/rl/graph_based/learning_generalized_policies_without_supervision_using_gnns.pdf|Learning Generalized Policies without Supervision Using GNNs.]]: (cite: conf/kr/StahlbergBG22) . [[papers/rl/graph_based/learning_generalized_policies_without_supervision_using_gnns.md|Notes]]
## grounded_language
 - [[pdfs/rl/grounded_language/survey_rl_informed_by_natural_language.pdf|A Survey of Reinforcement Learning Informed by Natural Language.]]: (cite: conf/ijcai/LuketinaNFFAGWR19) . [[papers/rl/grounded_language/survey_rl_informed_by_natural_language.md|Notes]]
 - [[pdfs/rl/grounded_language/mapping_instructions_and_visual_observations_to_actions_with_reinforcement_learning.pdf|Mapping Instructions and Visual Observations to Actions with Reinforcement Learning.]]: (cite: conf/emnlp/MisraLA17) Studies complex language instrucitons in a fully observable blocks-world. [[papers/rl/grounded_language/mapping_instructions_and_visual_observations_to_actions_with_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/grounded_language/overcoming_referential_ambiguity_in_language_guided_goal_conditioned_reinforcement_learning.pdf|Overcoming Referential Ambiguity in Language-Guided Goal-Conditioned Reinforcement Learning.]]: (cite: journals/corr/abs-2209-12758/Caselles-Dupre/2022) . [[papers/rl/grounded_language/overcoming_referential_ambiguity_in_language_guided_goal_conditioned_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/grounded_language/learn_using_natural_language_for_reward_shaping_in_rl.pdf|Using Natural Language for Reward Shaping in Reinforcement Learning.]]: (cite: conf/ijcai/GoyalNM19) Map from free-form natural language instructions to intermediate rewards based on actions takne by agent. 60% completion rate on Montezuma's Revenge. Descriptions obtained from human annotators. Train a discriminator to determine if a particular sentence is related to or unrelated to the action sequence. Then at test time the agent is given the language description of how to solve the task and picks actions so as to maximize the probability of agreement between the action sequence and the language instructions. The main claim is that you get faster learning performance, since you can use the discriminator output as a kind of intermediate reward to guide learning. [[papers/rl/grounded_language/learn_using_natural_language_for_reward_shaping_in_rl.md|Notes]]
### attention
 - [[pdfs/rl/grounded_language/attention/gated_attention_architectures_for_task_oriented_language_grounding.pdf|Gated-Attention Architectures for Task-Oriented Language Grounding.]]: (cite: conf/aaai/ChaplotSPRS18) Examined zero-shot task generalization with language-encoded tasks in vizdoom environment, where some tasks were withheld from the training set. 3D Navigation. Reported 70\%+ accuracy on the "hard" dataset with their gated-attention method. Amount of training data generated not reported, but presumably it is high due to the long training time. Training data included "catch-all" descriptions such as "blue object" as goals, meaning that even if "blue torch" was not in the training set, it may still appear as a target in the training data and thus appear in feature maps generated by the convolutional encoder. [[papers/rl/grounded_language/attention/gated_attention_architectures_for_task_oriented_language_grounding.md|Notes]]
 - [[pdfs/rl/grounded_language/attention/hanjie_emma_grounding_language_to_entities_and_dynamics.pdf|Grounding Language to Entities and Dynamics for Generalization in Reinforcement Learning.]]: (cite: conf/icml/HanjieZN21) Develops a new environment called "Messenger" to investigate the use of natural language conditioned policies. The environment is set up in a way that there is no supervision on the symbol grounding - the agent only gets a reward if it delivers the message correctly, but it must learn to do the symbol grounding itself. The authors develop a model called EMMA "Entity Mapper with Multi-Modal Attention", which in brief encodes text using BERT, then does attention between the encoded text and the symbol embeddings and re-weights the symbols according to this attention. The idea is that the value function should extract information relevant to the entity's role in the world (eg, "enemy, chasing etc"). The authors found that the model could get good generalization on held-out test games with unseen symbol-role combinations (so the model had seen the symbol before, but not in the role as indicated by the language statement). Also they performed a qualitative analysis where they looked at the attention head for language/objects and found that there was sparsity. [[papers/rl/grounded_language/attention/hanjie_emma_grounding_language_to_entities_and_dynamics.md|Notes]]
### babyai
 - [[pdfs/rl/grounded_language/babyai/babyai_with_transformers_kujanpaa.pdf|A Deep Relational Model for Natural Language Understanding]]: . [[papers/rl/grounded_language/babyai/babyai_with_transformers_kujanpaa.md|Notes]]
 - [[pdfs/rl/grounded_language/babyai/babyai.pdf|BabyAI - A Platform to Study the Sample Efficiency of Grounded Language Learning.]]: (cite: conf/iclr/Chevalier-Boisvert19) . [[papers/rl/grounded_language/babyai/babyai.md|Notes]]
 - [[pdfs/rl/grounded_language/babyai/babyai1.1.pdf|BabyAI 1.1.]]: (cite: journals/corr/abs-2007-12770/Hui/2020) . [[papers/rl/grounded_language/babyai/babyai1.1.md|Notes]]
 - [[pdfs/rl/grounded_language/babyai/babyai++.pdf|BabyAI++ - Towards Grounded-Language Learning beyond Memorization.]]: (cite: journals/corr/abs-2004-07200/Cao/2020) . [[papers/rl/grounded_language/babyai/babyai++.md|Notes]]
### communication
 - [[pdfs/rl/grounded_language/communication/few_shot_language_coordination_by_modeling_theory_of_mind.pdf|Few-shot Language Coordination by Modeling Theory of Mind.]]: (cite: conf/icml/ZhuNB21) . [[papers/rl/grounded_language/communication/few_shot_language_coordination_by_modeling_theory_of_mind.md|Notes]]
 - [[pdfs/rl/grounded_language/communication/natural_language_communication_with_robots.pdf|Natural Language Communication with Robots.]]: (cite: conf/naacl/BiskYM16) . Present a block-moving task, where the agent needs to move a random assortment of blocks so that they look like an MNIST image. Each of the blocks is identifiable by some logo which can be described in many ways by the human annotators. There are instrucitons about how to complete each step in the dataset. [[papers/rl/grounded_language/communication/natural_language_communication_with_robots.md|Notes]]
 - [[pdfs/rl/grounded_language/communication/language_learning_from_communicative_goals_and_linguistic_input.pdf|Simulated Language Learning from Communicative Goals and Linguistic Input]]: . [[papers/rl/grounded_language/communication/language_learning_from_communicative_goals_and_linguistic_input.md|Notes]]
 - [[pdfs/rl/grounded_language/communication/speaker_follower_models.pdf|Speaker-Follower Models for Vision-and-Language Navigation.]]: (cite: conf/nips/FriedHCRAMBSKD18) . [[papers/rl/grounded_language/communication/speaker_follower_models.md|Notes]]
### contrastive
 - [[pdfs/rl/grounded_language/contrastive/agile_learning_to_understanding_goal_specifications_by_modelling_reward.pdf|Learning to Understand Goal Specifications by Modelling Reward.]]: (cite: conf/iclr/BahdanauHLHHKG19) Task-conditioned reward modelling using a discriminator. Designed to be used in conjunction with a model-free method. The discriminator learns to distinguish between goal states for instructions as reached by an expert versus non-rewarding states reached by the agent during the learning process. The purpose of this work is to learn a reward function where it isn't feasisble to provide one in the environment (similar also to ValueDICE, RCE). [[papers/rl/grounded_language/contrastive/agile_learning_to_understanding_goal_specifications_by_modelling_reward.md|Notes]]
### curriculum
 - [[pdfs/rl/grounded_language/curriculum/curriculum_learning_for_vision_grounded_instruction_following.pdf|Curriculum Learning for Vision-Grounded Instruction Following]]: The authors explore principles for creating a curriculum for instruction-following. They consider the factors Subtask Trajectory (eg, learning things that you could stich together), Pacing (how much training you give to each sub-task or level), Subtask Ordering (eg, does the ordering of things to learn affect learning effectiveness). They also look at automated curriculum design approaches, eg, with a teacher that gets a reward for the agent learning.. [[papers/rl/grounded_language/curriculum/curriculum_learning_for_vision_grounded_instruction_following.md|Notes]]
### empirical
 - [[pdfs/rl/grounded_language/empirical/diagnosing_vision_and_language_navigation_what_really_matters.pdf|Diagnosing Vision-and-Language Navigation: What Really Matters.]]: (cite: conf/naacl/ZhuQNSBWWEW22) . [[papers/rl/grounded_language/empirical/diagnosing_vision_and_language_navigation_what_really_matters.md|Notes]]
 - [[pdfs/rl/grounded_language/empirical/do_trajectories_encode_verb_meaning.pdf|Do Trajectories Encode Verb Meaning?]]: (cite: conf/naacl/EbertSP22) . [[papers/rl/grounded_language/empirical/do_trajectories_encode_verb_meaning.md|Notes]]
 - [[pdfs/rl/grounded_language/empirical/early_word_learning.pdf|Understanding Early Word Learning in Situated Artificial Agents.]]: . [[papers/rl/grounded_language/empirical/early_word_learning.md|Notes]]
 - [[pdfs/rl/grounded_language/empirical/understanding_grounded_language_learning_agents.pdf|Understanding Grounded Language Learning Agents.]]: (cite: journals/corr/abs-1710-09867/Hill/2017) Studies some of the learning dynamics characteristics in the grounded language learning problem. Finds that there is a colour bias when learning new object descriptions, because colours are easier to detect than shapes. Negation is hard to represent if trained with a small amount of data. More words are learned more quickly if the range of words to which the agent is exposed is limited at first and then expanded gradully. Words of different semantic classes are learned at different speeds and represented with features that require different degrees of visual processing depth . [[papers/rl/grounded_language/empirical/understanding_grounded_language_learning_agents.md|Notes]]
 - [[pdfs/rl/grounded_language/empirical/what_do_navigation_agents_learn_about_their_environment.pdf|What do navigation agents learn about their environment?]]: (cite: conf/cvpr/DwivediRKM22) . [[papers/rl/grounded_language/empirical/what_do_navigation_agents_learn_about_their_environment.md|Notes]]
### environments
 - [[pdfs/rl/grounded_language/environments/gcomm_an_environment_for_investigating_generalization_in_grounded_language_acquisition.pdf|gComm: An environment for investigating generalization in Grounded Language Acquisition.]]: (cite: journals/corr/abs-2105-03943/Hazra/2021) gSCAN with a speaker-listener model. Speaker gets the instruction, listener gets the grid view and has to navigate. They have to learn to communicate.. [[papers/rl/grounded_language/environments/gcomm_an_environment_for_investigating_generalization_in_grounded_language_acquisition.md|Notes]]
#### 3d
 - [[pdfs/rl/grounded_language/environments/3d/deepmind_lab.pdf|DeepMind Lab.]]: (cite: journals/corr/BeattieLTWWKLGV16/Beattie/2016) A 3D environment based on Quake, where the inputs are RGB images, velocity and reward and the action space is movement in three directions + look direction. [[papers/rl/grounded_language/environments/3d/deepmind_lab.md|Notes]]
 - [[pdfs/rl/grounded_language/environments/3d/gll_simulated_3d_world.pdf|Grounded Language Learning in a Simulated 3D World.]]: (cite: journals/corr/HermannHGWFSSCJ17/Hermann/2017) Presents an agent that learns to interpret language in a simulated 3D environment and is rewarded for correctly executing instructions. The agent "learns to relate linguistic symbols to emergent perceptual representations of its physical surroundings and pertinent sequences of actions". The agent's comprehension extends beyond prior experience enabling it to apply "familiar language to unfamiliar situations". The environment is DeepMind Lab. The authors find that language learning is contingent on a combination of reinforcement and unsupervised learning. The authors find that semantic knowledge acquired generalizes zero-shot to "new situations and new language." Also, the authors find that due to the sparse reward, you really need to use some sort of unsuperivsed auxiliary objective to model the dynamics, otherwise you will not learn anything . The paper finds that word learning is much faster if some other words outside the current training set are already known, because the model has learned to ground words with objects in general.  The paper also studied a colour-shape composition experiment and found good performance on unseen compositions of objects. [[papers/rl/grounded_language/environments/3d/gll_simulated_3d_world.md|Notes]]
 - [[pdfs/rl/grounded_language/environments/3d/grounded_lang_simulated_3d_world.pdf|Grounded Language Learning in a Simulated 3D World.]]: (cite: journals/corr/HermannHGWFSSCJ17/Hermann/2017) . [[papers/rl/grounded_language/environments/3d/grounded_lang_simulated_3d_world.md|Notes]]
#### alfred
 - [[pdfs/rl/grounded_language/environments/alfred/alfred.pdf|ALFRED - A Benchmark for Interpreting Grounded Instructions for Everyday Tasks.]]: (cite: conf/cvpr/ShridharTGBHMZF20) .  A large scale vision-language navigation dataset, with 2685 combinations of tasks and 3 demonstrations per task. Tasks are annotated with natural language. In their baseline they use two auxiiliary losses, first is an internal estimate of progress towards the goal and second is predicting the number of sub-goals completed so far. . [[papers/rl/grounded_language/environments/alfred/alfred.md|Notes]]
 - [[pdfs/rl/grounded_language/environments/alfred/alfworld_aligning_text_and_embodied_environments_for_interactive_learning.pdf|ALFWorld: Aligning Text and Embodied Environments for Interactive Learning.]]: (cite: conf/iclr/ShridharYCBTH21) . Embodied TextWorld. Its a parallel environment where the agent interacts with a text world describing what is going on at the same time as interacting with a visual world. The idea is that you try to predict what the textworld prompts are going to be based on the visual obserations, and then transfer the result of solving in textworld back into the visual world . [[papers/rl/grounded_language/environments/alfred/alfworld_aligning_text_and_embodied_environments_for_interactive_learning.md|Notes]]
#### gscan
 - [[pdfs/rl/grounded_language/environments/gscan/gscan_grounded_language_benchmarks.pdf|A Benchmark for Systematic Generalization in Grounded Language Understanding.]]: (cite: conf/nips/RuisABBL20) Proposes a benchmark task for systematic generalization in grounded language understanding. Define a language grounded in states of the grid world and facilitated novel evaluations and acquiring linguistically motivated rules. The benchmark looks at many different types of systematic generalization, for example object property combinations, novel diretions, novel contextual references and novel adverbs (behaviour generalization). There's also length generalization. There is a multi-modal baseline (conv + lstm with attention) - they show poor performance on the novel object/property split. [[papers/rl/grounded_language/environments/gscan/gscan_grounded_language_benchmarks.md|Notes]]
 - [[pdfs/rl/grounded_language/environments/gscan/reascan_compositional_reasoning_in_language_grounding.pdf|ReaSCAN - Compositional Reasoning in Language Grounding.]]: (cite: conf/neurips/Wu/2021) Presents a "rectified" version of the gSCAN benchmark which ensures that compositional reasoning is actually required to solve some of the splits by ensuring that there are appropriate distractor objects . [[papers/rl/grounded_language/environments/gscan/reascan_compositional_reasoning_in_language_grounding.md|Notes]]
#### meta
 - [[pdfs/rl/grounded_language/environments/meta/meta_world_a_benchmark_and_evaluation_for_multi_task_and_meta_reinforcement_learning.pdf|Meta-World - A Benchmark and Evaluation for Multi-Task and Meta Reinforcement Learning.]]: (cite: conf/corl/YuQHJHFL19) . [[papers/rl/grounded_language/environments/meta/meta_world_a_benchmark_and_evaluation_for_multi_task_and_meta_reinforcement_learning.md|Notes]]
#### reading
 - [[pdfs/rl/grounded_language/environments/reading/rtfm_generalizing_by_reading.pdf|RTFM: Generalizing to Novel Environment Dynamics by Reading]]: . [[papers/rl/grounded_language/environments/reading/rtfm_generalizing_by_reading.md|Notes]]
 - [[pdfs/rl/grounded_language/environments/reading/silg_the_multi_domain_symbolic_interactive_language_grounding_benchmark.pdf|SILG: The Multi-domain Symbolic Interactive Language Grounding Benchmark.]]: (cite: conf/nips/ZhongHWNZ21) . [[papers/rl/grounded_language/environments/reading/silg_the_multi_domain_symbolic_interactive_language_grounding_benchmark.md|Notes]]
 - [[pdfs/rl/grounded_language/environments/reading/silg_the_multi_environment_symboplic_interactive_language_grounding_benchmark.pdf|SILG: The Multi-environment Symbolic Interactive Language Grounding Benchmark.]]: (cite: journals/corr/abs-2110-10661/Zhong/2021) . [[papers/rl/grounded_language/environments/reading/silg_the_multi_environment_symboplic_interactive_language_grounding_benchmark.md|Notes]]
#### real
 - [[pdfs/rl/grounded_language/environments/real/vision_and_language_navigation_interpreting_visually_grounded_navigation_instructions_in_real_environments.pdf|Vision-and-Language Navigation - Interpreting visually-grounded navigation instructions in real environments.]]: (cite: conf/cvpr/AndersonWTB0S0G18) Presents the R2R vision-and-language navigation task. Unique to this is that you have 70 different "visually realistic environments" where you have to navigate. The text instructions comprehensively describe what the agent needs to do but they're couched in natural language. They use student forcing to train the agent, eg, predicting from the predicted trajectory as a context and try to learn offline. They also studied generalization to "unseen environments" and noticed a drop in performance (although the training set success rate is also not great either). [[papers/rl/grounded_language/environments/real/vision_and_language_navigation_interpreting_visually_grounded_navigation_instructions_in_real_environments.md|Notes]]
#### webshop
 - [[pdfs/rl/grounded_language/environments/webshop/webshop_towards_scalable_real_world_web_interaction_with_grounded_language_agents.pdf|WebShop: Towards Scalable Real-World Web Interaction with Grounded Language Agents.]]: (cite: journals/corr/abs-2207-01206/Yao/2022) . [[papers/rl/grounded_language/environments/webshop/webshop_towards_scalable_real_world_web_interaction_with_grounded_language_agents.md|Notes]]
### exploration
 - [[pdfs/rl/grounded_language/exploration/improving_intrinsic_exploration_with_language_abstractions.pdf|Improving Intrinsic Exploration with Language Abstractions.]]: (cite: journals/corr/abs-2202-08938/Mu/2022) . [[papers/rl/grounded_language/exploration/improving_intrinsic_exploration_with_language_abstractions.md|Notes]]
### external_knowledge
 - [[pdfs/rl/grounded_language/external_knowledge/embodied_bert_a_transformer_model_for_embodied_language_guided_visual_task_completion.pdf|Embodied BERT: A Transformer Model for Embodied, Language-guided Visual Task Completion.]]: (cite: journals/corr/abs-2108-04927/Suglia/2021) . [[papers/rl/grounded_language/external_knowledge/embodied_bert_a_transformer_model_for_embodied_language_guided_visual_task_completion.md|Notes]]
 - [[pdfs/rl/grounded_language/external_knowledge/vln_bert_improving_vision_and_language_navigation_with_image_text_pairs_from_the_web.pdf|Improving Vision-and-Language Navigation with Image-Text Pairs from the Web.]]: (cite: conf/eccv/MajumdarSLAPB20) VLN-BERT approach . [[papers/rl/grounded_language/external_knowledge/vln_bert_improving_vision_and_language_navigation_with_image_text_pairs_from_the_web.md|Notes]]
 - [[pdfs/rl/grounded_language/external_knowledge/pre_trained_language_models_for_interactive_decision_making.pdf|Pre-Trained Language Models for Interactive Decision-Making.]]: (cite: journals/corr/abs-2202-01771/Li/2022) . [[papers/rl/grounded_language/external_knowledge/pre_trained_language_models_for_interactive_decision_making.md|Notes]]
### feedback
 - [[pdfs/rl/grounded_language/feedback/rmm_a_recursive_mental_model_for_dialogue_navigation.pdf|RMM: A Recursive Mental Model for Dialogue Navigation]]: . [[papers/rl/grounded_language/feedback/rmm_a_recursive_mental_model_for_dialogue_navigation.md|Notes]]
 - [[pdfs/rl/grounded_language/feedback/tackling_situated_multi_modal_task_oriented_dialogs_with_a_single_transformer_model.pdf|Tackling Situated Multi-Modal Task-Oriented Dialogs with a Single Transformer Model]]: . [[papers/rl/grounded_language/feedback/tackling_situated_multi_modal_task_oriented_dialogs_with_a_single_transformer_model.md|Notes]]
### foundation_models
 - [[pdfs/rl/grounded_language/foundation_models/latte_language_trajectory_transformer.pdf|LaTTe: Language Trajectory TransformEr.]]: (cite: journals/corr/abs-2208-02918/Bucker/2022) . [[papers/rl/grounded_language/foundation_models/latte_language_trajectory_transformer.md|Notes]]
 - [[pdfs/rl/grounded_language/foundation_models/vima_general_robot_manipulation_with_multimodal_prompts.pdf|VIMA: General Robot Manipulation with Multimodal Prompts.]]: (cite: journals/corr/abs-2210-03094/Jiang/2022) . [[papers/rl/grounded_language/foundation_models/vima_general_robot_manipulation_with_multimodal_prompts.md|Notes]]
### generalization
 - [[pdfs/rl/grounded_language/generalization/bcz_zero_shot_task_generalization_language.pdf|BC-Z - Zero-Shot Task Generalization with Robotic Imitation Learning.]]: (cite: conf/corl/JangIKKELLF21) Empircal study of a large-scale interactive imitation learning system that can solve many tasks including tasks not seen during training. A large dataset of 100 manipulation tasks is collected across many robots. At test time the robot can perform 24 unseen manipulation tasks between objects that have never previously appeared together in the same scene. [[papers/rl/grounded_language/generalization/bcz_zero_shot_task_generalization_language.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/challenges_of_acquiring_compositional_inductive_biases_via_meta_learning.pdf|Challenges of Acquiring Compositional Inductive Biases via Meta-Learning.]]: (cite: conf/aaai/MitchellFM21) Proposed various apporaches for constructing the meta-training support set. Concluded that there is high sensitivity to meta-training tasks and the procedure for selecting the support set matters a lot (namely, you need to ensure that the support set actually tells you something about the problem at hand). [[papers/rl/grounded_language/generalization/challenges_of_acquiring_compositional_inductive_biases_via_meta_learning.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/compositional_generalization_and_natural_language_variation_can_a_semantic_parsing_approach_handle_both.pdf|Compositional Generalization and Natural Language Variation: Can a Semantic Parsing Approach Handle Both?]]: (cite: conf/acl/ShawCPT20) . [[papers/rl/grounded_language/generalization/compositional_generalization_and_natural_language_variation_can_a_semantic_parsing_approach_handle_both.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/compositional_generalization_in_grounded_language_learning_via_induced_model_sparsity.pdf|Compositional Generalization in Grounded Language Learning via Induced Model Sparsity.]]: (cite: conf/naacl/SpilsburyI22) . [[papers/rl/grounded_language/generalization/compositional_generalization_in_grounded_language_learning_via_induced_model_sparsity.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/compositional_networks_enable_systematic_generalization_for_grounded_language_understanding.pdf|Compositional Networks Enable Systematic Generalization for Grounded Language Understanding.]]: (cite: conf/emnlp/KuoKB21) The compositional structure of networks should reflect the domain which they address, while allowing other parameters to be learned end-to-end. Proposes a "compositional network" architecture to solve some of the tasks in gSCAN. The architecture in brief parses the language statement using a dependency parser, then allocates each word an RNN. These RNNs are used to condition attention, which are then passed up the tree to the next words. On the red squares split the model does OK, but better than the baseline. [[papers/rl/grounded_language/generalization/compositional_networks_enable_systematic_generalization_for_grounded_language_understanding.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/ella_exploration_through_learned_language_abstraction.pdf|ELLA: Exploration through Learned Language Abstraction.]]: (cite: conf/nips/MirchandaniKS21) . [[papers/rl/grounded_language/generalization/ella_exploration_through_learned_language_abstraction.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/environmental_drivers_of_systematicity_and_generalization.pdf|Environmental drivers of systematicity and generalization in a situated agent.]]: (cite: conf/iclr/HillLSCBMS20) Studied what kind of environments and training data can assist generalization to unseen tasks. Concludes that having access to many frames of richly varying multi-modal observations can improve systematic generalization. [[papers/rl/grounded_language/generalization/environmental_drivers_of_systematicity_and_generalization.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/evaluating_the_impact_of_model_scale_for_compositional_generalization_in_semantic_parsing.pdf|Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing.]]: (cite: journals/corr/abs-2205-12253/Qiu/2022) None. [[papers/rl/grounded_language/generalization/evaluating_the_impact_of_model_scale_for_compositional_generalization_in_semantic_parsing.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/generalisation_in_lifelong_reinforcement_learning_through_logical_composition.pdf|Generalisation in Lifelong Reinforcement Learning through Logical Composition.]]: (cite: conf/iclr/TasseJR22) In the context of a lifelong learning agent in [[reading/papers/rl/grounded_language/babyai/babyai]]  , this paper presents a framework to autonomously determine if it has enough information to compositionally generalize to a new task. The agent can also produce a boolean expression of its understanding of the current task (using [[a_boolean_task_algebra_for_reinforcement_learning]]). So for example, if you have 15 different objects that you can pick up, you have a bitset of $2^{15}$ different combinations of picking up that can be learned. The main idea is that you can solve any new task in the set of tasks if "we are given the correct boolean expression that informs the agent how to compose its optimal skills". [[papers/rl/grounded_language/generalization/generalisation_in_lifelong_reinforcement_learning_through_logical_composition.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/grounding_spatio_temporal_language_with_transformers.pdf|Grounding Spatio-Temporal Language with Transformers.]]: (cite: conf/nips/KarchTHMO21) . [[papers/rl/grounded_language/generalization/grounding_spatio_temporal_language_with_transformers.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/human_instruction_following_with_deep_reinforcement_learning_via_transfer_learning_from_text.pdf|Human Instruction-Following with Deep Reinforcement Learning via Transfer-Learning from Text.]]: (cite: journals/corr/abs-2005-09382/Hill/2020) Proposes to use pre-trained language models to generalize from template-instruction RL agents to agents which are able to follow instrutions from human-like text. One of the models proposed is BERT + cross-modal self-attention, where the authors state that there is an explicit pathway to bind visual experience to specific contextual word representations. In this model, you treat the channels as word-like entities and then compute attention between the flattenend channels and the word embeddings. The transformer permits interactions on the word level rather than on the sentence embedding level. [[papers/rl/grounded_language/generalization/human_instruction_following_with_deep_reinforcement_learning_via_transfer_learning_from_text.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/improving_systematic_generalization_through_modularity_and_augmentation.pdf|Improving Systematic Generalization Through Modularity and Augmentation.]]: (cite: conf/cogsci/Ruis22) . The authors propose a modular model which disentangles planning and goal identification. Does better on split H (about 75% on the test set). [[papers/rl/grounded_language/generalization/improving_systematic_generalization_through_modularity_and_augmentation.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/inducing_transformers_compositional_generalization_ability_via_auxiliary_sequence_prediction_tasks.pdf|Inducing Transformer&apos;s Compositional Generalization Ability via Auxiliary Sequence Prediction Tasks.]]: (cite: conf/emnlp/JiangB21) Introduces auxiliary sequence prediction tasks to try and disentangle repetition from the actual objects that are being repeated . [[papers/rl/grounded_language/generalization/inducing_transformers_compositional_generalization_ability_via_auxiliary_sequence_prediction_tasks.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/interactive_grounded_language_acquisition_and_generalization_in_a_2d_world.pdf|Interactive Grounded Language Acquisition and Generalization in a 2D World.]]: (cite: conf/iclr/YuZX18) Presented a method for sharing concept detection between language grounding and question answering. Examined on both the combinatorial generalization out-of-distribution case and also on learning to interpret sentences with new word combinations. Training data consists of over 1 million distinct sentences and about 3 million training examples to reach peak performance. Also achieved very good out of distribution performance, but possibly explained by the diversity of training data available. [[papers/rl/grounded_language/generalization/interactive_grounded_language_acquisition_and_generalization_in_a_2d_world.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/language_representations_for_generalization_in_reinforcement_learning.pdf|Language Representations for Generalization in Reinforcement Learning.]]: (cite: conf/acml/Nikolaj0FD21) The basic idea here is to use language actions, selecting tokens from the input to generate the output. The paper finds that "agents using language representations generalize better and could solve tasks with more entities, new entities and more complexity than seen in the training task".  [[papers/rl/grounded_language/generalization/language_representations_for_generalization_in_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/learning_models_for_following_natural_language_directions_in_unknown_environments.pdf|Learning models for following natural language directions in unknown environments.]]: (cite: conf/icra/HemachandraDHRS15) Use spatial and semantic information that a human conveys through a command to learn a distribution over the measurable and semantic properties of an extended environment. A planner reasons over the map and behaviour distributions to solve for a policy by imitating previous trajectories. Defines a probabilistic graphical model, where the world state is conditioned on the command, the behaviours are conditioned on the world state and command and the probability of a trajectory are conditioned on behaviours, world state and command. Then the planning module tries to find a plan with maximal likelihood in the data given the world model, statement and behaviour distrubiton. Natural language understanding is done using a "Hierarchical Distributed Correspondence Graph" which is a type of probabilistic graphical model used for natual language. [[papers/rl/grounded_language/generalization/learning_models_for_following_natural_language_directions_in_unknown_environments.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/care_multi_task_rl_context_representations.pdf|Multi-Task Reinforcement Learning with Context-based Representations.]]: (cite: conf/icml/Sodhani0P21) Multi-task setting where tasks are encoded as natural language. Presents the CARE model. Uses a model consisting of a mixture of encoders, where encodings are re-weighted and combined according to attention scores. [[papers/rl/grounded_language/generalization/care_multi_task_rl_context_representations.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/neural_event_semantics_for_grounded_language_understanding.pdf|Neural Event Semantics for Grounded Language Understanding.]]: (cite: journals/tacl/BuchFG21) An extension of neural module networks which relies on the idea of *conjunctivism* and attention to route events in the environment to word-conditioned classifiers. [[papers/rl/grounded_language/generalization/neural_event_semantics_for_grounded_language_understanding.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/permutation_equivariant_models_for_compositional_generalization_in_language.pdf|Permutation Equivariant Models for Compositional Generalization in Language.]]: (cite: conf/iclr/GordonLBB20) Language Compositionality is a form of group-equivariance. They propose tools for constructing equivariant seq2seq models and do experiments on SCAN. Analyze existing models under lens of equivariance and demonstrate that an equivariant architecture can get good compositional generalization. Local group operation: Permutation of the word indices. Basically you can get verb replacement, but you cannot get conjunction replacement. Eg, WALK LEFT AND RUN -> JUMP LEFT AND RUN (LTURN WALK RUN -> LTURN JUMP RUN), but not RUN LEFT AND WALK -> RUN LEFT AFTER WALK (LTURN RUN WALK -> WALK LTURN RUN). This latter form is *global equivariance*. To make an equivariant sequence-to-sequence model, they use something called *group convolutions*. Each word gets transformed into a permutation equivariant embedding. Permutation equivariant embeddings are those where replacing, eg, LEFT with RIGHT leaves the embedding unchanged. Then you have permutation equivariant RNNs and permutation equivariant attention. This model requies knowing the permutation symmetries of interest, eg, knowing that LEFT and RIGHT have symmetry. Future work suggestions include grouping by parts of speech, learning the grouping and parameterizing the symemtry group and learning operations end-to-end by group structure. . [[papers/rl/grounded_language/generalization/permutation_equivariant_models_for_compositional_generalization_in_language.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/recursive_decoding_a_situated_cognition_approach_to_compositional_generalization_in_grounded_language_understanding.pdf|Recursive Decoding - A Situated Cognition Approach to Compositional Generation in Grounded Language Understanding.]]: (cite: journals/corr/abs-2201-11766/Setzler/2022) Solves the "novel direction" and "length extrapolation" splits in gSCAN by treating it as an RL problem (eg, take an action, observe next state) as opposed to a sequence prediction task. [[papers/rl/grounded_language/generalization/recursive_decoding_a_situated_cognition_approach_to_compositional_generalization_in_grounded_language_understanding.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/systematic_generalization_on_gscan_what_is_nearly_solved_and_what_is_next.pdf|Systematic Generalization on gSCAN - What is Nearly Solved and What is Next?]]: (cite: conf/emnlp/QiuH0SS21) Use a big transformer to solve gSCAN. The big transformer solves it pretty much perfectly except for splits that contain new directions, but identifying novel objects is not really a problem. The main concern is data efficiency - you need a lot of samples to make it work. . [[papers/rl/grounded_language/generalization/systematic_generalization_on_gscan_what_is_nearly_solved_and_what_is_next.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/systematic_generalization_on_gscan_with_language_conditioned_embedding.pdf|Systematic Generalization on gSCAN with Language Conditioned Embedding.]]: (cite: conf/ijcnlp/GaoHM20) Uses a graph neural network architecture to pass messages between objects in the scene and conditions the action decoder on those. [[papers/rl/grounded_language/generalization/systematic_generalization_on_gscan_with_language_conditioned_embedding.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/think_before_you_act_a_simple_baseline_for_compositional_generalization.pdf|Think before you act - A simple baseline for compositional generalization.]]: (cite: journals/corr/abs-2009-13962/Heinze-Deml/2020) Improve on the gSCAN benchmark by proposing a simple attention based model that achieves good performance on two of the test splits. It is based on identifying the target object (thinking) and then navigating to it successfully (acting). [[papers/rl/grounded_language/generalization/think_before_you_act_a_simple_baseline_for_compositional_generalization.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/when_can_transformers_ground_and_compose_insights_from_compositional_generalization_benchmarks.pdf|When Can Transformers Ground and Compose: Insights from Compositional Generalization Benchmarks.]]: (cite: journals/corr/abs-2210-12786/Sikarwar/2022) . [[papers/rl/grounded_language/generalization/when_can_transformers_ground_and_compose_insights_from_compositional_generalization_benchmarks.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/zero_shot_task_adaptation_with_multi_task_deep_reinforcement_learning.pdf|Zero-Shot Task Generalization with Multi-Task Deep Reinforcement Learning.]]: (cite: conf/icml/OhSLK17) Examines the problem of generalization, delayed reward and long compositions of tasks / memory in the context of grounded langauge learning. Proposes two new mechansims. The first is that to do generalization, proposes enforcing "analogies" so that two task encodings, both modified to change aspect X to value Y, have the same distance from the old task to the new task. The second is a "meta-controller" to handle the "long compositions of tasks" problem. This meta-controller has a kind of memory for every sub-task that it needs to complete and a mechanism to update which is the current active subtask. [[papers/rl/grounded_language/generalization/zero_shot_task_adaptation_with_multi_task_deep_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/zero_shot_task_adaptation_using_natural_language.pdf|Zero-shot Task Adaptation using Natural Language.]]: (cite: journals/corr/abs-2106-02972/Goyal/2021) Proposes "Languaged Aided Reward and Value Adaptation". The paper originally set our to explore generalization after consuming a single video demonstration as part fo the model input, but also incorporated natural language descriptions as encoded by a sentence encoder. The model decomposes the task of predicting the goal state and predicting the reward/value of an observed state given the predicted goal state. The model architecture is simple - just a convolutional network combined with LSTM encodings of the sentence using FiLM. In the zero-shot setting the model was tuned by validating on one OOD candidate and testing on the other. Using language descriptions you can get decent OOD performance, but there is a caveat in the way that the model was tuned. [[papers/rl/grounded_language/generalization/zero_shot_task_adaptation_using_natural_language.md|Notes]]
 - [[pdfs/rl/grounded_language/generalization/hierarchical_abstraction_for_combinatorial_generalization_in_object_rearrangement.pdf|hierarchical_abstraction_for_combinatorial_generalization_in_object_rearrangement]]: . [[papers/rl/grounded_language/generalization/hierarchical_abstraction_for_combinatorial_generalization_in_object_rearrangement.md|Notes]]
### imitation
 - [[pdfs/rl/grounded_language/imitation/improving_policy_learning_via_language_dynamics_distillation.pdf|Improving Policy Learning via Language Dynamics Distillation.]]: (cite: journals/corr/abs-2210-00066/Zhong/2022) . [[papers/rl/grounded_language/imitation/improving_policy_learning_via_language_dynamics_distillation.md|Notes]]
 - [[pdfs/rl/grounded_language/imitation/language_conditional_imitation_learning.pdf|Language-Conditional Imitation Learning]]: Auto-encode input language and learn a distribution of output actions conditioned on resulting context. [[papers/rl/grounded_language/imitation/language_conditional_imitation_learning.md|Notes]]
 - [[pdfs/rl/grounded_language/imitation/language_conditioned_imitation_learning_for_robot_manipulation_tasks.pdf|Language-Conditioned Imitation Learning for Robot Manipulation Tasks.]]: (cite: conf/nips/StepputtisCPLBA20) . [[papers/rl/grounded_language/imitation/language_conditioned_imitation_learning_for_robot_manipulation_tasks.md|Notes]]
 - [[pdfs/rl/grounded_language/imitation/learning_to_interpret_natural_language_navigation_instructions_from_observations.pdf|Learning to Interpret Natural Language Navigation Instructions from Observations.]]: (cite: conf/aaai/ChenM11) An earlier work which does vision-language navigation by estimating the probability of a plan graph given the presence of an n-gram in an instruction, then re-plans to maximize the graph probability given the sentence . [[papers/rl/grounded_language/imitation/learning_to_interpret_natural_language_navigation_instructions_from_observations.md|Notes]]
 - [[pdfs/rl/grounded_language/imitation/language_guided_task_adaptation_for_imitation_learning.pdf|language_guided_task_adaptation_for_imitation_learning]]: . [[papers/rl/grounded_language/imitation/language_guided_task_adaptation_for_imitation_learning.md|Notes]]
### inverse_rl
 - [[pdfs/rl/grounded_language/inverse_rl/lc_rl_from_language_to_goals.pdf|From Language to Goals - Inverse Reinforcement Learning for Vision-Based Instruction Following.]]: (cite: conf/iclr/FuKLG19) Extend MaxEntIRL, conditions the likelihood prediction of expert trajectories on the language statement given. [[papers/rl/grounded_language/inverse_rl/lc_rl_from_language_to_goals.md|Notes]]
 - [[pdfs/rl/grounded_language/inverse_rl/inverse_rl_with_natural_language_goals.pdf|Inverse Reinforcement Learning with Natural Language Goals.]]: (cite: conf/aaai/0006S21) Builds upon AGILE by proposing a method for natural-language goal generation given a trajectory and uses these generated goals as positive examples for the discriminator. They find that such goal relabeling greatly assists in improving the generalization of the discriminator. [[papers/rl/grounded_language/inverse_rl/inverse_rl_with_natural_language_goals.md|Notes]]
### language_action_space
 - [[pdfs/rl/grounded_language/language_action_space/kg_a2c_graph_constrained_action_spaces.pdf|Graph Constrained Reinforcement Learning for Natural Language Action Spaces.]]: (cite: conf/iclr/AmmanabroluH20) Present KG-A2C: An agent that builds a knowledge graph while exploring and generates actions according to templates in this knowledge graph. [[papers/rl/grounded_language/language_action_space/kg_a2c_graph_constrained_action_spaces.md|Notes]]
 - [[pdfs/rl/grounded_language/language_action_space/calm_language_models_action_generation.pdf|Keep CALM and Explore: Language Models for Action Generation in Text-based Games.]]: (cite: conf/emnlp/YaoRHN20) . [[papers/rl/grounded_language/language_action_space/calm_language_models_action_generation.md|Notes]]
 - [[pdfs/rl/grounded_language/language_action_space/gold_text_generation_by_learning_from_demonstrations.pdf|Text Generation by Learning from Demonstrations.]]: (cite: conf/iclr/Pang021) "GOLD" generation, which learns from demonstrations by importance weighting. Upweight confident tokens and downweight unconfident ones in the reference during training. [[papers/rl/grounded_language/language_action_space/gold_text_generation_by_learning_from_demonstrations.md|Notes]]
### language_generation
 - [[pdfs/rl/grounded_language/language_generation/text_games_natural_language_actions.pdf|Deep Reinforcement Learning with a Natural Language Action Space.]]: (cite: conf/acl/HeCHGLDO16) . [[papers/rl/grounded_language/language_generation/text_games_natural_language_actions.md|Notes]]
 - [[pdfs/rl/grounded_language/language_generation/cho_vision_and_language_navigation.pdf|Generative Language-Grounded Policy in Vision-and-Language Navigation with Bayes&apos; Rule.]]: (cite: conf/iclr/KuritaC21) Proposes the use of a language-generative model to select actions in vision-anguage problems. In summary, model the probability of the language sequence given an action and divide by the marginal probability of that language statement given all actions and a hidden state. The idea is that the language is a richer learning signal than the action. [[papers/rl/grounded_language/language_generation/cho_vision_and_language_navigation.md|Notes]]
 - [[pdfs/rl/grounded_language/language_generation/reinforced_cross_modal_matching_and_ss_imitation_learning_for_vision_language_navigation.pdf|Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning for Vision-Language Navigation.]]: (cite: conf/cvpr/WangHcGSWWZ19) Proposes an end-to-end learning agent to learn vision-language navigation problems ina. variety fo datasets, including R2R. The main conttributions are the design of a cross-attentional policy (eg, conditioning the language instruciton based on the current history) and conditioning the visual observation based on the attended text instruction. There is also a "critic" which tries to estimate the probability of reconstructing the language statement from the path. [[papers/rl/grounded_language/language_generation/reinforced_cross_modal_matching_and_ss_imitation_learning_for_vision_language_navigation.md|Notes]]
### logical
 - [[pdfs/rl/grounded_language/logical/interactive_symbol_grounding_with_complex_referential_expressions.pdf|Interactive Symbol Grounding with Complex Referential Expressions.]]: (cite: conf/naacl/RubaviciusL22) . [[papers/rl/grounded_language/logical/interactive_symbol_grounding_with_complex_referential_expressions.md|Notes]]
### mapping
 - [[pdfs/rl/grounded_language/mapping/chasing_ghosts_instruction_following_as_bayesian_state_tracking.pdf|Chasing Ghosts: Instruction Following as Bayesian State Tracking.]]: (cite: conf/nips/AndersonSPBL19) . [[papers/rl/grounded_language/mapping/chasing_ghosts_instruction_following_as_bayesian_state_tracking.md|Notes]]
 - [[pdfs/rl/grounded_language/mapping/learning_to_navigate_unseen_environments_back_translation_with_environmental_dropout.pdf|Learning to Navigate Unseen Environments: Back Translation with Environmental Dropout.]]: (cite: conf/naacl/TanYB19) . [[papers/rl/grounded_language/mapping/learning_to_navigate_unseen_environments_back_translation_with_environmental_dropout.md|Notes]]
 - [[pdfs/rl/grounded_language/mapping/look_wide_and_interpret_twice_improving_performance_on_intearctive_instruction_following_tasks.pdf|Look Wide and Interpret Twice: Improving Performance on Interactive Instruction-following Tasks.]]: (cite: conf/ijcai/NguyenSO21) . [[papers/rl/grounded_language/mapping/look_wide_and_interpret_twice_improving_performance_on_intearctive_instruction_following_tasks.md|Notes]]
 - [[pdfs/rl/grounded_language/mapping/tactical_rewind_self-correction_via_backtracking_in_vision_and_language_navigation.pdf|Tactical Rewind: Self-Correction via Backtracking in Vision-and-Language Navigation.]]: (cite: journals/corr/abs-1903-02547/Ke/2019) . [[papers/rl/grounded_language/mapping/tactical_rewind_self-correction_via_backtracking_in_vision_and_language_navigation.md|Notes]]
### meta
 - [[pdfs/rl/grounded_language/meta/grounded_language_learning_fast_slow.pdf|Grounded Language Learning Fast and Slow.]]: (cite: conf/iclr/HillTGWMC21) Uses a re-writable memory to enable fast one-shot generalization to new objects. [[papers/rl/grounded_language/meta/grounded_language_learning_fast_slow.md|Notes]]
### planning
 - [[pdfs/rl/grounded_language/planning/a_framework_for_learning_to_request_rich_and_contextually_useful_information_from_humans.pdf|A Framework for Learning to Request Rich and Contextually Useful Information from Humans.]]: (cite: conf/icml/NguyenBD22) . [[papers/rl/grounded_language/planning/a_framework_for_learning_to_request_rich_and_contextually_useful_information_from_humans.md|Notes]]
 - [[pdfs/rl/grounded_language/planning/episodic_transformer_for_vision_and_language_navigation.pdf|Episodic Transformer for Vision-and-Language Navigation.]]: (cite: conf/iccv/PashevichS021) . [[papers/rl/grounded_language/planning/episodic_transformer_for_vision_and_language_navigation.md|Notes]]
 - [[pdfs/rl/grounded_language/planning/film_following_instructions_in_language_with_modular_methods.pdf|FILM: Following Instructions in Language with Modular Methods.]]: (cite: journals/corr/abs-2110-07342/Min/2021) . [[papers/rl/grounded_language/planning/film_following_instructions_in_language_with_modular_methods.md|Notes]]
 - [[pdfs/rl/grounded_language/planning/few_shot_subgoal_planning_with_language_models.pdf|Few-shot Subgoal Planning with Language Models.]]: (cite: conf/naacl/LogeswaranFLL22) Uses a pre-trained language model to propose subgoals for a query instruction, then executes each of those subgoals. It extends on previous work by first using a meta-learning approach (eg, where you have a few queries and subgoals in a meta-learning context window) with a mutual information objective (eg, $p(\text{subgoal}|\text{query})$ and $p(\text{query}|\text{subgoal})$, then also proposes a learnable ranking model to rank different kinds of subgoals based on a beam search, trained with a small amount of RL . [[papers/rl/grounded_language/planning/few_shot_subgoal_planning_with_language_models.md|Notes]]
 - [[pdfs/rl/grounded_language/planning/lad_language_augmented_diffusion_for_reinforcement_learning.pdf|LAD: Language Augmented Diffusion for Reinforcement Learning.]]: (cite: journals/corr/abs-2210-15629/Zhang/2022) . [[papers/rl/grounded_language/planning/lad_language_augmented_diffusion_for_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/grounded_language/planning/lisa_learning_interpretable_skill_abstractions_from_language (1).pdf|LISA: Learning Interpretable Skill Abstractions from Language.]]: (cite: journals/corr/abs-2203-00054/Garg/2022) . [[papers/rl/grounded_language/planning/lisa_learning_interpretable_skill_abstractions_from_language (1).md|Notes]]
 - [[pdfs/rl/grounded_language/planning/learning_invariable_semantical_representation_for_extensible_policy_generalization.pdf|Learning Invariable Semantical Representation from Language for Extensible Policy Generalization.]]: (cite: journals/corr/abs-2202-00466/Li/2022) . [[papers/rl/grounded_language/planning/learning_invariable_semantical_representation_for_extensible_policy_generalization.md|Notes]]
 - [[pdfs/rl/grounded_language/planning/self_monitoring_navigation_agent_via_auxiliary_progress_estimation.pdf|Self-Monitoring Navigation Agent via Auxiliary Progress Estimation.]]: (cite: conf/iclr/MaLWAKSX19) . [[papers/rl/grounded_language/planning/self_monitoring_navigation_agent_via_auxiliary_progress_estimation.md|Notes]]
 - [[pdfs/rl/grounded_language/planning/decision_making_as_language_generation.pdf|decision_making_as_language_generation]]: . [[papers/rl/grounded_language/planning/decision_making_as_language_generation.md|Notes]]
 - [[pdfs/rl/grounded_language/planning/hierarchical_agents_by_combining_language_generation_and_semantic_goal_directed_rl.pdf|hierarchical_agents_by_combining_language_generation_and_semantic_goal_directed_rl]]: . [[papers/rl/grounded_language/planning/hierarchical_agents_by_combining_language_generation_and_semantic_goal_directed_rl.md|Notes]]
 - [[pdfs/rl/grounded_language/planning/human_level_play_in_the_game_of_diplomacy_by_combining_language_models_with_strategic_reasoning.pdf|human_level_play_in_the_game_of_diplomacy_by_combining_language_models_with_strategic_reasoning]]: . [[papers/rl/grounded_language/planning/human_level_play_in_the_game_of_diplomacy_by_combining_language_models_with_strategic_reasoning.md|Notes]]
 - [[pdfs/rl/grounded_language/planning/language_models_are_zero_shot_reasoners_extracting_actional_knowledge_for_embodied_agents.pdf|language_models_are_zero_shot_reasoners_extracting_actional_knowledge_for_embodied_agents]]: . [[papers/rl/grounded_language/planning/language_models_are_zero_shot_reasoners_extracting_actional_knowledge_for_embodied_agents.md|Notes]]
 - [[pdfs/rl/grounded_language/planning/large_language_models_still_cant_plan_a_benchmark_for_llms_on_planning_and_reasoning_about_change.pdf|large_language_models_still_cant_plan_a_benchmark_for_llms_on_planning_and_reasoning_about_change]]: . [[papers/rl/grounded_language/planning/large_language_models_still_cant_plan_a_benchmark_for_llms_on_planning_and_reasoning_about_change.md|Notes]]
 - [[pdfs/rl/grounded_language/planning/lmpriors_pretrained_language_models_as_task_specific_priors.pdf|lmpriors_pretrained_language_models_as_task_specific_priors]]: . [[papers/rl/grounded_language/planning/lmpriors_pretrained_language_models_as_task_specific_priors.md|Notes]]
 - [[pdfs/rl/grounded_language/planning/planning_with_large_language_models_via_corrective_reprompting.pdf|planning_with_large_language_models_via_corrective_reprompting]]: . [[papers/rl/grounded_language/planning/planning_with_large_language_models_via_corrective_reprompting.md|Notes]]
 - [[pdfs/rl/grounded_language/planning/tackling_alfword_with_action_attention_and_common_sense_from_pretrained_lms.pdf|tackling_alfword_with_action_attention_and_common_sense_from_pretrained_lms]]: . [[papers/rl/grounded_language/planning/tackling_alfword_with_action_attention_and_common_sense_from_pretrained_lms.md|Notes]]
### robotics
 - [[pdfs/rl/grounded_language/robotics/a_persistent_spatial_semantic_representation_for_high_level_natural_language_instruction_execution.pdf|A Persistent Spatial Semantic Representation for High-level Natural Language Instruction Execution.]]: (cite: conf/corl/BlukisPFGA21) . [[papers/rl/grounded_language/robotics/a_persistent_spatial_semantic_representation_for_high_level_natural_language_instruction_execution.md|Notes]]
 - [[pdfs/rl/grounded_language/robotics/do_as_i_can_not_as_i_say_grounding_language_in_robotic_affordances.pdf|Do As I Can, Not As I Say - Grounding Language in Robotic Affordances.]]: (cite: journals/corr/abs-2204-01691/Ahn/2022) The SayCan paper. Train a robot for different kinds of "skills" using behaviour cloning, then define an "affordance function" $p(c_{\pi}|s, l_{\pi})$ which is the probability of successfully completing the skill given the state. You can then have $p(l_{\pi}|i)$ (the language model), which gives language-conditioned skills and select task descriptions based on what is likely to work. [[papers/rl/grounded_language/robotics/do_as_i_can_not_as_i_say_grounding_language_in_robotic_affordances.md|Notes]]
 - [[pdfs/rl/grounded_language/robotics/inner_monologue_embodied_reasoning_through_planning_with_language_models.pdf|Inner Monologue: Embodied Reasoning through Planning with Language Models.]]: (cite: journals/corr/abs-2207-05608/Huang/2022) . [[papers/rl/grounded_language/robotics/inner_monologue_embodied_reasoning_through_planning_with_language_models.md|Notes]]
 - [[pdfs/rl/grounded_language/robotics/lila_language_informed_latent_actions.pdf|LILA: Language-Informed Latent Actions.]]: (cite: conf/corl/KaramchetiSLS21) . [[papers/rl/grounded_language/robotics/lila_language_informed_latent_actions.md|Notes]]
 - [[pdfs/rl/grounded_language/robotics/lm_nav_robotic_navigation_with_large_pre_trained_models_of_language_vision_and_action.pdf|LM-Nav: Robotic Navigation with Large Pre-Trained Models of Language, Vision, and Action.]]: (cite: journals/corr/abs-2207-04429/Shah/2022) . [[papers/rl/grounded_language/robotics/lm_nav_robotic_navigation_with_large_pre_trained_models_of_language_vision_and_action.md|Notes]]
 - [[pdfs/rl/grounded_language/robotics/what_matters_in_language_conditioned_robotic_imitation_learning.pdf|What Matters in Language Conditioned Robotic Imitation Learning.]]: (cite: journals/corr/abs-2204-06252/Mees/2022) . [[papers/rl/grounded_language/robotics/what_matters_in_language_conditioned_robotic_imitation_learning.md|Notes]]
### skills
 - [[pdfs/rl/grounded_language/skills/lisa_learning_interpretable_skill_abstractions_from_language.pdf|LISA - Learning Interpretable Skill Abstractions from Language.]]: (cite: journals/corr/abs-2203-00054/Garg/2022) . [[papers/rl/grounded_language/skills/lisa_learning_interpretable_skill_abstractions_from_language.md|Notes]]
### vin
 - [[pdfs/rl/grounded_language/vin/grounded_language_learning_for_transfer_in_deep_reinfrocement_learning.pdf|Grounded Language Learning for Transfer in Deep Reinforcement Learning]]: (cite: journals/jair/NarasimhanBJ18) Explores the utilization of natural language to drive transfer in Reinforcement Learning. The model architecture that they propose comprises of both an initial feature encoding module (bag-of-words + LSTM encoder for a sentence concatenated on each cell) and a VIN which is used to compute the Q function. The paper explored transfer from one game to another and found that using such a model formulation can result in higher asymptotic reward in the transfer setting. [[papers/rl/grounded_language/vin/grounded_language_learning_for_transfer_in_deep_reinfrocement_learning.md|Notes]]
 - [[pdfs/rl/grounded_language/vin/grounding_language_for_transfer_in_deep_reinforcement_learning.pdf|Grounding Language for Transfer in Deep Reinforcement Learning.]]: (cite: journals/jair/NarasimhanBJ18) . [[papers/rl/grounded_language/vin/grounding_language_for_transfer_in_deep_reinforcement_learning.md|Notes]]
## hrl
 - [[pdfs/rl/hrl/attaining_interpretability_hierarchical_primitive_composition.pdf|Attaining Interpretability in Reinforcement Learning via Hierarchical Primitive Composition.]]: (cite: journals/corr/abs-2110-01833/Lee/2021) . [[papers/rl/hrl/attaining_interpretability_hierarchical_primitive_composition.md|Notes]]
 - [[pdfs/rl/hrl/sutton_hrl.pdf|Between MDPs and Semi-MDPs: A Framework for Temporal Abstraction in Reinforcement Learning.]]: (cite: journals/ai/SuttonPS99) The original paper on Hierarchical Reinforcement Learning . [[papers/rl/hrl/sutton_hrl.md|Notes]]
 - [[pdfs/rl/hrl/maxq.pdf|Hierarchical Reinforcement Learning with the MAXQ Value Function Decomposition.]]: (cite: journals/jair/Dietterich00) . [[papers/rl/hrl/maxq.md|Notes]]
 - [[pdfs/rl/hrl/precup_efficiency_bounds_hrl.pdf|On Efficiency in Hierarchical Reinforcement Learning.]]: (cite: conf/nips/WenPIBRS20) . [[papers/rl/hrl/precup_efficiency_bounds_hrl.md|Notes]]
 - [[pdfs/rl/hrl/the_promise_of_hrl_survey.pdf|The Promise of Hierarchical Reinforcement Learning]]: Survey paper . [[papers/rl/hrl/the_promise_of_hrl_survey.md|Notes]]
### goal_discovery
 - [[pdfs/rl/hrl/goal_discovery/adjacency_constrained_subgoals.pdf|Generating Adjacency-Constrained Subgoals in Hierarchical Reinforcement Learning.]]: (cite: conf/nips/ZhangG0H020) . [[papers/rl/hrl/goal_discovery/adjacency_constrained_subgoals.md|Notes]]
 - [[pdfs/rl/hrl/goal_discovery/selfplay_goal_embeddings.pdf|Learning Goal Embeddings via Self-Play for Hierarchical Reinforcement Learning.]]: (cite: journals/corr/abs-1811-09083/Sukhbaatar/2018) . [[papers/rl/hrl/goal_discovery/selfplay_goal_embeddings.md|Notes]]
### graphs
 - [[pdfs/rl/hrl/graphs/world_graphs_hrl.pdf|Learning World Graphs to Accelerate Hierarchical Reinforcement Learning.]]: (cite: journals/corr/abs-1907-00664/Shang/2019) . [[papers/rl/hrl/graphs/world_graphs_hrl.md|Notes]]
### hindsight
 - [[pdfs/rl/hrl/hindsight/hiro_data_efficient_hrl.pdf|Data-Efficient Hierarchical Reinforcement Learning.]]: (cite: conf/nips/NachumGLL18) The HIRO agent, which does off-policy correlation for higher-level training . [[papers/rl/hrl/hindsight/hiro_data_efficient_hrl.md|Notes]]
 - [[pdfs/rl/hrl/hindsight/ho2_hindsight_off_policy.pdf|Data-efficient Hindsight Off-policy Option Learning.]]: (cite: conf/icml/WulfmeierRHLAHN21) HO2, Hindsight Off-policy options. [[papers/rl/hrl/hindsight/ho2_hindsight_off_policy.md|Notes]]
 - [[pdfs/rl/hrl/hindsight/goal_directed_planning_via_hindsight_experience_replay.pdf|Goal-Directed Planning via Hindsight Experience Replay.]]: (cite: conf/iclr/MoroLPR22) Extend AlphaZero with HER. This is an off-policy RL algorithm, but AlphaZero isn't an off-policy algorithm (eg, it requires the state-distribution to be generated by the current policy rather than a different one). The solution to this (without importance sampling) is to sample k-subgoals at the end of each episode by sampling from actual visited states . [[papers/rl/hrl/hindsight/goal_directed_planning_via_hindsight_experience_replay.md|Notes]]
 - [[pdfs/rl/hrl/hindsight/hide_functionally_decomposed_hierarchy.pdf|Learning Functionally Decomposed Hierarchies for Continuous Control Tasks With Path Planning.]]: (cite: journals/ral/ChristenJAH21) Functional decomposition of components. Planning and reward modelling are separate concerns. HiDE also proposes to use MVProp for planning. Reaching a sub-goal and planning sub-goals are done by different components of the system. [[papers/rl/hrl/hindsight/hide_functionally_decomposed_hierarchy.md|Notes]]
 - [[pdfs/rl/hrl/hindsight/hac_hierarchical_actor_critic.pdf|Learning Multi-Level Hierarchies with Hindsight.]]: (cite: conf/iclr/LevyKPS19) The "Hindsight Actor Critic" (HAC) architecture. [[papers/rl/hrl/hindsight/hac_hierarchical_actor_critic.md|Notes]]
 - [[pdfs/rl/hrl/hindsight/representation_learning_hrl.pdf|Near-Optimal Representation Learning for Hierarchical Reinforcement Learning.]]: (cite: conf/iclr/NachumGLL19) Develops the notion of what a "sub-optimal" representation of a goal state is, defined in terms of an expected reward of the optimal hiearchical policy using that representation. Suboptimality defined as $\sup_{s \ in S} V^{\pi^*}(s) - V^{\pi^*_{\text{hier}}}(s)$, eg the worst case value function drop when using the optimal hierarchical policy compared to a normal optimal policy. This implies that you should set $k$-step goals such that a $k$-step goal reaching policy's state distribution energy function parameterized by the distance t othe goal is the *close to* the next-state distribution for the optimal policy. The low-level policy's reward is basically then the distance to the predicted goal plus the log-probability of its next-state transition. The experiments show that in an ant-navigation environment, the proposed method learns to represent the state as something close to x,y coordinates and predict the goals in terms of those x-y coordinates  [[papers/rl/hrl/hindsight/representation_learning_hrl.md|Notes]]
 - [[pdfs/rl/hrl/hindsight/revisiting_experience_replay_non_stationary_environments.pdf|Revisiting Experience Replay in Non-Stationary Environments]]: Recency corretion in minibatch sampling can mitigate negative impact from nonstationary data in experience replay . [[papers/rl/hrl/hindsight/revisiting_experience_replay_non_stationary_environments.md|Notes]]
### imitation
 - [[pdfs/rl/hrl/imitation/jing_adversarial_option_aware_hierarchical_imitation_learning.pdf|Adversarial Option-Aware Hierarchical Imitation Learning.]]: (cite: conf/icml/JingH0MKGL21) . [[papers/rl/hrl/imitation/jing_adversarial_option_aware_hierarchical_imitation_learning.md|Notes]]
 - [[pdfs/rl/hrl/imitation/compile_compositional_imitation_learning_and_execution.pdf|CompILE: Compositional Imitation Learning and Execution.]]: (cite: conf/icml/KipfLDZSGKB19) . [[papers/rl/hrl/imitation/compile_compositional_imitation_learning_and_execution.md|Notes]]
 - [[pdfs/rl/hrl/imitation/discovering_motor_programs_by_recomposing_demonstrations.pdf|Discovering Motor Programs by Recomposing Demonstrations.]]: (cite: conf/iclr/ShankarTP020) . [[papers/rl/hrl/imitation/discovering_motor_programs_by_recomposing_demonstrations.md|Notes]]
 - [[pdfs/rl/hrl/imitation/hierarchical_task_models_demonstration.pdf|Learning Hierarchical Task Models by Demonstration]]: . [[papers/rl/hrl/imitation/hierarchical_task_models_demonstration.md|Notes]]
 - [[pdfs/rl/hrl/imitation/learning_robot_skills_via_temporal_variational_inference.pdf|Learning Robot Skills with Temporal Variational Inference.]]: (cite: conf/icml/Shankar020) . [[papers/rl/hrl/imitation/learning_robot_skills_via_temporal_variational_inference.md|Notes]]
### options
 - [[pdfs/rl/hrl/options/precup_attention_option_critic.pdf|Attention Option-Critic.]]: (cite: journals/corr/abs-2201-02628/Chunduru/2022) . [[papers/rl/hrl/options/precup_attention_option_critic.md|Notes]]
 - [[pdfs/rl/hrl/options/precup_option_keyboard.pdf|The Option Keyboard: Combining Skills in Reinforcement Learning.]]: (cite: conf/nips/BarretoBHCAHTHM19) . [[papers/rl/hrl/options/precup_option_keyboard.md|Notes]]
 - [[pdfs/rl/hrl/options/precup_option_critic.pdf|The Option-Critic Architecture.]]: (cite: conf/aaai/BaconHP17) . [[papers/rl/hrl/options/precup_option_critic.md|Notes]]
 - [[pdfs/rl/hrl/options/precup_termination_critic.pdf|The Termination Critic.]]: (cite: conf/aistats/HarutyunyanDBHM19) . [[papers/rl/hrl/options/precup_termination_critic.md|Notes]]
 - [[pdfs/rl/hrl/options/precup_options_deliberation_cost.pdf|When Waiting Is Not an Option: Learning Options With a Deliberation Cost.]]: (cite: conf/aaai/HarbBKP18) . [[papers/rl/hrl/options/precup_options_deliberation_cost.md|Notes]]
### probabilistic
 - [[pdfs/rl/hrl/probabilistic/stochastic_skills.pdf|Stochastic Neural Networks for Hierarchical Reinforcement Learning.]]: (cite: conf/iclr/FlorensaDA17) . [[papers/rl/hrl/probabilistic/stochastic_skills.md|Notes]]
### representations
 - [[pdfs/rl/hrl/representations/kyrki_data_efficient_visuomotor_policy_training_using_reinforcement_learning_and_generative_models.pdf|Data-efficient visuomotor policy training using reinforcement learning and generative models.]]: (cite: journals/corr/abs-2007-13134/Ghadirzadeh/2020) . [[papers/rl/hrl/representations/kyrki_data_efficient_visuomotor_policy_training_using_reinforcement_learning_and_generative_models.md|Notes]]
 - [[pdfs/rl/hrl/representations/language_as_abstraction_hrl.pdf|Language as an Abstraction for Hierarchical Deep Reinforcement Learning.]]: (cite: conf/nips/JiangGMF19) Proposes to use language as the abstraction for hierarchical reinforcement learning, since it provides unique compositional structure and could enable fast learning and combinatorial generalization. Learns an instruction-following low-level policy and a high-level policy that can re-use linguistic abstractions across tasks. Uses hindsight along with a re-labelling engine to re-label end-states with the correct goal so as to enable hindsight learning of the low-level policy. Similar to HER in that instead of re-labelling states as goals, you re-label them with the appropriate language. The high level policy produces language statements, the low-level policy consumes those language statements in order to determine its actions. This approach was tested in an environment where the tasks are more abstract, for example, objects should be sorted by size (so the high level policy creates instructions which tell the low-level policy how the objects should be re-ordered). The paper also studied compositional generalization, for example, in the training set "red" appears only in the first half of the instruction and in the test set "red" appears only in the second half.  The paper also propses to learn a "disentanged representaiton of language" using an InfoGAN and vector quantization. [[papers/rl/hrl/representations/language_as_abstraction_hrl.md|Notes]]
 - [[pdfs/rl/hrl/representations/structured_hierarchical_grammar.pdf|Reinforcement Learning with Structured Hierarchical Grammar Representations of Actions.]]: (cite: journals/corr/abs-1910-02876/Christodoulou/2019) . [[papers/rl/hrl/representations/structured_hierarchical_grammar.md|Notes]]
 - [[pdfs/rl/hrl/representations/sectar_hrl_trajectory_autoencoder.pdf|Self-Consistent Trajectory Autoencoder - Hierarchical Reinforcement Learning with Trajectory Embeddings.]]: (cite: conf/icml/Co-ReyesLGEAL18) . [[papers/rl/hrl/representations/sectar_hrl_trajectory_autoencoder.md|Notes]]
 - [[pdfs/rl/hrl/representations/skill_induction_planning_with_latent_language.pdf|Skill Induction and Planning with Latent Language.]]: (cite: conf/acl/Sharma0A22) . [[papers/rl/hrl/representations/skill_induction_planning_with_latent_language.md|Notes]]
 - [[pdfs/rl/hrl/representations/towards_mental_time_travel_a_hierarchical_memory_for_reinforcement_learning_agents.pdf|Towards mental time travel: a hierarchical memory for reinforcement learning agents.]]: (cite: conf/nips/LampinenCBH21) . [[papers/rl/hrl/representations/towards_mental_time_travel_a_hierarchical_memory_for_reinforcement_learning_agents.md|Notes]]
 - [[pdfs/rl/hrl/representations/discrete_factorial_representations_as_an_abstraction_for_goal_conditioned_rl.pdf|discrete_factorial_representations_as_an_abstraction_for_goal_conditioned_rl]]: . [[papers/rl/hrl/representations/discrete_factorial_representations_as_an_abstraction_for_goal_conditioned_rl.md|Notes]]
### search
 - [[pdfs/rl/hrl/search/subgoal_search_complex_reasoning.pdf|Subgoal Search For Complex Reasoning Tasks.]]: (cite: conf/nips/CzechowskiOZZOW21) . [[papers/rl/hrl/search/subgoal_search_complex_reasoning.md|Notes]]
### skills
 - [[pdfs/rl/hrl/skills/spirl_accelerated_rl_learned_skill_priors.pdf|Accelerated Reinforcement Learning with Learned Skill Priors]]: The SPIRL method, figure out which skills are promising to explore . [[papers/rl/hrl/skills/spirl_accelerated_rl_learned_skill_priors.md|Notes]]
 - [[pdfs/rl/hrl/skills/combining_modular_skills_in_multitask_learning.pdf|Combining Modular Skills in Multitask Learning.]]: (cite: journals/corr/abs-2202-13914/Ponti/2022) . [[papers/rl/hrl/skills/combining_modular_skills_in_multitask_learning.md|Notes]]
 - [[pdfs/rl/hrl/skills/from_skills_to_symbols_learning_symbolic_representation_for_abstract_high_level_planning.pdf|From Skills to Symbols: Learning Symbolic Representations for Abstract High-Level Planning.]]: (cite: journals/jair/KonidarisKL18) . [[papers/rl/hrl/skills/from_skills_to_symbols_learning_symbolic_representation_for_abstract_high_level_planning.md|Notes]]
 - [[pdfs/rl/hrl/skills/hierarchically_intrinsically_motivated_agent_planning_behaviour_with_dreaming_in_grid_world_environments.pdf|Hierarchical intrinsically motivated agent planning behavior with dreaming in grid environments.]]: (cite: journals/braininf/DzhivelikianLKP22) . [[papers/rl/hrl/skills/hierarchically_intrinsically_motivated_agent_planning_behaviour_with_dreaming_in_grid_world_environments.md|Notes]]
 - [[pdfs/rl/hrl/skills/latent_skill_planning_for_exploration_and_transfer.pdf|Latent Skill Planning for Exploration and Transfer.]]: (cite: conf/iclr/XieBHGS21) . [[papers/rl/hrl/skills/latent_skill_planning_for_exploration_and_transfer.md|Notes]]
 - [[pdfs/rl/hrl/skills/skill_behaviour_diversification.pdf|Learning to Coordinate Manipulation Skills via Skill Behavior Diversification.]]: (cite: conf/iclr/LeeYL20) . [[papers/rl/hrl/skills/skill_behaviour_diversification.md|Notes]]
 - [[pdfs/rl/hrl/skills/learning_to_coordinate_skills.pdf|Learning to Coordinate Manipulation Skills via Skill Behavior Diversification.]]: (cite: conf/iclr/LeeYL20) . [[papers/rl/hrl/skills/learning_to_coordinate_skills.md|Notes]]
 - [[pdfs/rl/hrl/skills/deep_skill_chaining_option_discovery.pdf|Option Discovery using Deep Skill Chaining.]]: (cite: conf/iclr/BagariaK20) . [[papers/rl/hrl/skills/deep_skill_chaining_option_discovery.md|Notes]]
 - [[pdfs/rl/hrl/skills/bagaria_deep_skill_graphs.pdf|Skill Discovery for Exploration and Planning using Deep Skill Graphs.]]: (cite: conf/icml/BagariaS021) . [[papers/rl/hrl/skills/bagaria_deep_skill_graphs.md|Notes]]
 - [[pdfs/rl/hrl/skills/stochastic_skill_learning_hrl.pdf|Stochastic Neural Networsk for Hierarchical Reinforcement Learning]]: . [[papers/rl/hrl/skills/stochastic_skill_learning_hrl.md|Notes]]
 - [[pdfs/rl/hrl/skills/hippo_sub_policy_adaptation_hrl.pdf|Sub-policy Adaptation for Hierarchical Reinforcement Learning.]]: (cite: conf/iclr/LiFCA20) The HiPPO approach, random time commitment for higher level skills. [[papers/rl/hrl/skills/hippo_sub_policy_adaptation_hrl.md|Notes]]
### top_down
 - [[pdfs/rl/hrl/top_down/feudal_networks.pdf|FeUdal Networks for Hierarchical Reinforcement Learning.]]: (cite: conf/icml/VezhnevetsOSHJS17) . [[papers/rl/hrl/top_down/feudal_networks.md|Notes]]
 - [[pdfs/rl/hrl/top_down/latent_space_hrl.pdf|Latent Space Policies for Hierarchical Reinforcement Learning.]]: (cite: conf/icml/HaarnojaHAL18) . [[papers/rl/hrl/top_down/latent_space_hrl.md|Notes]]
 - [[pdfs/rl/hrl/top_down/representation_learning_for_acting_and_planning_a_top_down_approach.pdf|Representaiton Learning for Acting and Planning: A top-down approach]]: Tutorial at ICAPS 2022 on top-down representation learning and systematic generalization . [[papers/rl/hrl/top_down/representation_learning_for_acting_and_planning_a_top_down_approach.md|Notes]]
### unsupervised
 - [[pdfs/rl/hrl/unsupervised/director_deep_hierarchical_planning_from_pixels.pdf|Deep Hierarchical Planning from Pixels.]]: (cite: journals/corr/abs-2206-04114/Hafner/2022) Extends [[dreamerv2]] with a hierarchical policy. There is a goal autoencoder which uses vector quantization to represent subgoals. These subgoals come from end-states within an 8-step replay buffer. The idea is to condition the worker policy on the *decoded*g goals (eg, not the discrete codes themselves. There is then a reward function that measures the similarity between the current state $s_t$ and the current goal $g$, for which they use cosine similarity. The nice thing about this approach is that you can use it entirely with pixels and train end-to-end with a sparse reward, there's no need for any sort of hindsight goal relabelling. [[papers/rl/hrl/unsupervised/director_deep_hierarchical_planning_from_pixels.md|Notes]]
## imitation
 - [[pdfs/rl/imitation/bc_td3_a_minimalist_approach_to_offline_reinforcement_learning.pdf|A Minimalist Approach to Offline Reinforcement Learning.]]: (cite: conf/nips/FujimotoG21) BC-TD3 algorithm. Build on TD3, adding a behavior cloning regularization term to the standard policy update step, and normalize the features of every state in the provided dataset . [[papers/rl/imitation/bc_td3_a_minimalist_approach_to_offline_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/imitation/adverarial_imitation_learning.pdf|Adversarial Soft Advantage Fitting - Imitation Learning without Policy Optimization.]]: (cite: conf/nips/BardeRJPPN20) Proposes to remove policy optimization from the adversarial imitation learning process by instead leveraging a novel discriminator formulation. The discriminator directly learns the optimal generator policy and therefore solves the generator's optimization problem "for free". This removes the reinforcement learning phase alltogether.  Effectively the optimal discriminator parameter is the "expert distribution" which in this case is the policy that we would have used RL To solve for. This policy matches the expert's trajectory distribution. Adversarial Soft Advantage Fitting alternates between two steps - first trinaing the discriminator by minimizing hte binary cross entropy loss between the discriminator's output on trajectories that came from the generator and trajectories that came from the expert, then updating the generator to maximize the discriminator loss. [[papers/rl/imitation/adverarial_imitation_learning.md|Notes]]
 - [[pdfs/rl/imitation/critic_regularized_regression.pdf|Critic Regularized Regression.]]: (cite: conf/nips/0001NZMSRSSGHF20) Offline reinforcement learning method to try and deal with overly-optimistic Q-estimates and inappropriate extrapolation beyond the observed data. CRR reduces offline policy optimization to a form of value-filtered regression which requires minimal algorithmic changes to standard actor-critic method. The main gist is that where trajectories are sub-optimal, only update the policy from the data where the Q-estimate indicates that the action taken in the data is better than the action that would have been taken by the policy. This means that you do not use the computed advantages when training the policy at all - just optimize the log-likelihood of actions which have a better Q-estimate than what the current policy would have chosen . [[papers/rl/imitation/critic_regularized_regression.md|Notes]]
 - [[pdfs/rl/imitation/deep_imitative_models_for_flexible_inference_planning_and_control.pdf|Deep Imitative Models for Flexible Inference, Planning, and Control.]]: (cite: conf/iclr/RhinehartML20) . [[papers/rl/imitation/deep_imitative_models_for_flexible_inference_planning_and_control.md|Notes]]
## inverse_rl
 - [[pdfs/rl/inverse_rl/a_connection_between_generative_adversarial_networks_inverse_reinfrocement_learning_and_energy_based_models.pdf|A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy-Based Models.]]: (cite: journals/corr/FinnCAL16/Finn/2016) . [[papers/rl/inverse_rl/a_connection_between_generative_adversarial_networks_inverse_reinfrocement_learning_and_energy_based_models.md|Notes]]
 - [[pdfs/rl/inverse_rl/guided_cost_learning.pdf|Guided Cost Learning - Deep Inverse Optimal Control via Policy Optimization.]]: (cite: conf/icml/FinnLA16) Extends the MaxEnt method by addressing two challenges, the need for informative features and effective regularization and the difficulty of learning the cost function under unknown dynamics. To address the first problem, learn arbitrary nonlinear cost functions with a neural network. To deal with the second problem, formulate a sample-based approximation for MaxEnt. In Guided Cost Learning, you match the maximum entropy cost distribution (where the cost is the energy function) by optimizing a trajectory distribution with respect to the current cost using RL. Use the samples to both improve the policy and estimate the partition function. This basically requires both offline data and also a few online trajectories where you don't know the reward function but you optimize the online policy according to what your current estimate of the cost function is. . [[papers/rl/inverse_rl/guided_cost_learning.md|Notes]]
## learning_algorithms
 - [[pdfs/rl/learning_algorithms/ddpg.pdf|Continuous control with deep reinforcement learning.]]: (cite: journals/corr/LillicrapHPHETS15/Lillicrap/2016) . [[papers/rl/learning_algorithms/ddpg.md|Notes]]
 - [[pdfs/rl/learning_algorithms/equivalence_policy_gradient_soft_q_learning.pdf|Equivalence Between Policy Gradients and Soft Q-Learning.]]: (cite: journals/corr/SchulmanAC17/Schulman/2017) . [[papers/rl/learning_algorithms/equivalence_policy_gradient_soft_q_learning.md|Notes]]
 - [[pdfs/rl/learning_algorithms/gae_generalized_advantage_estimation.pdf|High-Dimensional Continuous Control Using Generalized Advantage Estimation.]]: (cite: journals/corr/SchulmanMLJA15/Schulman/2016) . [[papers/rl/learning_algorithms/gae_generalized_advantage_estimation.md|Notes]]
 - [[pdfs/rl/learning_algorithms/phasic_policy_gradient.pdf|Phasic Policy Gradient.]]: (cite: conf/icml/CobbeHKS21) . [[papers/rl/learning_algorithms/phasic_policy_gradient.md|Notes]]
 - [[pdfs/rl/learning_algorithms/ppo.pdf|Proximal Policy Optimization Algorithms.]]: (cite: journals/corr/SchulmanWDRK17/Schulman/2017) . [[papers/rl/learning_algorithms/ppo.md|Notes]]
 - [[pdfs/rl/learning_algorithms/soft_actor_critic.pdf|Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor.]]: (cite: conf/icml/HaarnojaZAL18) . [[papers/rl/learning_algorithms/soft_actor_critic.md|Notes]]
 - [[pdfs/rl/learning_algorithms/bear_stabilizing_off_policy_q_learning_via_bootstrapping_error_reduction.pdf|Stabilizing Off-Policy Q-Learning via Bootstrapping Error Reduction.]]: (cite: conf/nips/KumarFSTL19) The BEAR method (bootstrapping error accumulation reduction). Bootstrapping error is the key source of instability in current methods for Q-learning when learning off-policy. . [[papers/rl/learning_algorithms/bear_stabilizing_off_policy_q_learning_via_bootstrapping_error_reduction.md|Notes]]
 - [[pdfs/rl/learning_algorithms/action_dependent_baselines.pdf|The Mirage of Action-Dependent Baselines in Reinforcement Learning.]]: (cite: conf/iclr/TuckerBGTGL18) . [[papers/rl/learning_algorithms/action_dependent_baselines.md|Notes]]
## mdp
 - [[pdfs/rl/mdp/partially_observable_stochastic_games.pdf|A Sufficient Statistic for Influence in Structured Multiagent Environments.]]: (cite: journals/jair/OliehoekWK21) . [[papers/rl/mdp/partially_observable_stochastic_games.md|Notes]]
 - [[pdfs/rl/mdp/plannable_approximations_to_mdp_homomorphisms_equivariance_under_actions.pdf|Plannable Approximations to MDP Homomorphisms: Equivariance under Actions.]]: (cite: conf/atal/PolKOW20) . [[papers/rl/mdp/plannable_approximations_to_mdp_homomorphisms_equivariance_under_actions.md|Notes]]
## memory
 - [[pdfs/rl/memory/memory_augmented_control.pdf|Memory Augmented Control Networks.]]: (cite: conf/iclr/KhanZAK0L18) . [[papers/rl/memory/memory_augmented_control.md|Notes]]
 - [[pdfs/rl/memory/working_memory_graphs.pdf|Working Memory Graphs.]]: (cite: conf/icml/LoyndFcSH20) Talks about the importance of "factored observations". But in general, proposes an architecture that looks like an RNN but with different memory banks updated on a schedule and self-attention between them . [[papers/rl/memory/working_memory_graphs.md|Notes]]
 - [[pdfs/rl/memory/toward_semantic_history_compression_for_reinforcement_learning.pdf|toward_semantic_history_compression_for_reinforcement_learning]]: . [[papers/rl/memory/toward_semantic_history_compression_for_reinforcement_learning.md|Notes]]
## meta
 - [[pdfs/rl/meta/a_simple_neural_attentive_meta_learner.pdf|A Simple Neural Attentive Meta-Learner.]]: (cite: conf/iclr/MishraR0A18) Introduces the SNAIL architecture. Temporal convolutions (WaveNet) + attention for meta-learning. [[papers/rl/meta/a_simple_neural_attentive_meta_learner.md|Notes]]
 - [[pdfs/rl/meta/bootstrapped_meta_learning.pdf|Bootstrapped Meta-Learning.]]: (cite: journals/corr/abs-2109-04504/Flennerhag/2021) . [[papers/rl/meta/bootstrapped_meta_learning.md|Notes]]
 - [[pdfs/rl/meta/comps_continual_meta_policy_search.pdf|CoMPS: Continual Meta Policy Search.]]: (cite: journals/corr/abs-2112-04467/Berseth/2021) . [[papers/rl/meta/comps_continual_meta_policy_search.md|Notes]]
 - [[pdfs/rl/meta/contextual_transformer_for_offline_meta_reinforcement_learning.pdf|Contextual Transformer for Offline Meta Reinforcement Learning.]]: (cite: journals/corr/abs-2211-08016/Lin/2022) . [[papers/rl/meta/contextual_transformer_for_offline_meta_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/meta/distributionally_adaptive_meta_reinforcement_learning.pdf|Distributionally Adaptive Meta Reinforcement Learning.]]: (cite: journals/corr/abs-2210-03104/Ajay/2022) . [[papers/rl/meta/distributionally_adaptive_meta_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/meta/enhanced_meta_reinforcement_learning_using_demonstrations_in_sparse_reward_environments.pdf|Enhanced Meta Reinforcement Learning using Demonstrations in Sparse Reward Environments.]]: (cite: journals/corr/abs-2209-13048/Rengarajan/2022) . [[papers/rl/meta/enhanced_meta_reinforcement_learning_using_demonstrations_in_sparse_reward_environments.md|Notes]]
 - [[pdfs/rl/meta/fast_and_slow_learning_of_recurrent_independent_mechanisms.pdf|Fast and Slow Learning of Recurrent Independent Mechanisms.]]: (cite: journals/corr/abs-2105-08710/Madan/2021) An extension of [[rim]] to the meta-learning setting. The main idea is that on each timestep, only a subset of modules is activated, and they communicate sparsely with each other. The core contribution is in the meta-training setup. The RIMs update on every step, whereas the communication attention updates every few steps after accumulating gradients for a while. On the results side, it is shown that the modules end up learning different things and that you can get better sample efficiency (for example, 100k frames to learn GoToLocal as opposed to 400k). [[papers/rl/meta/fast_and_slow_learning_of_recurrent_independent_mechanisms.md|Notes]]
 - [[pdfs/rl/meta/meta_imitation_learning_by_watching_video_demonstrations.pdf|Meta-Imitation Learning by Watching Video Demonstrations.]]: (cite: conf/iclr/LiLCCW22) . [[papers/rl/meta/meta_imitation_learning_by_watching_video_demonstrations.md|Notes]]
 - [[pdfs/rl/meta/on_the_effectiveness_of_fine_tuning_versus_meta_reinforcement_learning.pdf|On the Effectiveness of Fine-tuning Versus Meta-reinforcement Learning.]]: (cite: journals/corr/abs-2206-03271/Zhao/2022) . [[papers/rl/meta/on_the_effectiveness_of_fine_tuning_versus_meta_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/meta/rl2_fast_reinforcement_learning_via_slow_reinforcement_learning.pdf|RL$2$ - Fast Reinforcement Learning via Slow Reinforcement Learning.]]: (cite: journals/corr/DuanSCBSA16/Duan/2016) . [[papers/rl/meta/rl2_fast_reinforcement_learning_via_slow_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/meta/transformers_are_meta_reinforcement_learners.pdf|Transformers are Meta-Reinforcement Learners.]]: (cite: conf/icml/Melo22) None. [[papers/rl/meta/transformers_are_meta_reinforcement_learners.md|Notes]]
### retrieval
 - [[pdfs/rl/meta/retrieval/large_scale_retrieval_for_reinforcement_learning.pdf|Large-Scale Retrieval for Reinforcement Learning.]]: (cite: journals/corr/abs-2206-05314/Humphreys/2022) . [[papers/rl/meta/retrieval/large_scale_retrieval_for_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/meta/retrieval/retrieval_augmented_reinforcement_learning.pdf|Retrieval-Augmented Reinforcement Learning.]]: (cite: conf/icml/GoyalFBWKBGMHKV22) . [[papers/rl/meta/retrieval/retrieval_augmented_reinforcement_learning.md|Notes]]
## methodology
 - [[pdfs/rl/methodology/accounting_for_neglected_dimensions_of_ai_progress.pdf|Accounting for the Neglected Dimensions of AI Progress.]]: (cite: journals/corr/abs-1806-00610/Martinez-Plumed/2018) None. [[papers/rl/methodology/accounting_for_neglected_dimensions_of_ai_progress.md|Notes]]
## multiagent
 - [[pdfs/rl/multiagent/a_learning_agent_that_acquires_social_norms_from_public_sanctions_in_decentralized_multi_agent_settings.pdf|A learning agent that acquires social norms from public actions in decentrlalized multi-agent settings]]: . [[papers/rl/multiagent/a_learning_agent_that_acquires_social_norms_from_public_sanctions_in_decentralized_multi_agent_settings.md|Notes]]
 - [[pdfs/rl/multiagent/compositionality_and_capacity_in_emergent_languages.pdf|Compositionality and Capacity in Emergent Languages.]]: (cite: conf/rep4nlp/GuptaRFDC20) . [[papers/rl/multiagent/compositionality_and_capacity_in_emergent_languages.md|Notes]]
 - [[pdfs/rl/multiagent/disentangling_categorization_in_multi_agent_emergent_communication.pdf|Disentangling Categorization in Multi-agent Emergent Communication.]]: (cite: conf/naacl/GarciaCB22) . [[papers/rl/multiagent/disentangling_categorization_in_multi_agent_emergent_communication.md|Notes]]
 - [[pdfs/rl/multiagent/disentangling_the_role_of_categorization_in_multi_agent_emergent_communication_presentation.pdf|Disentangling the Role of Categorization in Multi-agent emergent communication]]: . [[papers/rl/multiagent/disentangling_the_role_of_categorization_in_multi_agent_emergent_communication_presentation.md|Notes]]
 - [[pdfs/rl/multiagent/learning_to_communicate_dial_rial.pdf|Learning to Communicate with Deep Multi-Agent Reinforcement Learning.]]: (cite: conf/nips/FoersterAFW16) . [[papers/rl/multiagent/learning_to_communicate_dial_rial.md|Notes]]
 - [[pdfs/rl/multiagent/maddpg.pdf|Multi-Agent Actor-Critic for Mixed Cooperative-Competitive Environments.]]: (cite: conf/nips/LoweWTHAM17) . [[papers/rl/multiagent/maddpg.md|Notes]]
## multitask
 - [[pdfs/rl/multitask/multi_objective_distributional.pdf|A Distributional View on Multi-Objective Policy Optimization.]]: (cite: journals/corr/abs-2005-07513/Abdolmaleki/2020) . [[papers/rl/multitask/multi_objective_distributional.md|Notes]]
 - [[pdfs/rl/multitask/distributional_view_on_multi_objective_policy_optimization.pdf|A distributional view on multi-objective policy optimization.]]: (cite: conf/icml/AbdolmalekiHNS20) . [[papers/rl/multitask/distributional_view_on_multi_objective_policy_optimization.md|Notes]]
 - [[pdfs/rl/multitask/learning_to_achieve_goals.ps|Learning to Achieve Goals.]]: (cite: conf/ijcai/Kaelbling93) . [[papers/rl/multitask/learning_to_achieve_goals.md|Notes]]
 - [[pdfs/rl/multitask/multitask_policy_sketches.pdf|Modular Multitask Reinforcement Learning with Policy Sketches.]]: (cite: conf/icml/AndreasKL17) . [[papers/rl/multitask/multitask_policy_sketches.md|Notes]]
 - [[pdfs/rl/multitask/mtan_end_to_end_multi_task_learning_with_attention.pdf|Multi-Task Learning With Attention for End-to-End Autonomous Driving.]]: (cite: conf/cvpr/IshiharaKMH21) Task specific channel attention - shared backbone with different channel attention networks per task, which perform a form of feature selection like FiLM (MTAN). [[papers/rl/multitask/mtan_end_to_end_multi_task_learning_with_attention.md|Notes]]
 - [[pdfs/rl/multitask/softmodule_multi_task_rl_with_soft_modularization.pdf|Multi-Task Reinforcement Learning with Soft Modularization.]]: (cite: conf/nips/YangXWW20) Avoid gradient conflicts by using different modules for different tasks and then learning to route inputs between them (SoftModule). [[papers/rl/multitask/softmodule_multi_task_rl_with_soft_modularization.md|Notes]]
 - [[pdfs/rl/multitask/planning_with_goal_conditioned_policies.pdf|Planning with Goal-Conditioned Policies.]]: (cite: conf/nips/NasirianyPLL19) . [[papers/rl/multitask/planning_with_goal_conditioned_policies.md|Notes]]
## offline
 - [[pdfs/rl/offline/finn_connection_between_gan_and_inverse_rl_energy_based_models.pdf|A Connection between Generative Adversarial Networks, Inverse Reinforcement Learning, and Energy-Based Models.]]: (cite: journals/corr/FinnCAL16/Finn/2016) Demonstrates that there is an equivalence between certain inverse reinforcement learning methods and generative modelling, particularly, sample-based maximum entropy inverse reinforcement learning and GANs. The paper shows that the "optimal discriminator" for a generator with density $q(t)$ to discriminate from a real data distribution $p(t)$ is $\frac{p(t)}{p(t) + q(t)}$. The paper shows further that the discriminator output for maximum entropy inverse reinforcement learning takes on a similar form. [[papers/rl/offline/finn_connection_between_gan_and_inverse_rl_energy_based_models.md|Notes]]
 - [[pdfs/rl/offline/workflow_offline_model_free_robotic_rl.pdf|A Workflow for Offline Model-Free Robotic Reinforcement Learning.]]: (cite: conf/corl/KumarSTFL21) . [[papers/rl/offline/workflow_offline_model_free_robotic_rl.md|Notes]]
 - [[pdfs/rl/offline/cog_connecting_new_skills_to_past_experience_with_offline_reinforcement_learning.pdf|COG: Connecting New Skills to Past Experience with Offline Reinforcement Learning.]]: (cite: journals/corr/abs-2010-14500/Singh/2020) . [[papers/rl/offline/cog_connecting_new_skills_to_past_experience_with_offline_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/offline/corl_research_oriented_deep_offline_reinforcement_learning_library.pdf|CORL: Research-oriented Deep Offline Reinforcement Learning Library.]]: (cite: journals/corr/abs-2210-07105/Tarasov/2022) . [[papers/rl/offline/corl_research_oriented_deep_offline_reinforcement_learning_library.md|Notes]]
 - [[pdfs/rl/offline/conservative_q_learning_offline_rl.pdf|Conservative Q-Learning for Offline Reinforcement Learning.]]: (cite: conf/nips/KumarZTL20) Tries to tackle the problem of Q-function over-estimation for unseen actions when learning offline (since there are rarely any "failed" examples). Limits the learning of the Q function such that the expected value of a policy under the Q function is a lower bound on its true value. This can be used as a regularizer. In essence, what it does is that it tries to minimize the Q function values under a hypothetical policy that tries to exploit the Q function in order to get a maximal Q value. [[papers/rl/offline/conservative_q_learning_offline_rl.md|Notes]]
 - [[pdfs/rl/offline/deep_transformer_q_networks_for_partially_observable_reinforcement_learning.pdf|Deep Transformer Q-Networks for Partially Observable Reinforcement Learning.]]: (cite: journals/corr/abs-2206-01078/Esslinger/2022) . [[papers/rl/offline/deep_transformer_q_networks_for_partially_observable_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/offline/deepaveragers_offline_rl_by_solving_derived_nonparametric_mdps.pdf|DeepAveragers: Offline Reinforcement Learning by Solving Derived Non-Parametric MDPs.]]: (cite: journals/corr/abs-2010-08891/Shrestha/2020) . [[papers/rl/offline/deepaveragers_offline_rl_by_solving_derived_nonparametric_mdps.md|Notes]]
 - [[pdfs/rl/offline/valuedice_discriminator_actor_critic_offline_imitation_learning.pdf|Discriminator-Actor-Critic - Addressing Sample Inefficiency and Reward Bias in Adversarial Imitation Learning.]]: (cite: conf/iclr/KostrikovADLT19) Tries to address the implicit bias present in the reward functions in the adversarial imitation learning framework as well as the number of interactions required with the requirement in order to properly learn to imitate the expert's policy. Proposes a new algorithm called "Discriminator Actor-Critic" that uses off-policy RL to reduce policy-environment interaction sample complexity. To address the sample inefficiency problem, sample transitions from a replay buffer while performing off-polciy training for the generator. In order to recover the originak on-policy expectation, use importance sampling when evaluating the discriminator on the replay buffer  . [[papers/rl/offline/valuedice_discriminator_actor_critic_offline_imitation_learning.md|Notes]]
 - [[pdfs/rl/offline/effective_offline_rl_needs_going_beyond_pessimism_representations_and_distributional_shift.pdf|Effective Offline RL Needs Going Beyond Pessimism: Representations and Distributional Shift]]: . [[papers/rl/offline/effective_offline_rl_needs_going_beyond_pessimism_representations_and_distributional_shift.md|Notes]]
 - [[pdfs/rl/offline/gail_generative_adversarial_imitation_learning.pdf|Generative Adversarial Imitation Learning.]]: (cite: conf/nips/HoE16) Train a generative distribution for state-visitation that approximates the data distribution. The discriminator must classify if the state-action pairs come from the agent or expert and the generator's job is to fool the discriminator similar to GAN. [[papers/rl/offline/gail_generative_adversarial_imitation_learning.md|Notes]]
 - [[pdfs/rl/offline/imitating_past_successes_can_be_very_suboptimal.pdf|Imitating Past Successes can be Very Suboptimal.]]: (cite: journals/corr/abs-2206-03378/Eysenbach/2022) . [[papers/rl/offline/imitating_past_successes_can_be_very_suboptimal.md|Notes]]
 - [[pdfs/rl/offline/robust_rewards_with_adversarial_inverse_rl.pdf|Learning Robust Rewards with Adversarial Inverse Reinforcement Learning.]]: (cite: journals/corr/abs-1710-11248/Fu/2017) Propose AIRL, a practical and scaleable inverse reinforcement learning algorithm based on an adversarial reward learning formulation. AIRL is capable of recovering reward functions robust to changes in dynamics. Compared to GAIL, GAIL doesn't attempt to recover a reward function, it just attempts to recover a discriminator for trajectories and therefore the policy for the expert via the generator. This work builds on GAIL by using a discriminator that corresponds to an odds-ratio between the policy and exponentiated reward distribution. In the single state and action case you have $D_{\theta}(s, a) = \frac{\exp{f_{\theta}(s, a)}}{\exp{f_{\theta}(s, a)} + \pi(a|s)}$ and at optimality, $f$ equasl the log-policy.  The problem is reward ambiguiuty. The paper goes on to formulate what a "disentangled reward function" is (eg, one where the optimal policy is the same no matter what the dynamics).  To remove unwanted reward shaping with arbitrary reward function classes, the learned reward can only depend on $s$.  The paper proposes to instead limit $f$ to be a composition of $g$ and $h$, where $h$ is the reward shaping term. [[papers/rl/offline/robust_rewards_with_adversarial_inverse_rl.md|Notes]]
 - [[pdfs/rl/offline/gscl_learning_to_reach_goals_via_iterated_supervised_learning.pdf|Learning to Reach Goals via Iterated Supervised Learning.]]: (cite: conf/iclr/Ghosh0RFDEL21) Study RL algorithms that use imitation learning to acquire goal-reaching policies from scratch without the need for expert demonstrations or a value function. Leverage the idea that any trajectory is a successful demonstration of reaching its final state. Propose a simple algorithm where the agent continually relabels and imitates trajectories that it generates to progressively learn new goal-reaching behaviours from scratch. Essentially, collect policy rollouts, relabel the goals, then do behavioural cloning on those relabelled trajectories. There is no need to maintain an estimate of the value function. Authors then tested this method in a goal-conditioned setup. Starting from scratch, GSCL can beat TD3-HER - the inputs to the policy are the goal and the states and at the end of each episode you either relabel the trajectory and give a reward of zero, or give a reward of 1 and don't relabel. When comparing with PPO, there is no goal-relabelling, so instead a surrogate $\epsilon$-ball indicator reward function is given and the hindsight methods can still beat this. [[papers/rl/offline/gscl_learning_to_reach_goals_via_iterated_supervised_learning.md|Notes]]
 - [[pdfs/rl/offline/maxent_inverse_rl.pdf|Maximum Entropy Offline Reinforcement Learning]]: (cite: conf/aaai/Ziebart08) Compute backward and forward messages. This produces the reward that best explains the behaviour. It utilizes the notion of suboptimality. If you see the expert continuously doing one thing then that is likely to be the thing that has high rewards. Called maximum entropy because it maximizes the entropy of the policy. In essence, you don't want to be any more committed to a particular path except as required to explain some behaviour. Under this model, plans with equivalent rewards have equal probabilities, and plans with higher rewards are exponentially more preferred. [[papers/rl/offline/maxent_inverse_rl.md|Notes]]
 - [[pdfs/rl/offline/mutual_information_regularized_offline_reinforcement_learning.pdf|Mutual Information Regularized Offline Reinforcement Learning.]]: (cite: journals/corr/abs-2210-07484/Ma/2022) . [[papers/rl/offline/mutual_information_regularized_offline_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/offline/offline_rl_policies_should_be_trained_to_be_adaptive.pdf|Offline RL Policies Should be Trained to be Adaptive.]]: (cite: journals/corr/abs-2207-02200/Ghosh/2022) . [[papers/rl/offline/offline_rl_policies_should_be_trained_to_be_adaptive.md|Notes]]
 - [[pdfs/rl/offline/onestep_offline_rl_without_off_policy_evaluation.pdf|Offline RL Without Off-Policy Evaluation.]]: (cite: conf/nips/BrandfonbrenerW21) One-step baseline . [[papers/rl/offline/onestep_offline_rl_without_off_policy_evaluation.md|Notes]]
 - [[pdfs/rl/offline/offline_reinforcement_learning_tutorial_levine.pdf|Offline Reinforcement Learning - Tutorial, Review, and Perspectives on Open Problems.]]: (cite: journals/corr/abs-2005-01643/Levine/2020) Discusses some applications of offline reinforcement learning, which includes "learning goal-directed dialogue policies", since collecting trials requires interacting with a live human, which could be very expensive. Summarized what makes offline reinforcement learning difficult, namely that you cannot explore the environment, so one assumption that you have to amke is that the dataset covers high-reward transitions. But another challenge is that learning a policy that does something different from the observed dataset is difficult because its out of distribution. There are theoretical bounds on the error that come from Behavioural Cloning and DAgger, which are basically that we get an error bound that is at best quadratic in the time horizon H in the offline case, but linear in H in the online case. Also notes that in the offline case, MBRL can suffer from poor performance as a result of distribution shift.  [[papers/rl/offline/offline_reinforcement_learning_tutorial_levine.md|Notes]]
 - [[pdfs/rl/offline/lompo-offline-rl-images-latent-space.pdf|Offline Reinforcement Learning from Images with Latent Space Models.]]: (cite: conf/l4dc/RafailovYRF21) . [[papers/rl/offline/lompo-offline-rl-images-latent-space.md|Notes]]
 - [[pdfs/rl/offline/offline_reinfrocement_learning_with_implicit_q_learning.pdf|Offline Reinforcement Learning with Implicit Q-Learning.]]: (cite: conf/iclr/KostrikovNL22) . [[papers/rl/offline/offline_reinfrocement_learning_with_implicit_q_learning.md|Notes]]
 - [[pdfs/rl/offline/planning_for_sample_efficient_imitation_learning.pdf|Planning for Sample Efficient Imitation Learning.]]: (cite: journals/corr/abs-2210-09598/Yin/2022) . [[papers/rl/offline/planning_for_sample_efficient_imitation_learning.md|Notes]]
 - [[pdfs/rl/offline/reinforcement_learning_with_sparse_rewards_using_guidance_from_offline_demonstration.pdf|Reinforcement Learning with Sparse Rewards using Guidance from Offline Demonstration.]]: (cite: journals/corr/abs-2202-04628/Rengarajan/2022) . [[papers/rl/offline/reinforcement_learning_with_sparse_rewards_using_guidance_from_offline_demonstration.md|Notes]]
 - [[pdfs/rl/offline/rce_replacing_rewards_with_examples.pdf|Replacing Rewards with Examples - Example-Based Policy Search via Recursive Classification.]]: (cite: journals/corr/abs-2103-12656/Eysenbach/2021) Defining reward functions can be difficult to do in practice - can we instead use examples in order to derive a reward? This is like a form of inverse reinforcement learning, where just have a bunch of labelled goal states. Define a classifier which estimates whether we will be successful given a current state-action pair and bootstrap the trajectory probabilities. [[papers/rl/offline/rce_replacing_rewards_with_examples.md|Notes]]
 - [[pdfs/rl/offline/rvs_what_is_essential_for_offl.pdf|RvS: What is Essential for Offline RL via Supervised Learning?]]: (cite: conf/iclr/EmmonsEKL22) . [[papers/rl/offline/rvs_what_is_essential_for_offl.md|Notes]]
 - [[pdfs/rl/offline/sqil_offline_imitation_learning_via_rl_sparse_rewards.pdf|SQIL - Imitation Learning via Reinforcement Learning with Sparse Rewards.]]: (cite: conf/iclr/ReddyDL20) Provide an incentive to the agent to match the demonstrations over a long horizon by encouraging it to return to demonstrated states upon encountering new OOD states. This is called "Soft Q Imitation Learning (SQIL)". This is a regularized variant of behavioural cloning which uses a sparsity prior to encourage long-horizon imitation. The algorithm gives a reward of 1 for all samples in the dataset and reward of zero for everything sampled online. In that sense, visiting states outside of the data manifold get low Q values due to the reward of zero, but going from an unknown-state back to a known state will get a positive reward (due to adding the log-sum-exponents of the next-state, next-action pairs). There is more detail provided in equation 1 of the paper.  [[papers/rl/offline/sqil_offline_imitation_learning_via_rl_sparse_rewards.md|Notes]]
 - [[pdfs/rl/offline/should_i_run_offline_reinforcement_learning_or_behavioural_cloning.pdf|Should I run Offline Reinforcement Learning or Behavioural Cloning?]]: Offline RL works best when you have suboptimal training data and you want to distill the optimal policy, behavioural cloning is the best when all your data is optimal. However offline RL can get asymptotically close, especially conservative methods. [[papers/rl/offline/should_i_run_offline_reinforcement_learning_or_behavioural_cloning.md|Notes]]
 - [[pdfs/rl/offline/trail_near_optimal_imitation_learning_with_suboptimal_data.pdf|TRAIL: Near-Optimal Imitation Learning with Suboptimal Data.]]: (cite: journals/corr/abs-2110-14770/Yang/2021) . [[papers/rl/offline/trail_near_optimal_imitation_learning_with_suboptimal_data.md|Notes]]
 - [[pdfs/rl/offline/why_so_pessimistic_estimating_uncertainties_for_offline_rl_through_ensembles_and_why_their_independence_matters.pdf|Why So Pessimistic? Estimating Uncertainties for Offline RL through Ensembles, and Why Their Independence Matters.]]: (cite: journals/corr/abs-2205-13703/Ghasemipour/2022) . [[papers/rl/offline/why_so_pessimistic_estimating_uncertainties_for_offline_rl_through_ensembles_and_why_their_independence_matters.md|Notes]]
 - [[pdfs/rl/offline/dual_generator_for_offline_reinforcement_learning.pdf|dual_generator_for_offline_reinforcement_learning]]: . [[papers/rl/offline/dual_generator_for_offline_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/offline/guiding_offline_reinforcement_learning_using_a_safety_expert.pdf|guiding_offline_reinforcement_learning_using_a_safety_expert]]: . [[papers/rl/offline/guiding_offline_reinforcement_learning_using_a_safety_expert.md|Notes]]
 - [[pdfs/rl/offline/optimal_transport_for_offline_imitation_learning.pdf|optimal_transport_for_offline_imitation_learning]]: . [[papers/rl/offline/optimal_transport_for_offline_imitation_learning.md|Notes]]
 - [[pdfs/rl/offline/q_ensemble_for_offline_rl_dont_scale_the_ensemble_scale_the_batch_size.pdf|q_ensemble_for_offline_rl_dont_scale_the_ensemble_scale_the_batch_size]]: . [[papers/rl/offline/q_ensemble_for_offline_rl_dont_scale_the_ensemble_scale_the_batch_size.md|Notes]]
 - [[pdfs/rl/offline/return_augmentation_gives_supervised_rl_temporal_compositionality.pdf|return_augmentation_gives_supervised_rl_temporal_compositionality]]: . [[papers/rl/offline/return_augmentation_gives_supervised_rl_temporal_compositionality.md|Notes]]
 - [[pdfs/rl/offline/sparse_q_learning_offline_reinforcement_learning_with_implicit_value_regularization.pdf|sparse_q_learning_offline_reinforcement_learning_with_implicit_value_regularization]]: . [[papers/rl/offline/sparse_q_learning_offline_reinforcement_learning_with_implicit_value_regularization.md|Notes]]
 - [[pdfs/rl/offline/using_confounded_data_in_offline_rl.pdf|using_confounded_data_in_offline_rl]]: . [[papers/rl/offline/using_confounded_data_in_offline_rl.md|Notes]]
### model_based
 - [[pdfs/rl/offline/model_based/combo_conservative_offline_model_based_policy_optimization.pdf|COMBO: Conservative Offline Model-Based Policy Optimization.]]: (cite: conf/nips/YuKRRLF21) . [[papers/rl/offline/model_based/combo_conservative_offline_model_based_policy_optimization.md|Notes]]
 - [[pdfs/rl/offline/model_based/domain_generalization_for_robust_model_base_offline_reinforcement_learning.pdf|Domain Generalization for Robust Model-Based Offline Reinforcement Learning.]]: (cite: journals/corr/abs-2211-14827/Clark/2022) . [[papers/rl/offline/model_based/domain_generalization_for_robust_model_base_offline_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/offline/model_based/model_based_offline_meta_reinforcement_learning_with_regularization.pdf|Model-Based Offline Meta-Reinforcement Learning with Regularization.]]: (cite: journals/corr/abs-2202-02929/Lin/2022) Offline Meta-RL: Learn a meta-policy for policy-adaptation based on knowledge of task distirbution. But how to handle the exploration-exploitation tradeoff? Value over-estimation is a problem. Exploration is following the meta-policy and exploiting is staying close to the behaviour policy. MerPO: a meta-model for efficient task structure inference and safe exploration of out-of-distribution state-actions. Perform model-rollouts using learnt methods, conservative policy evaluation (COMBO style), regularize the policy imporvement using the meta-policy. Optimistically following the meta-policy in the inner loop may degrade performance. Tradeoff between staying close to the behaviour policy and following the meta-policy to explore OOD. [[papers/rl/offline/model_based/model_based_offline_meta_reinforcement_learning_with_regularization.md|Notes]]
 - [[pdfs/rl/offline/model_based/revisiting_design_choices_in_offline_model_based_reinforcement_learning.pdf|Revisiting Design Choices in Offline Model Based Reinforcement Learning.]]: (cite: conf/iclr/LuBPOR22) . [[papers/rl/offline/model_based/revisiting_design_choices_in_offline_model_based_reinforcement_learning.md|Notes]]
### transfer
 - [[pdfs/rl/offline/transfer/awac_accelerating_online_reinforcement_learning_with_offline_datasets.pdf|AWAC: Accelerating Online Reinforcement Learning with Offline Datasets]]: . [[papers/rl/offline/transfer/awac_accelerating_online_reinforcement_learning_with_offline_datasets.md|Notes]]
## planning
 - [[pdfs/rl/planning/consciousness_inspired_planning_mbrl_set_representation.pdf|A Consciousness-Inspired Planning Agent for Model-Based Reinforcement Learning.]]: (cite: journals/corr/abs-2106-02097/Zhao/2021) Combines a model-based deep reinforcement learning agent with a sparsity inducing bottleneck in its attention to the state. This forces the number of entities to which the agent attends to be small. The query is a set of inducing points and a vector for the action under consideration and the keys come from the object. Hard-attention is performed, so only the top $k$ matching values are kept. Tested on out-of-distribution environment layouts. [[papers/rl/planning/consciousness_inspired_planning_mbrl_set_representation.md|Notes]]
 - [[pdfs/rl/planning/compositional_rl_logical_specifications.pdf|Compositional Reinforcement Learning from Logical Specifications.]]: (cite: journals/corr/abs-2106-13906/Jothimurugan/2021) Study the problem of learning control policies for complex tasks given by logical specifications. This work develops a compositional learning approach called DIRL. First encode the specification into an abstract graph, then incorporate reinforcement learning to learn a policy for each edge within a Dijkstra-style planning algorithm to compute a high-level plan. In this case the high-level specifications are given by a formal language already. So to combine the two, the only learning that you need to do on the "high level" is estimate the probability that a policy for a given edge safely takes you from one node to the next. Then you can allocate the negative log probability as the "cost" for that edge, meaning that transitions that are less likely to be successful have a higher cost. The higher level planner which fuses all the policies together is just Djikstra's algorithm for finding a shortest path to complete the specification. [[papers/rl/planning/compositional_rl_logical_specifications.md|Notes]]
 - [[pdfs/rl/planning/dreamer_dream_to_control.pdf|Dream to Control - Learning Behaviors by Latent Imagination.]]: (cite: conf/iclr/HafnerLB020) . [[papers/rl/planning/dreamer_dream_to_control.md|Notes]]
 - [[pdfs/rl/planning/chane-sane_goal_conditioned_rl_imagined_subgoals.pdf|Goal-Conditioned Reinforcement Learning with Imagined Subgoals.]]: (cite: conf/icml/Chane-SaneSL21) . [[papers/rl/planning/chane-sane_goal_conditioned_rl_imagined_subgoals.md|Notes]]
 - [[pdfs/rl/planning/gnn_motion_planning.pdf|Graph Neural Networks for Motion Planning.]]: (cite: journals/corr/abs-2006-06248/Khan/2020) . [[papers/rl/planning/gnn_motion_planning.md|Notes]]
 - [[pdfs/rl/planning/grounding_complex_navigational_instructions_using_scene_graphs.pdf|Grounding Complex Navigational Instructions Using Scene Graphs.]]: (cite: journals/corr/abs-2106-01607/Jong/2021) . [[papers/rl/planning/grounding_complex_navigational_instructions_using_scene_graphs.md|Notes]]
 - [[pdfs/rl/planning/learning_what_if_explanations_for_sequential_decision_making.pdf|Learning &quot;What-if&quot; Explanations for Sequential Decision-Making.]]: (cite: conf/iclr/BicaJHS21) . [[papers/rl/planning/learning_what_if_explanations_for_sequential_decision_making.md|Notes]]
 - [[pdfs/rl/planning/planet_learning_latent_dynamics_planning_from_pixels.pdf|Learning Latent Dynamics for Planning from Pixels.]]: (cite: conf/icml/HafnerLFVHLD19) Presents the PlaNet architecture. [[papers/rl/planning/planet_learning_latent_dynamics_planning_from_pixels.md|Notes]]
 - [[pdfs/rl/planning/planning_from_pixels_latent_dynamics.pdf|Learning Latent Dynamics for Planning from Pixels.]]: (cite: conf/icml/HafnerLFVHLD19) . [[papers/rl/planning/planning_from_pixels_latent_dynamics.md|Notes]]
 - [[pdfs/rl/planning/portable_rep_high_level_planning.pdf|Learning Portable Representations for High-Level Planning.]]: (cite: conf/icml/JamesR020) . [[papers/rl/planning/portable_rep_high_level_planning.md|Notes]]
 - [[pdfs/rl/planning/oracle_planning_clash_of_clans.pdf|Learning to Play Imperfect-Information Games by Imitating an Oracle Planner.]]: (cite: journals/tciaig/BoneyIKS22) . [[papers/rl/planning/oracle_planning_clash_of_clans.md|Notes]]
 - [[pdfs/rl/planning/dreamerv2.pdf|Mastering Atari with Discrete World Models.]]: (cite: conf/iclr/HafnerL0B21) Presents the DreamerV2 architecture. [[papers/rl/planning/dreamerv2.md|Notes]]
 - [[pdfs/rl/planning/muzero.pdf|Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model.]]: (cite: journals/corr/abs-1911-08265/Schrittwieser/2019) . [[papers/rl/planning/muzero.md|Notes]]
 - [[pdfs/rl/planning/model_based_rl_for_atari.pdf|Model Based Reinforcement Learning for Atari.]]: (cite: conf/iclr/KaiserBMOCCEFKL20) Introduces the SimPLE algorithm (Simulated Policy Learning), which is a complete model-based Deep Reinforcement Learning algorithm based on video prediction models. Addresses the challenge from a 2018 survey that there "has been no clear demonstration of successful planning with a learned model in the Atari Learning Environment". In the empirical evaluation, they find that SimPLE is "significantly more sample efficient" than a highly tuned Rainbow (though Rainbow can be tuned to have better results in the low-data regime). The model works by stacking four frames + the action selected by the agent and putting that through an encoder-decoder network with skip connections, then predicting the next frame. The next part of the model is a convolutional inference network which approximates the posterior given the next frame and discretizes it into latents. The idea is then to use the latent from the four previous frames to try and predict the latent code for the posterior (eg, when you know the next frame). During training, there is a "neural network simulated environment" (a world model) [[papers/rl/planning/model_based_rl_for_atari.md|Notes]]
 - [[pdfs/rl/planning/mbold_model_based_visual_planning_with_self_supervised_functional_distances.pdf|Model-Based Visual Planning with Self-Supervised Functional Distances.]]: (cite: conf/iclr/TianNEDEFL21) MBold method which uses a dynamical distance function to determine distance-to-goal when planning . [[papers/rl/planning/mbold_model_based_visual_planning_with_self_supervised_functional_distances.md|Notes]]
 - [[pdfs/rl/planning/2020_mbrl_survey.pdf|Model-based Reinforcement Learning - A Survey.]]: (cite: journals/corr/abs-2006-16712/Moerland/2020) . [[papers/rl/planning/2020_mbrl_survey.md|Notes]]
 - [[pdfs/rl/planning/motion_planning_networks.pdf|Motion Planning Networks.]]: (cite: conf/icra/QureshiSBY19) . [[papers/rl/planning/motion_planning_networks.md|Notes]]
 - [[pdfs/rl/planning/on_the_role_of_planning_in_model_based_deep_reinforcement_learning.pdf|On the role of planning in model-based deep reinforcement learning.]]: (cite: conf/iclr/HamrickFBGVWABV21) Studie sthe performance of MuZero and performs ablations to determine what role planning plays in MBRL agents. The results suggest that planning is most useful in the learning process in order to provide a more useufl data distribution. A shallow tree for MCTS works just as well as a deep one. Planning alone isn't enough to drive generalization - planning only works as well as the value function was trained. . [[papers/rl/planning/on_the_role_of_planning_in_model_based_deep_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/planning/plan_arithmetic.pdf|Plan Arithmetic: Compositional Plan Vectors for Multi-Task Control.]]: (cite: journals/corr/abs-1910-14033/Devin/2019) . [[papers/rl/planning/plan_arithmetic.md|Notes]]
 - [[pdfs/rl/planning/plan_based_relaxed_reward_shaping_for_goal_directed_tasks.pdf|Plan-Based Relaxed Reward Shaping for Goal-Directed Tasks.]]: (cite: conf/iclr/SchubertOT21) . [[papers/rl/planning/plan_based_relaxed_reward_shaping_for_goal_directed_tasks.md|Notes]]
 - [[pdfs/rl/planning/planning_from_pixels_inv_dynamics.pdf|Planning from Pixels using Inverse Dynamics Models.]]: (cite: conf/iclr/PasterMB21) . [[papers/rl/planning/planning_from_pixels_inv_dynamics.md|Notes]]
 - [[pdfs/rl/planning/sample_efficient_cem_planning.pdf|Sample-efficient Cross-Entropy Method for Real-time Planning.]]: (cite: conf/corl/PinneriSBASRM20) . [[papers/rl/planning/sample_efficient_cem_planning.md|Notes]]
 - [[pdfs/rl/planning/visual_planning_skip_connections.pdf|Self-Supervised Visual Planning with Temporal Skip Connections.]]: (cite: conf/corl/EbertFLL17) . [[papers/rl/planning/visual_planning_skip_connections.md|Notes]]
 - [[pdfs/rl/planning/spending_thinking_time_wisely_accelerating_mcts_with_virtual_expansions.pdf|Spending Thinking Time Wisely: Accelerating MCTS with Virtual Expansions.]]: (cite: journals/corr/abs-2210-12628/Ye/2022) . [[papers/rl/planning/spending_thinking_time_wisely_accelerating_mcts_with_virtual_expansions.md|Notes]]
 - [[pdfs/rl/planning/thompson_sampling_efficiently_learns_to_control_diffusion_processes.pdf|Thompson Sampling Efficiently Learns to Control Diffusion Processes.]]: (cite: journals/corr/abs-2206-09977/Faradonbeh/2022) . [[papers/rl/planning/thompson_sampling_efficiently_learns_to_control_diffusion_processes.md|Notes]]
 - [[pdfs/rl/planning/trajectory_guided_control_prediction_for_end_to_end_autonomous_driving_a_simple_yet_strong_baseline.pdf|Trajectory-guided Control Prediction for End-to-end Autonomous Driving: A Simple yet Strong Baseline.]]: (cite: journals/corr/abs-2206-08129/Wu/2022) . [[papers/rl/planning/trajectory_guided_control_prediction_for_end_to_end_autonomous_driving_a_simple_yet_strong_baseline.md|Notes]]
 - [[pdfs/rl/planning/transformers_are_adaptable_task_planners.pdf|Transformers are Adaptable Task Planners.]]: (cite: journals/corr/abs-2207-02442/Jain/2022) . [[papers/rl/planning/transformers_are_adaptable_task_planners.md|Notes]]
 - [[pdfs/rl/planning/local_experience_global_planning.pdf|Using Local Experiences for Global Motion Planning.]]: (cite: conf/icra/ChamzasSK19) . [[papers/rl/planning/local_experience_global_planning.md|Notes]]
 - [[pdfs/rl/planning/vtnet_visual_transformer_network_for_object_goal_navigation.pdf|VTNet: Visual Transformer Network for Object Goal Navigation.]]: (cite: conf/iclr/DuY021) . [[papers/rl/planning/vtnet_visual_transformer_network_for_object_goal_navigation.md|Notes]]
 - [[pdfs/rl/planning/ozair_vector_quantized_models_for_planning.pdf|Vector Quantized Models for Planning.]]: (cite: conf/icml/OzairLRAOV21) . [[papers/rl/planning/ozair_vector_quantized_models_for_planning.md|Notes]]
 - [[pdfs/rl/planning/vector_quantized_models_for_planning.pdf|Vector Quantized Models for Planning.]]: (cite: conf/icml/OzairLRAOV21) . [[papers/rl/planning/vector_quantized_models_for_planning.md|Notes]]
 - [[pdfs/rl/planning/learning_to_prioritize_planning_updates_in_model_based_reinforcement_learning.pdf|learning_to_prioritize_planning_updates_in_model_based_reinforcement_learning]]: . [[papers/rl/planning/learning_to_prioritize_planning_updates_in_model_based_reinforcement_learning.md|Notes]]
### diffusion
 - [[pdfs/rl/planning/diffusion/is_conditional_generative_modeling_all_you_need_for_decision_making.pdf|Is Conditional Generative Modeling all you need for Decision-Making?]]: (cite: journals/corr/abs-2211-15657/Ajay/2022) . [[papers/rl/planning/diffusion/is_conditional_generative_modeling_all_you_need_for_decision_making.md|Notes]]
 - [[pdfs/rl/planning/diffusion/planning_with_diffusion_for_flexible_behavior_synthesis.pdf|Planning with Diffusion for Flexible Behavior Synthesis.]]: (cite: conf/icml/JannerDTL22) Introduces the "Diffuser" planning algorithm. The basic idea is similar to [[repaint_inpainting_using_denoising_diffusion_probabilistic_models]], eg, we treat the planning problem as an inference problem where the planning process is part of the model. Here we have a diffusion based model - we noise trajectories, then derive the appropriate backward process so that we can start out with noise and end up with trajectories. The key difference here is that the diffusion process is controllable - you add the gradients of some objective that you want your plans to meet. The authors show that you can stitch together in-distribution subsequences in order to generalize compositionally. You can also generalize to new tasks by using a guided diffusion process. This does well on eg, mazes . [[papers/rl/planning/diffusion/planning_with_diffusion_for_flexible_behavior_synthesis.md|Notes]]
### disentanglement
 - [[pdfs/rl/planning/disentanglement/composable_planning_with_attributes_disentanglement.pdf|Composable Planning with Attributes.]]: (cite: conf/icml/ZhangSLSF18) If the agent knows which properties of the environment are important, then after learning how its actions affect those properties, it may be able to use this knowledge to solve complex tasks without specifically training for them. This paper considers a setup where the environment is augmented with a set of user-defined attributes that parameterize features of interest and proposes to learn policies for transitioning between attributes and maintaining a graph of possible transitions. Effectively, the policy takes a pair of inputs, the current state and the attributes of a goal state and outputs a distribution over actions. This is similar to [[compositional_rl_logical_specifications]] in a way, since both methods also use a transition table, but in this case the attributes are provided by the neural network. [[papers/rl/planning/disentanglement/composable_planning_with_attributes_disentanglement.md|Notes]]
### generalization
 - [[pdfs/rl/planning/generalization/procedural_generalization_by_planning_self_supervised_world_models.pdf|Procedural Generalization by Planning with Self-Supervised World Models.]]: (cite: journals/corr/abs-2111-01587/Anand/2021) Investigates generalization capability of planning, and representation learning via MuZero. Results indicated that observation generalization was possible when planning decoupled from representation learning, but task generalization did not always work. [[papers/rl/planning/generalization/procedural_generalization_by_planning_self_supervised_world_models.md|Notes]]
 - [[pdfs/rl/planning/generalization/trajectory_wise_multiple_choice_learning_for_dynamics_regularization.pdf|Trajectory-wise Multiple Choice Learning for Dynamics Generalization in Reinforcement Learning.]]: (cite: conf/nips/SeoLGKSA20) . [[papers/rl/planning/generalization/trajectory_wise_multiple_choice_learning_for_dynamics_regularization.md|Notes]]
### probabilistic
 - [[pdfs/rl/planning/probabilistic/continuous_time_mbrl.pdf|Continuous-Time Model-Based Reinforcement Learning.]]: (cite: journals/corr/abs-2102-04764/Yildiz/2021) . [[papers/rl/planning/probabilistic/continuous_time_mbrl.md|Notes]]
 - [[pdfs/rl/planning/probabilistic/sample_efficient_rl_using_deep_gps.pdf|Sample-efficient reinforcement learning using deep Gaussian processes.]]: (cite: journals/corr/abs-2011-01226/Gadd/2020) . [[papers/rl/planning/probabilistic/sample_efficient_rl_using_deep_gps.md|Notes]]
### value
 - [[pdfs/rl/planning/value/chaplot_spatial_planning_transformers.pdf|Differentiable Spatial Planning using Transformers.]]: (cite: conf/icml/ChaplotPM21) Use a big pre-trained transformer to perform a similar task that VINs perform. The claim is that planning problems have statistical regularities to them - usually maps to plan on are not noise. SPT can predict multiple steps ahead in one go and deal with the case where the map is unknown and is predicted as a function of the observations . [[papers/rl/planning/value/chaplot_spatial_planning_transformers.md|Notes]]
 - [[pdfs/rl/planning/value/gvin_life_beyond_lattices.pdf|Generalized Value Iteration Networks - Life Beyond Lattices.]]: (cite: conf/aaai/NiuCGTSK18) Extends value iteration networks using a graph convolution operator, which enables planning on irregular spatial graphs. Also considers some different graph convolution kernels to deal with things like direction and distance. [[papers/rl/planning/value/gvin_life_beyond_lattices.md|Notes]]
 - [[pdfs/rl/planning/value/graph_neural_induction_of_value_iteration.pdf|Graph neural induction of value iteration.]]: (cite: journals/corr/abs-2009-12604/Deac/2020) . [[papers/rl/planning/value/graph_neural_induction_of_value_iteration.md|Notes]]
 - [[pdfs/rl/planning/value/graph_based_motion_planning_networks.pdf|Graph-Based Motion Planning Networks.]]: (cite: conf/pkdd/HoangV20) . [[papers/rl/planning/value/graph_based_motion_planning_networks.md|Notes]]
 - [[pdfs/rl/planning/value/motion_planning_transformers.pdf|Motion Planning Transformers: One Model to Plan Them All.]]: (cite: journals/corr/abs-2106-02791/Johnson/2021) . [[papers/rl/planning/value/motion_planning_transformers.md|Notes]]
 - [[pdfs/rl/planning/value/xlvin_neural_algorithmic_reasoners_are_implicit_planners.pdf|Neural Algorithmic Reasoners are Implicit Planners.]]: (cite: conf/nips/DeacVMBTN21) A conference submission of [[xlvin_executed_latent_vin]]. The basic idea is to learn a linear translation function $T(z(s), a) \approx z(s')$ which defines the neighbours of a state in latent space. Then you can unroll this an do value iteration with an "executor" network. The executor network has to be pre-trained. [[papers/rl/planning/value/xlvin_neural_algorithmic_reasoners_are_implicit_planners.md|Notes]]
 - [[pdfs/rl/planning/value/operator_splitting_value_iteration.pdf|Operator Splitting Value Iteration.]]: (cite: journals/corr/abs-2211-13937/Rakhsha/2022) . [[papers/rl/planning/value/operator_splitting_value_iteration.md|Notes]]
 - [[pdfs/rl/planning/value/predictron.pdf|The Predictron - End-To-End Learning and Planning.]]: (cite: conf/icml/SilverHHSGHDRRB17) . [[papers/rl/planning/value/predictron.md|Notes]]
 - [[pdfs/rl/planning/value/treeqn_and_atreec_differentiable_tree_structured_models_for_deep_reinforcement_learning.pdf|TreeQN and ATreeC: Differentiable Tree-Structured Models for Deep Reinforcement Learning.]]: (cite: conf/iclr/FarquharRIW18) . [[papers/rl/planning/value/treeqn_and_atreec_differentiable_tree_structured_models_for_deep_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/planning/value/universal_planning_networks.pdf|Universal Planning Networks - Learning Generalizable Representations for Visuomotor Control.]]: (cite: conf/icml/SrinivasJALF18) Addresses the challenge of learning abstract representations that are effective for specifying goals, palnning and generalization. Introduces Universal Planning Networks. Planning unrolls a forward model in latent space and infers and otimal action plan through gradient descent. . [[papers/rl/planning/value/universal_planning_networks.md|Notes]]
 - [[pdfs/rl/planning/value/universal_value_function_approximators.pdf|Universal Value Function Approximators.]]: (cite: conf/icml/SchaulHGS15) . [[papers/rl/planning/value/universal_value_function_approximators.md|Notes]]
 - [[pdfs/rl/planning/value/universal_function_value_approximators.pdf|Universal Value Function Approximators.]]: (cite: conf/icml/SchaulHGS15) . [[papers/rl/planning/value/universal_function_value_approximators.md|Notes]]
 - [[pdfs/rl/planning/value/value_iteration_on_multiple_levels_of_abstraction.pdf|Value Iteration Networks on Multiple Levels of Abstraction.]]: (cite: conf/rss/SchleichKB19) . [[papers/rl/planning/value/value_iteration_on_multiple_levels_of_abstraction.md|Notes]]
 - [[pdfs/rl/planning/value/value_iteration_networks.pdf|Value Iteration Networks.]]: (cite: conf/ijcai/TamarWTLA17) Perform differentiable value iteration via convolution and use the learned value maps to plan. [[papers/rl/planning/value/value_iteration_networks.md|Notes]]
 - [[pdfs/rl/planning/value/lutter_value_iteration_continuous_actions_states_and_time.pdf|Value Iteration in Continuous Actions, States and Time.]]: (cite: conf/icml/LutterM0FG21) Provides a method to perform value iteration when the state space is continuous. Proposes "Continuous Fitted Value Iteration". If you have a known dynamics model, then the optimal policy and value function can be derived for non-linear control affine dynamics. [[papers/rl/planning/value/lutter_value_iteration_continuous_actions_states_and_time.md|Notes]]
 - [[pdfs/rl/planning/value/value_prediction_network.pdf|Value Prediction Network.]]: (cite: conf/nips/OhSL17) . [[papers/rl/planning/value/value_prediction_network.md|Notes]]
 - [[pdfs/rl/planning/value/mvprop.pdf|Value Propagation Networks.]]: (cite: conf/iclr/NardelliSLKTU19) Extends Value Iteration Networks by using a different parameterization of the value propagation kernel at each location in the image. In essence, this means that we learn how the value propagates around the state-space, as opposed to learning a single kernel with a single value-transition function where there are areas with "negative predicted reward" to compensate . [[papers/rl/planning/value/mvprop.md|Notes]]
 - [[pdfs/rl/planning/value/xlvin_executed_latent_vin.pdf|XLVIN - eXecuted Latent Value Iteration Nets.]]: (cite: journals/corr/abs-2010-13146/Deac/2020) . See [[xlvin_neural_algorithmic_reasoners_are_implicit_planners]] . [[papers/rl/planning/value/xlvin_executed_latent_vin.md|Notes]]
## relational
 - [[pdfs/rl/relational/deep_rl_relational_inductive_biases_lillicrap_zambaldi.pdf|Deep reinforcement learning with relational inductive biases.]]: (cite: conf/iclr/ZambaldiRSBLBTR19) Encode the image into feature maps using a convolutional encoder. Treat each pixel as an "entity", then create a fully connected graph of entities which update their states via attention-weighted message passing. (Note: This seems very similar to just taking a transformer to the pixels). Then pool the updated entity embeddings and use an MLP to produce a policy. Tested on a box-world environment where an agent must unlock boxes in sequence and showed that the model generalizes the longer sequence lengths and new key-lock combinations. Seems to require several hundred million environment steps to solve. [[papers/rl/relational/deep_rl_relational_inductive_biases_lillicrap_zambaldi.md|Notes]]
## representations
 - [[pdfs/rl/representations/contrastive_explanations_for_rl_self_predictions.pdf|Contrastive Explanations for Reinforcement Learning via Embedded Self Predictions.]]: (cite: conf/iclr/LinLF21) . [[papers/rl/representations/contrastive_explanations_for_rl_self_predictions.md|Notes]]
 - [[pdfs/rl/representations/contrastive_learning_as_goal_conditioned_reinforcement_learning.pdf|Contrastive Learning as Goal-Conditioned Reinforcement Learning.]]: (cite: journals/corr/abs-2206-07568/Eysenbach/2022) . [[papers/rl/representations/contrastive_learning_as_goal_conditioned_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/representations/data_efficient_rl_self_predictive_representations.pdf|Data-Efficient Reinforcement Learning with Self-Predictive Representations.]]: (cite: conf/iclr/SchwarzerAGHCB21) Hypothesizes that an agent can learn more efficiently if we augment reward maximization with a self-supervised objective based on structure in its visual input and sequential interaction with the environment. rain the agent to predict its own latents multiple steps into the future. This "predict the future" objective outperforms prior methods for sample-efficient deep RL from pixels. [[papers/rl/representations/data_efficient_rl_self_predictive_representations.md|Notes]]
 - [[pdfs/rl/representations/stooke_decoupling_representation_learning_from_rl.pdf|Decoupling Representation Learning from Reinforcement Learning.]]: (cite: conf/icml/StookeLAL21) Proposes to decouple representation learning frm policy learning. introduces a new unsupervised learning task called Augmented Temporal Contrast, which trains a convolutional encoder to associate pairs of observatiosn separated by a short time difference under image augmentations using a contrastive loss. [[papers/rl/representations/stooke_decoupling_representation_learning_from_rl.md|Notes]]
 - [[pdfs/rl/representations/farm_feature_attending_recurrent_modules_for_generalization_in_rl.pdf|Feature-Attending Recurrent Modules for Generalization in Reinforcement Learning.]]: (cite: journals/corr/abs-2112-08369/Carvalho/2021) Hypothesizes that a single deep reinforcement learning architecture can exhibit multiple types of generalization if it can learn schema-like representations for regularly occurring structures within its experience. FARM learns perceptual schemas that are distributed across multiple smaller recurrent models. Each module performs attention over the *channels* of the observation. This is similar to [[papers/dl/rim|RIM]], except that it does feature attention instead of spatial attention. In the KeyBox task, generalization is tested in the densely-populated case and the sparsely populated case. Generalization is on the dimension of "more distractors" and "longer paths". [[papers/rl/representations/farm_feature_attending_recurrent_modules_for_generalization_in_rl.md|Notes]]
 - [[pdfs/rl/representations/improving_zero_shot_generalization_in_offline_reinforcement_learning_using_generalized_similarity_functions.pdf|Improving Zero-shot Generalization in Offline Reinforcement Learning using Generalized Similarity Functions.]]: (cite: journals/corr/abs-2111-14629/Mazoure/2021) . [[papers/rl/representations/improving_zero_shot_generalization_in_offline_reinforcement_learning_using_generalized_similarity_functions.md|Notes]]
 - [[pdfs/rl/representations/learning_from_demonstration_with_weakly_supervised_disentanglement.pdf|Learning from Demonstration with Weakly Supervised Disentanglement.]]: (cite: conf/iclr/HristovR21) Tries to solve the problem of interpretable learning from demonstrations. Treat it as an optimization problem. Finds that the latent space is already disentangled, what you need is to align it with some human-understandable labels and then rotate the latent space to align on the axes that you care about. [[papers/rl/representations/learning_from_demonstration_with_weakly_supervised_disentanglement.md|Notes]]
 - [[pdfs/rl/representations/reinforcement_learning_prototypical_representations.pdf|Reinforcement Learning with Prototypical Representations.]]: (cite: conf/icml/YaratsFLP21) . [[papers/rl/representations/reinforcement_learning_prototypical_representations.md|Notes]]
 - [[pdfs/rl/representations/representation_matters_improving_perception_and_exploration_higgins.pdf|Representation Matters - Improving Perception and Exploration for Robotics.]]: (cite: conf/icra/WulfmeierBHHGKR21) What is a "good" representation for robotics applications? Systematic evaluation of a number of commonly learnt and hand-engineered representations in the context of three robotics tasks, both as input to the agent or as a source of auxiliary tasks. The results show that dimensionality strongly matters for task generation and disentanglement can lead to better auxiliary tasks but has limited benefits as an input representation. Compares a number of promising representation learning approaches as MONET, Transporter and beta-VAE. Having all the information in the representation is what is important for learning in general, but disentanglement does allow you to have smaller representations since you can more easily prune irrelevant information . [[papers/rl/representations/representation_matters_improving_perception_and_exploration_higgins.md|Notes]]
 - [[pdfs/rl/representations/return_based_contrastive_repre.pdf|Return-Based Contrastive Representation Learning for Reinforcement Learning.]]: (cite: conf/iclr/LiuZZQZLYL21) . [[papers/rl/representations/return_based_contrastive_repre.md|Notes]]
 - [[pdfs/rl/representations/smorl_self_supervised_visual_reinforcement_learning_with_object_centric_representations.pdf|Self-supervised Visual Reinforcement Learning with Object-centric Representations.]]: (cite: conf/iclr/ZadaianchukSM21) . Extends on previous work that uses $\beta$-VAE or other representation learning to propose "goals" which then need to be be reached by an agent (self-supervised). Stuffing everything into one vector doesn't work so well when you have lots of objects. Uses SCALOR object-learning framework to learn a set representation of the scene instead, then interact with the objects one-by-one with goal proposals . [[papers/rl/representations/smorl_self_supervised_visual_reinforcement_learning_with_object_centric_representations.md|Notes]]
 - [[pdfs/rl/representations/stochastic_latent_actor_critic.pdf|Stochastic Latent Actor-Critic - Deep Reinforcement Learning with a Latent Variable Model.]]: (cite: conf/nips/LeeNAL20) Explicitly learn latent representations that can accelerate reinforcement learning from images with the "Stochastic Latent Actor-Critic" algorithm, whcih can improve sample efficiency. The basic idea is that we have a latent variable model to try and describe the observations. The policy isn't conditioned on the latent states however - only the critic is. In this sense, the critic can in theory be learned much faster because it operates on a reduced dimensionality input. The model can be viewed as avariant of Soft-Actor Critic, where the critic is trained on the stochastic latent state of the sequential latent variable model of the environment. [[papers/rl/representations/stochastic_latent_actor_critic.md|Notes]]
 - [[pdfs/rl/representations/temporal_disentanglement_of_representations_for_improved_generalisation_in_reinforcement_learning.pdf|Temporal Disentanglement of Representations for Improved Generalisation in Reinforcement Learning.]]: (cite: journals/corr/abs-2207-05480/Dunion/2022) . [[papers/rl/representations/temporal_disentanglement_of_representations_for_improved_generalisation_in_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/representations/towards_learning_abstractions_via_reinforcement_learning.pdf|Towards Learning Abstractions via Reinforcement Learning]]: . [[papers/rl/representations/towards_learning_abstractions_via_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/representations/traning_and_evaluation_of_deep_policies_using_reinforcement_learning_and_generative_models.pdf|Training and Evaluation of Deep Policies using Reinforcement Learning and Generative Models.]]: (cite: journals/corr/abs-2204-08573/Ghadirzadeh/2022) . [[papers/rl/representations/traning_and_evaluation_of_deep_policies_using_reinforcement_learning_and_generative_models.md|Notes]]
## sample_efficiency
### offline
 - [[pdfs/rl/sample_efficiency/offline/batch_value_function_approximation_with_only_realizability.pdf|Batch Value-function Approximation with Only Realizability.]]: (cite: conf/icml/XieJ21) Introduces Batch Value Function Tournament. They claim that under the assumption that all actions have some probability weight greater than $\frac{1}{C_A}$ under the dataset given every state and further that the data distribution is exploratory (eg, we have explored many transitions), denoted $C_S$. $C = C_S C_A$ .Then, they show an algorithm bounding the error to $J(\pi^*) - J(\hat \pi) \le \frac{(4 + 8 \sqrt{C}) \epsilon_{\mathcal{F}}}{(1 - \gamma)^2}$  with sample complexity $|D| = \bar {\mathcal{O}} (\frac{C^2 \ln \frac{|\mathcal{F}|}{\delta} \epsilon_{\mathcal{F}}}{\epsilon^4 (1-  \gamma)^8})$ . [[papers/rl/sample_efficiency/offline/batch_value_function_approximation_with_only_realizability.md|Notes]]
 - [[pdfs/rl/sample_efficiency/offline/what_are_the_statistical_limits_of_offline_rl_with_linear_function_approximation.pdf|What are the Statistical Limits of Offline RL with Linear Function Approximation?]]: (cite: conf/iclr/WangFK21) This work focuses on the basic question of what the necessary representational and distributional conditions are that permit provable sample-fficient offline reinforcement learning. The main result is that is that even if the true value function of every policy is learning in a given set of features and off-policy data has good coverage over all the features, then any algorithm still requires a number of offline samples that is exponential in the problem horizon in order to non-trivially estimate the value of any given policy. Realizability (the condition that a a transformation exists from the features to the value function) and Good Coverage (the feature covariance matrix has lower-bounded eigenvalues, no eigenvalues aer zero) are not sufficient to get you efficient offline RL. Sample-efficient offline policy evaluation is not psosible unless singificantly stronger conditions hold, such as having low distribution shift or stronger representational conditions.  . [[papers/rl/sample_efficiency/offline/what_are_the_statistical_limits_of_offline_rl_with_linear_function_approximation.md|Notes]]
### online
 - [[pdfs/rl/sample_efficiency/online/coberl_contrastive_bert_for_reinforcement_learning.pdf|CoBERL - Contrastive BERT for Reinforcement Learning.]]: (cite: journals/corr/abs-2107-05431/Banino/2021) . Proposes a method to bring BERT-like masked token modelling to RL sequences. In this case we don't have the tokens so we use a contrastive objective instead (eg, guess which batch a token is from, plus a bunch of KL divergences) . [[papers/rl/sample_efficiency/online/coberl_contrastive_bert_for_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/sample_efficiency/online/improving_sample_efficiency_of_value_based_models_using_attention_and_vision_transformers.pdf|Improving Sample Efficiency of Value Based Models Using Attention and Vision Transformers.]]: (cite: journals/corr/abs-2202-00710/Kalantari/2022) . [[papers/rl/sample_efficiency/online/improving_sample_efficiency_of_value_based_models_using_attention_and_vision_transformers.md|Notes]]
 - [[pdfs/rl/sample_efficiency/online/measuring_progress_in_deep_reinforcement_learning_sample_efficiency.pdf|Measuring Progress in Deep Reinforcement Learning Sample Efficiency.]]: (cite: journals/corr/abs-2102-04881/Dorner/2021) The paper is a reivew paper which investigates progress in sample efficiency on Atari games and continuous control tasks by comparing the number of samples that a variety of algorithms need to reach a given performance level according to training curves. Sample efficiency performance is improving exponentially, with a doubling time of around 10-18 months on Atari, 5-24 months on state-based continuous control and 4-9 months on pixel-based continuous control. The main contributors to improved sample efficiency in practice have been (1) improved off-policy learning, (2) MBRL, (3) auxiliary training objectives, (4) incentives for sample efficiency, eg, explicit tuning of hyperparameters, such as frequency of updates to the Q network, (5) increased compute which enables new techniques like DDQN. However, progress might be slower for offline reinforcement learning, since you can't improve things with exploration. "Further Investigation into sample efficiency for offline RL would be valuable but challenging due tot he lack of established evaluation prototocols" [[papers/rl/sample_efficiency/online/measuring_progress_in_deep_reinforcement_learning_sample_efficiency.md|Notes]]
 - [[pdfs/rl/sample_efficiency/online/pretraining_representations_for_data_efficient_reinforcement_learning.pdf|Pretraining Representations for Data-Efficient Reinforcement Learning.]]: (cite: conf/nips/SchwarzerRNACHB21) . [[papers/rl/sample_efficiency/online/pretraining_representations_for_data_efficient_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/sample_efficiency/online/rainbow_combining_improvements_in_deep_reinforcement_learning.pdf|Rainbow - Combining Improvements in Deep Reinforcement Learning.]]: (cite: conf/aaai/HesselMHSODHPAS18) Examines several independent improvements to DQN and looks at how they can be combined empirically. The extensions they examine are Double Q learning, Prioritized Replay, Duelling Networks, Multi-step learning, Distributional RL and Nosiy Nets. The things making the biggest impact were prioritized replay (sample frequently from transitions where there is something to learn, so increase sampling weight on transitions with high absolute TD error) and multi-step learning. . [[papers/rl/sample_efficiency/online/rainbow_combining_improvements_in_deep_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/sample_efficiency/online/reinforcement_learning_with_augmented_data.pdf|Reinforcement Learning with Augmented Data.]]: (cite: conf/nips/LaskinLSPAS20) Investigates the effect of different data augmentation schemes on reinforcement learning sample efficiency. The most effective are random translation and random crop. [[papers/rl/sample_efficiency/online/reinforcement_learning_with_augmented_data.md|Notes]]
 - [[pdfs/rl/sample_efficiency/online/sample_efficient_deep_reinforcement_learning_via_uncertainty_estimation.pdf|Sample Efficient Deep Reinforcement Learning via Uncertainty Estimation.]]: (cite: journals/corr/abs-2201-01666/Mai/2022) . [[papers/rl/sample_efficiency/online/sample_efficient_deep_reinforcement_learning_via_uncertainty_estimation.md|Notes]]
 - [[pdfs/rl/sample_efficiency/online/sample_efficient_reinforcement_learning_is_feasible_for_linearly_realizable_mdps_with_limited_revisiting.pdf|Sample-Efficient Reinforcement Learning Is Feasible for Linearly Realizable MDPs with Limited Revisiting.]]: (cite: conf/nips/LiCCGW21) . [[papers/rl/sample_efficiency/online/sample_efficient_reinforcement_learning_is_feasible_for_linearly_realizable_mdps_with_limited_revisiting.md|Notes]]
 - [[pdfs/rl/sample_efficiency/online/towards_sample_efficient_reinforcement_learning.pdf|Towards Sample Efficient Reinforcement Learning.]]: (cite: conf/ijcai/Yu18) Discusses different possible ways to adress the sample efficiency problem, including exploration, optimization, environment modelling, experience transfer and abstraction. In terms of environment modelling, some suggested approaches include [[value_iteration_networks]] , learning the distance to the goal, or just learning imagined model rollouts which are encoded as augmented features. [[papers/rl/sample_efficiency/online/towards_sample_efficient_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/sample_efficiency/online/when_to_use_parametric_models_in_reinforcement_learning.pdf|When to use parametric models in reinforcement learning?]]: (cite: conf/nips/HasseltHA19) Explores the link between experience replay and MBRL. Hypothesizes and confirms that under suitable conditions, replay based algorithms should be competitive to ro better than MBRL if the model's role is to generate fictitional transitions. They compare Rainbow-DQN to SimPLE by configuring the parameters such that both models look at the same number of real interactions. They also increase the number of steps in multi-step returns form 3 to 20 and reduce the number of steps before sampling from the replay buffer starts. Empirically, they find that on the 26 Atari Games trialled by SimPLE, they cn get 25% higher performance after 100,000 interactions with the environment. [[papers/rl/sample_efficiency/online/when_to_use_parametric_models_in_reinforcement_learning.md|Notes]]
#### model_based
 - [[pdfs/rl/sample_efficiency/online/model_based/do_recent_advancements_in_model_based_rl_really_improve_sample_efficiency.pdf|Do recent advancements in model-based deep reinforcement learning really improve data efficiency]]: . [[papers/rl/sample_efficiency/online/model_based/do_recent_advancements_in_model_based_rl_really_improve_sample_efficiency.md|Notes]]
 - [[pdfs/rl/sample_efficiency/online/model_based/efficientzero_mastering_atari_limited_data.pdf|Mastering Atari Games with Limited Data.]]: (cite: conf/nips/YeLKAG21) The EfficientZero paper. [[papers/rl/sample_efficiency/online/model_based/efficientzero_mastering_atari_limited_data.md|Notes]]
 - [[pdfs/rl/sample_efficiency/online/model_based/pdsketch_integrated_domain_programming_and_learning.pdf|pdsketch_integrated_domain_programming_and_learning]]: . [[papers/rl/sample_efficiency/online/model_based/pdsketch_integrated_domain_programming_and_learning.md|Notes]]
## software
 - [[pdfs/rl/software/introduction_to_the_sonar_cognitive_architecture.pdf|Introduction to the Sonar Cognitive Architecture]]: . [[papers/rl/software/introduction_to_the_sonar_cognitive_architecture.md|Notes]]
## symmetry
 - [[pdfs/rl/symmetry/block_mdps_robust_state_abstractions.pdf|Learning Robust State Abstractions for Hidden-Parameter Block MDPs.]]: (cite: conf/iclr/0001SKP21) . [[papers/rl/symmetry/block_mdps_robust_state_abstractions.md|Notes]]
 - [[pdfs/rl/symmetry/mdp_homomorphic_networks.pdf|MDP Homomorphic Networks: Group Symmetries in Reinforcement Learning.]]: (cite: conf/nips/PolWHOW20) . [[papers/rl/symmetry/mdp_homomorphic_networks.md|Notes]]
 - [[pdfs/rl/symmetry/symmetry_based_disentangled_representation_learning_interation.pdf|Symmetry-Based Disentangled Representation Learning requires Interaction with Environments.]]: (cite: conf/nips/Caselles-DupreO19) . [[papers/rl/symmetry/symmetry_based_disentangled_representation_learning_interation.md|Notes]]
## theory
 - [[pdfs/rl/theory/batch_size_invariance_for_policy_optimization.pdf|Batch size-invariance for policy optimization.]]: (cite: journals/corr/abs-2110-00641/Hilton/2021) . [[papers/rl/theory/batch_size_invariance_for_policy_optimization.md|Notes]]
 - [[pdfs/rl/theory/efficient_deep_reinforcement_learning_requires_regulating_statistical_overfitting.pdf|efficient_deep_reinforcement_learning_requires_regulating_statistical_overfitting]]: . [[papers/rl/theory/efficient_deep_reinforcement_learning_requires_regulating_statistical_overfitting.md|Notes]]
## transfer
 - [[pdfs/rl/transfer/icml_ctrlformer_slides.pdf|CtrlFormer: Learning Transferable State Representation for Visual Control via Transformer (ICML 2022 Slides)]]: . [[papers/rl/transfer/icml_ctrlformer_slides.md|Notes]]
 - [[pdfs/rl/transfer/ctrlformer_learning_transferrable_state_representation_for_visual_control_via_transformer.pdf|CtrlFormer: Learning Transferable State Representation for Visual Control via Transformer.]]: (cite: conf/icml/MuCDCCL22) Multitask agent given a "policy token" in a transformer, so you know which policy you're doing. Helps with catastrophic forgetting. [[papers/rl/transfer/ctrlformer_learning_transferrable_state_representation_for_visual_control_via_transformer.md|Notes]]
 - [[pdfs/rl/transfer/darla_zero_shot_transfer_reinforcement_learning_disentanglement.pdf|DARLA - Improving Zero-Shot Transfer in Reinforcement Learning.]]: (cite: conf/icml/HigginsPRMBPBBL17) Proposes a new multi-stage RL agent, DARLA which "learns to see before learning to act". Vision is based on learning a disentangled representation of the environment. Once the vision module is trained, DARLA can acquire many source policies that are robust to domain shifts. In the domain adaptation setting, the input distribution is modified bu the reward structure remains intact. DARLA relies on learning a latent state representation that is shared between the source and target domains by learning a disentangled representation of the environment's generative factors. The first stage learns an unsupervised mapping that utilises observations collected by a random policy (with sufficient variability of factors and their conjunctions). Then training the policy is conditioned on the disentangled view of the world. The disentangled representations are learned using a combination Beta-VAE and a denoising autoencoder. So the Beta-VAE in this case is actually taking the DAE latent state as inputs and learning to reconstruct it as opposed to reconstructing the whole image. To do transfer, evaluate the disentangling encoder on the target domain inputs, then evaluate the policy on the output of the disentangling encoder. [[papers/rl/transfer/darla_zero_shot_transfer_reinforcement_learning_disentanglement.md|Notes]]
 - [[pdfs/rl/transfer/disentangled_cumulants_successor_representations_transfer.pdf|Disentangled Cumulants Help Successor Representations Transfer to New Tasks.]]: (cite: journals/corr/abs-1911-10866/Grimm/2019) Proposes a principled way to learn a basis set of policies which when recombined through generalised policy improvement, come with guarantees on the coverage of the final state space. First the agent learns to perform intrinsically generated goal-based tasks in the total abscence of rewards, then the agent leverages that experience to quickly acheive a high level of performance on externally specified tasks. A "successor feature" representation decouples the dynamics from the environment's reward function, basically the reward is a linear combination of the feature and some weight. GPI basically learns the "weight" for different reward funtions while keeping the successor features. The learned control policies during the first step (after disentangled feature discovery) "achieve a certain uniformly spread values for the learnt features". By learning a disentangled latent space with $z$ dimensions and discretising into $b$ bins, we can re-use the $zb$ feature control policies to solve $(b + 1)^z$ downstream goal-based tasks, where $b + 1$ includes the extra bin value per disentangled dimension which indicates whether the value is irrelevant to the task. [[papers/rl/transfer/disentangled_cumulants_successor_representations_transfer.md|Notes]]
 - [[pdfs/rl/transfer/modular_neural_network_policies_for_multi_task_and_multi_robot_transfer.pdf|Learning modular neural network policies for multi-task and multi-robot transfer.]]: (cite: conf/icra/DevinGDAL17) Decompose into "task specific" and "robot specific" modules to enable zero-shot generalization with a variety of different robots. [[papers/rl/transfer/modular_neural_network_policies_for_multi_task_and_multi_robot_transfer.md|Notes]]
 - [[pdfs/rl/transfer/parrot_data_driven_behavioural_priors_rl.pdf|Parrot - Data-Driven Behavioral Priors for Reinforcement Learning.]]: (cite: conf/iclr/SinghLZYRL21) . Presents a method to transfer from past demonstrations from similar MDPs using normalizing flows. The basic idea is to learn a function using a dataset of past trajectories on similar tasks which maps from noise to likely actions. Then you can use that downstream to learn a new task faster: random exploration corresponds to taking useful actions, since you map the random noise into "likely" actions. This results in much faster downstream learning on a variety of grasping tasks. The idea is that sampling from the gaussian distribution doesn't just do random things, it does random things that happen to be potentially useful actions on various tasks. Now all the agent needs to do is choose from which of those random potentially useful actions will it do. Note that this is different from just doing transfer learning, since transfer learning transfers an entire policy, not a distribution of policies, meaning that you might have to "unlearn" good behaviour, go back to random exploration and "re-learn" the behaviour that you want. [[papers/rl/transfer/parrot_data_driven_behavioural_priors_rl.md|Notes]]
 - [[pdfs/rl/transfer/the_role_of_pretrained_representations_for_the_ood_generalization_of_rl_agents.pdf|The Role of Pretrained Representations for the OOD Generalization of RL Agents.]]: (cite: conf/iclr/TraubleDWWGWLBS22) . [[papers/rl/transfer/the_role_of_pretrained_representations_for_the_ood_generalization_of_rl_agents.md|Notes]]
 - [[pdfs/rl/transfer/using_task_features_for_zero_shot_knowledge_transfer_in_lifelong_learning.pdf|Using Task Features for Zero-Shot Knowledge Transfer in Lifelong Learning.]]: (cite: conf/ijcai/IseleRE16) None. [[papers/rl/transfer/using_task_features_for_zero_shot_knowledge_transfer_in_lifelong_learning.md|Notes]]
## transformer
 - [[pdfs/rl/transformer/a_model_based_approach_to_meta_reinforcement_learning_transformers_and_tree_search.pdf|A model-based approach to meta-Reinforcement Learning: Transformers and tree search.]]: (cite: journals/corr/abs-2208-11535/Pinon/2022) . [[papers/rl/transformer/a_model_based_approach_to_meta_reinforcement_learning_transformers_and_tree_search.md|Notes]]
 - [[pdfs/rl/transformer/bootstrapped_transformer_for_offline_reinforcement_learning.pdf|Bootstrapped Transformer for Offline Reinforcement Learning.]]: (cite: journals/corr/abs-2206-08569/Wang/2022) . [[papers/rl/transformer/bootstrapped_transformer_for_offline_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/transformer/efficient_transformers_in_reinforcement_learning_using_actor_learner_distillation.pdf|Efficient Transformers in Reinforcement Learning using Actor-Learner Distillation.]]: (cite: conf/iclr/ParisottoS21) In a nutshell - distill the transformer into an LSTM, so that you get the transformer's superior sample efficiency, while keeping the LSTM's computational efficiency. [[papers/rl/transformer/efficient_transformers_in_reinforcement_learning_using_actor_learner_distillation.md|Notes]]
 - [[pdfs/rl/transformer/trajectory-transformer-neurips-2021.pdf|Offline Reinforcement Learning as One Big Sequence Modeling Problem.]]: (cite: conf/nips/JannerLL21) . [[papers/rl/transformer/trajectory-transformer-neurips-2021.md|Notes]]
 - [[pdfs/rl/transformer/stabilizing_transformers_for_reinforcement_learning.pdf|Stabilizing Transformers for Reinforcement Learning.]]: (cite: conf/icml/ParisottoSRPGJJ20) Transformers for real-time reinforcement learning don't work well, especially due to the use of learning rate warmup. Proposes a new architecture that allows skip connections to bypass layer normalization and replaces residual connections with  GRUCell units . [[papers/rl/transformer/stabilizing_transformers_for_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/transformer/structure_aware_transformer_policy_for_inhomogeneous_multi_task_reinforcement_learning.pdf|Structure-Aware Transformer Policy for Inhomogeneous Multi-Task Reinforcement Learning.]]: (cite: conf/iclr/HongYK22) . [[papers/rl/transformer/structure_aware_transformer_policy_for_inhomogeneous_multi_task_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/transformer/sensory_neuron_as_transformer_permutation_invariant_nn_rl.pdf|The Sensory Neuron as a Transformer - Permutation-Invariant Neural Networks for Reinforcement Learning.]]: (cite: journals/corr/abs-2109-02869/Tang/2021) Split image into patches and use a transformer without positional encodings. This is permutation invariant at test-time (to permutations of patches). [[papers/rl/transformer/sensory_neuron_as_transformer_permutation_invariant_nn_rl.md|Notes]]
 - [[pdfs/rl/transformer/transformers_are_sample_efficient_world_models.pdf|Transformers are Sample Efficient World Models.]]: (cite: journals/corr/abs-2209-00588/Micheli/2022) . Encode the world as tokens using a discrete autoencoder, learn to autoregressively predict the next world state (eg, what the discrete autoencoder says $s_{t + 1}$ encodes to) in terms of those tokens. Then learn in the imagination similar to [[dreamerv2]]. [[papers/rl/transformer/transformers_are_sample_efficient_world_models.md|Notes]]
### algorithm
 - [[pdfs/rl/transformer/algorithm/in_context_policy_iteration.pdf|In-Context Policy Iteration.]]: (cite: journals/corr/abs-2210-03821/Brooks/2022) . [[papers/rl/transformer/algorithm/in_context_policy_iteration.md|Notes]]
 - [[pdfs/rl/transformer/algorithm/in_context_reinforcement_learning_with_algorithm_distillation.pdf|In-context Reinforcement Learning with Algorithm Distillation.]]: (cite: journals/corr/abs-2210-14215/Laskin/2022) . [[papers/rl/transformer/algorithm/in_context_reinforcement_learning_with_algorithm_distillation.md|Notes]]
### decision_transformer
 - [[pdfs/rl/transformer/decision_transformer/decision_transformer.pdf|Decision Transformer: Reinforcement Learning via Sequence Modeling.]]: (cite: conf/nips/ChenLRLGLASM21) . [[papers/rl/transformer/decision_transformer/decision_transformer.md|Notes]]
 - [[pdfs/rl/transformer/decision_transformer/generalized_decision_transformer_for_offline_hindsight_information_matching.pdf|Generalized Decision Transformer for Offline Hindsight Information Matching.]]: (cite: conf/iclr/FurutaMG22) . [[papers/rl/transformer/decision_transformer/generalized_decision_transformer_for_offline_hindsight_information_matching.md|Notes]]
 - [[pdfs/rl/transformer/decision_transformer/how_crucial_is_transformer_in_decision_transformer.pdf|How Crucial is Transformer in Decision Transformer?]]: (cite: journals/corr/abs-2211-14655/Siebenborn/2022) . [[papers/rl/transformer/decision_transformer/how_crucial_is_transformer_in_decision_transformer.md|Notes]]
 - [[pdfs/rl/transformer/decision_transformer/multi_game_decision_transformers.pdf|Multi-Game Decision Transformers.]]: (cite: journals/corr/abs-2205-15241/Lee/2022) . [[papers/rl/transformer/decision_transformer/multi_game_decision_transformers.md|Notes]]
 - [[pdfs/rl/transformer/decision_transformer/dynamics_augmented_decision_transformer_for_offline_dynamics_generalization.pdf|dynamics_augmented_decision_transformer_for_offline_dynamics_generalization]]: . [[papers/rl/transformer/decision_transformer/dynamics_augmented_decision_transformer_for_offline_dynamics_generalization.md|Notes]]
 - [[pdfs/rl/transformer/decision_transformer/hyper_decision_transformer_for_efficient_online_policy_adaptation.pdf|hyper_decision_transformer_for_efficient_online_policy_adaptation]]: . [[papers/rl/transformer/decision_transformer/hyper_decision_transformer_for_efficient_online_policy_adaptation.md|Notes]]
 - [[pdfs/rl/transformer/decision_transformer/skill_decision_transformer.pdf|skill_decision_transformer]]: . [[papers/rl/transformer/decision_transformer/skill_decision_transformer.md|Notes]]
 - [[pdfs/rl/transformer/decision_transformer/when_does_returned_condition_supervised_learning_work_for_offline_reinforcement_learning.pdf|when_does_returned_condition_supervised_learning_work_for_offline_reinforcement_learning]]: . [[papers/rl/transformer/decision_transformer/when_does_returned_condition_supervised_learning_work_for_offline_reinforcement_learning.md|Notes]]
 - [[pdfs/rl/transformer/decision_transformer/you_can_t_count_on_luck_why_decision_transformers_and_rvs_fail_in_stochastic_environments.pdf|you_can_t_count_on_luck_why_decision_transformers_and_rvs_fail_in_stochastic_environments]]: . [[papers/rl/transformer/decision_transformer/you_can_t_count_on_luck_why_decision_transformers_and_rvs_fail_in_stochastic_environments.md|Notes]]
## world_models
 - [[pdfs/rl/world_models/augwm_augmented_world_models_facilitate_zero_shot_dynamics_generalization.pdf|Augmented World Models Facilitate Zero-Shot Dynamics Generalization From a Single Offline Environment.]]: (cite: conf/icml/BallLPR21) . [[papers/rl/world_models/augwm_augmented_world_models_facilitate_zero_shot_dynamics_generalization.md|Notes]]
 - [[pdfs/rl/world_models/contrastive_learning_structured_world_models.pdf|Contrastive Learning of Structured World Models.]]: (cite: conf/iclr/KipfPW20) . [[papers/rl/world_models/contrastive_learning_structured_world_models.md|Notes]]
 - [[pdfs/rl/world_models/contrastive_structured_world_models.pdf|Contrastive Learning of Structured World Models.]]: (cite: conf/iclr/KipfPW20) . [[papers/rl/world_models/contrastive_structured_world_models.md|Notes]]
 - [[pdfs/rl/world_models/structured_world_belief_for_rl_pomdp.pdf|Structured World Belief for Reinforcement Learning in POMDP.]]: (cite: conf/icml/SinghPKKA21) . [[papers/rl/world_models/structured_world_belief_for_rl_pomdp.md|Notes]]
# speech
 - [[pdfs/speech/chunked_autoregressive_gan_for_conditional_waveform_synthesis.pdf|Chunked Autoregressive GAN for Conditional Waveform Synthesis.]]: (cite: conf/iclr/MorrisonKKSCB22) . [[papers/speech/chunked_autoregressive_gan_for_conditional_waveform_synthesis.md|Notes]]
 - [[pdfs/speech/guided_tts_a_diffusion_model_for_text_to_speech.pdf|Guided-TTS: A Diffusion Model for Text-to-Speech via Classifier Guidance.]]: (cite: conf/icml/KimKY22) . [[papers/speech/guided_tts_a_diffusion_model_for_text_to_speech.md|Notes]]
 - [[pdfs/speech/its_raw_audio_generation_with_state_space_models.pdf|It&apos;s Raw! Audio Generation with State-Space Models.]]: (cite: conf/icml/GoelGDR22) . [[papers/speech/its_raw_audio_generation_with_state_space_models.md|Notes]]
 - [[pdfs/speech/style_transfer_of_audio_effects_with_differentiable_signal_processing.pdf|Style Transfer of Audio Effects with Differentiable Signal Processing.]]: (cite: journals/corr/abs-2207-08759/Steinmetz/2022) . [[papers/speech/style_transfer_of_audio_effects_with_differentiable_signal_processing.md|Notes]]
 - [[pdfs/speech/nu_wave_2_a_general_audio_upsampling_model_for_sampling_rates.pdf|nu_wave_2_a_general_audio_upsampling_model_for_sampling_rates]]: . [[papers/speech/nu_wave_2_a_general_audio_upsampling_model_for_sampling_rates.md|Notes]]
 - [[pdfs/speech/vq_wave2vec.pdf|vq-wav2vec: Self-Supervised Learning of Discrete Speech Representations.]]: (cite: conf/iclr/BaevskiSA20) . [[papers/speech/vq_wave2vec.md|Notes]]
# transfer
## mixed
 - [[pdfs/transfer/mixed/visual_nlp_supervision.pdf|Learning Transferable Visual Models From Natural Language Supervision.]]: (cite: conf/icml/RadfordKHRGASAM21) . [[papers/transfer/mixed/visual_nlp_supervision.md|Notes]]
