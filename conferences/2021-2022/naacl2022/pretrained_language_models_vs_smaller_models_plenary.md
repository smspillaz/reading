Emily Bender: Large language models don't do well on logic problems for example

Christopher Manning: Nah, the LLMs can actually understand words in the same way that we do. But grounded language learning is very exciting

Comment: Don't not teach the classical methods

William Schuler: We found some evidence suggesting that DNNs when they're used as predictors, as they get bigger, they get worse. At least in the vision case. There's an analogy that machines might work like jet engines, whereas humans work like flapping wings. Do you think that's a problem if those results replicate? Would it be a problem if machines work very different from the way that humans do?

Emily Bender: Machines will work very differently from the way that humans do, there's too much effort on trying to create autonomous machines as opposed to trying to create machines that are useful for humans.

Questions: Linguistics is an active field of research, questions like "how do children acquire language" are still unsolved.

Emily Bender: Its not a single ground truth. There's a lot to learn from the established knowledge of linguistics, you at least have methodologies and frameworks. These can inform us to get a more nuanced view on what the problem is, as opposed to "its just a wall of text".

Christopher Manning: We should pay attention to child language acquision. Kids acquire language much quicker than our models do.

Dan Roth: Self-supervision is clearly an important paradigm. However we are doing self-supervision in a rather simplistic way.

Comment: We don't raise children with hundreds of thousands of pairs. You do need to have a grounding, where machines are actually interested in achieving something, that's what gets you some language. Can we introduce multimodality and task-oriented language learning? Perhaps this would give us more parsimony.

Chitta Baral: Children go to school and read textbook. So they also learn by reading.

Emily Bender: Children learn in a grounded multimodal space and a social space. Early learning seems to come from social connections with caregivers. Mimicing that with robots means that we're creating something that is human-like - before we go down that path, ask "to what end"? Building something that is human like is not the goal here.

Chris Manning: Its a great time to be getting into grounded and social language learning. We really should have much more work in doing that. Now the possibilities for doing that are pretty good because we have multimodal models. A large part of why we've been pushing emergent language .. that's not a new idea. For a long time it was just hard to make progress that way but it was easy to make progress on a big pile of language data.

Question: Reasoning

Emily Bender: Don't just take large quanitites of text as a representation of the world, because it might not be up to the standard that you expect. Wikipedia is not a sufficient foundation for that. Wikipedia is not even big enough. If you're doing reasoning about the world you need more solid information on this.

Chris Manning: We just don't know. Its just been unbelievable how powerful systems we've been able to make with extremely simple artificial neuron systems and just stringing them together. If people had said in 2000 

Question: Language is symbolic, but human brain isn't. What is it in the human brain that is adapted to this?

Emily Bender: Linguistics hasn't solved this yet :-)

Chris Manning: Human brain cannot have any structure that is very specific to language. Language is just too evolutionarily specific. We have to view that the capacity to support language arose out of the same kind of brain developments that enabled rich visual interpretations. One of the basic facts of linguistics is that they have this hierarchical recursive structure - visual scenes also have this. (Music also has this). We have to believe that brain learning systems and inductive biases that make us of stuctured ideas that allow humans to learn language much more efficiently.

Chitta Bural: A neuroscientist could answer this better. The language you use makes you think differently. There is a connection between language and how the brain interprets the world.

Sophie from Yale/NYU: We treat linguistic and symbolic structure as alike. Are there linguistic concepts that are not symbolic which are of relevance to NLP

Emily Bender: We probably need a good definition of symbolic to answer that. When you're talking about the form side of linguistics, phonology uses discrete units. On the other end of things, you end up with things that are still symbolic, but maybe less discrete.

Chris Manning: The most common mechanism of language is speech waves and they are continuous. However there is categorical perception. People depending on their language will distinguish voiced and unvoiced consonants as distinct. Is there any continuous aspect to human communication? Yeah there are a few, emotions expressed with faces etc.