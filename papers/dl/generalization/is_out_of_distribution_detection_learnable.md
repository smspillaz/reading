---
title: "Is Out-of-Distribution Detection Learnable?"
venue: "CoRR"
volume: "abs/2210.14707"
year: "2022"
type: "Informal Publications"
access: "open"
key: "journals/corr/abs-2210-14707"
doi: "10.48550/ARXIV.2210.14707"
ee: "https://doi.org/10.48550/arXiv.2210.14707"
url: "https://dblp.org/rec/journals/corr/abs-2210-14707"
authors: ["Zhen Fang", "Yixuan Li", "Jie Lu", "Jiahua Dong", "Bo Han", "Feng Liu"]
sync_version: 3
cite_key: "journals/corr/abs-2210-14707/Fang/2022"
---
Test data may come from an unknown class, can we detect this?

This paper looks at the problem through the PAC framework and proves several impossiblity theorems and give several necessary/sufficient conditions to characterize the learnability of OOD detection.

In this paper, the scope is limited only to *detecting* OOD data, not about zero-shot performance on said OOD data.

Research questions:
 - Is OOD detection PAC-learnable?
 - Is there a PAC-learning theory to guarantee the generalization ability of OOD detection.