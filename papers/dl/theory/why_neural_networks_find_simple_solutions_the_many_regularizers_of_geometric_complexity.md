---
title: "Why neural networks find simple solutions: the many regularizers of geometric complexity."
venue: "CoRR"
volume: "abs/2209.13083"
year: "2022"
type: "Informal Publications"
access: "open"
key: "journals/corr/abs-2209-13083"
doi: "10.48550/ARXIV.2209.13083"
ee: "https://doi.org/10.48550/arXiv.2209.13083"
url: "https://dblp.org/rec/journals/corr/abs-2209-13083"
authors: ["Benoit Dherin", "Michael Munn", "Mihaela Rosca", "David G. T. Barrett"]
sync_version: 3
cite_key: "journals/corr/abs-2209-13083/Dherin/2022"
---

They propose a new notion of model complexity which sheds light on why overparameterized networks generalize so well.

Geometric complexity: discrete dichrilet energy of its logit network.

Many standard training heuristics work to lower the geometric conplexity.